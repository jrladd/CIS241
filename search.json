[
  {
    "objectID": "slides/wrangling.html#python-is-a-programming-language.",
    "href": "slides/wrangling.html#python-is-a-programming-language.",
    "title": "Data Wrangling with Python & Pandas",
    "section": "Python is a programming language.",
    "text": "Python is a programming language.\nIt’s the code you write.\nsomevariable = 5 + 6"
  },
  {
    "objectID": "slides/wrangling.html#pandas-is-a-library.",
    "href": "slides/wrangling.html#pandas-is-a-library.",
    "title": "Data Wrangling with Python & Pandas",
    "section": "Pandas is a library.",
    "text": "Pandas is a library.\nLibraries store reusable functions and methods. They need to be imported at the top of your code.\n# These are our standard imports\nimport pandas as pd # Data analysis\nimport numpy as np # Numerical Calculation\nimport altair as alt # Visualization"
  },
  {
    "objectID": "slides/wrangling.html#jupyter-is-a-program-an-integrated-development-environment-ide.",
    "href": "slides/wrangling.html#jupyter-is-a-program-an-integrated-development-environment-ide.",
    "title": "Data Wrangling with Python & Pandas",
    "section": "Jupyter is a program, an “integrated development environment” (IDE).",
    "text": "Jupyter is a program, an “integrated development environment” (IDE).\nYou can write Python in different places, but in this class we will write and run Python inside JupyterHub."
  },
  {
    "objectID": "slides/wrangling.html#jupyterhub-lets-you-store-and-access-.ipynb-files.",
    "href": "slides/wrangling.html#jupyterhub-lets-you-store-and-access-.ipynb-files.",
    "title": "Data Wrangling with Python & Pandas",
    "section": "JupyterHub lets you store and access .ipynb files.",
    "text": "JupyterHub lets you store and access .ipynb files.\nFiles are organized in a hierarchy of directories, just like on your computer."
  },
  {
    "objectID": "slides/wrangling.html#variables-store-information",
    "href": "slides/wrangling.html#variables-store-information",
    "title": "Data Wrangling with Python & Pandas",
    "section": "Variables store information",
    "text": "Variables store information\n# In Python, anything can be stored in a variable\nmyvar = 5\n\nmyvar #or print(myvar)\n\n# In Pandas, whole spreadsheets can be \"read\"\n# and then stored in a variable\ncars = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/taxis.csv')\ncars\nData in Pandas can be loaded from a filename or a URL.\nUse descriptive variable names, and avoid spaces!"
  },
  {
    "objectID": "slides/wrangling.html#you-try-it",
    "href": "slides/wrangling.html#you-try-it",
    "title": "Data Wrangling with Python & Pandas",
    "section": "You Try It!",
    "text": "You Try It!\n\nCreate a variable called newVar that is equal to the value of five plus seven. Then display your variable to see what its value is.\nCreate a variable called penguins to hold the data available at https://jrladd.com/CIS241/data/penguins.csv. Then display the DataFrame in Jupyter."
  },
  {
    "objectID": "slides/wrangling.html#add-frequent-comments-to-explain-what-your-code-does.",
    "href": "slides/wrangling.html#add-frequent-comments-to-explain-what-your-code-does.",
    "title": "Data Wrangling with Python & Pandas",
    "section": "Add frequent comments to explain what your code does.",
    "text": "Add frequent comments to explain what your code does.\nComments in Python begin with a # symbol.\n# This variable contains a continuous value\nsome_variable = 2.5\nYou should also use comments for citations!"
  },
  {
    "objectID": "slides/wrangling.html#variables-have-types-and-so-do-pandas-columns.",
    "href": "slides/wrangling.html#variables-have-types-and-so-do-pandas-columns.",
    "title": "Data Wrangling with Python & Pandas",
    "section": "Variables have types, and so do Pandas columns.",
    "text": "Variables have types, and so do Pandas columns.\n\nString or Character: a piece of text (ex. \"five\")\nInteger: a discrete numerical value (ex. 5)\nFloat or Double: a continuous numerical value (ex. 5.0)\n\nstringvar = \"five\"\n\ntype(stringvar)\n\ncars.info()"
  },
  {
    "objectID": "slides/wrangling.html#you-try-it-1",
    "href": "slides/wrangling.html#you-try-it-1",
    "title": "Data Wrangling with Python & Pandas",
    "section": "You Try It!",
    "text": "You Try It!\n\nFind the type of newVar, that you created in the last exercise.\nFind all the data types in the penguins dataframe."
  },
  {
    "objectID": "slides/wrangling.html#individual-data-types-strings-floats-integers-can-be-put-into-container-data-types-lists-dictionaries-series-dataframe.",
    "href": "slides/wrangling.html#individual-data-types-strings-floats-integers-can-be-put-into-container-data-types-lists-dictionaries-series-dataframe.",
    "title": "Data Wrangling with Python & Pandas",
    "section": "Individual data types (strings, floats, integers) can be put into container data types (lists, dictionaries, series, dataframe).",
    "text": "Individual data types (strings, floats, integers) can be put into container data types (lists, dictionaries, series, dataframe)."
  },
  {
    "objectID": "slides/wrangling.html#a-python-list-and-a-pandas-series-contain-an-ordered-collection-of-items.",
    "href": "slides/wrangling.html#a-python-list-and-a-pandas-series-contain-an-ordered-collection-of-items.",
    "title": "Data Wrangling with Python & Pandas",
    "section": "A Python list and a Pandas Series contain an ordered collection of items.",
    "text": "A Python list and a Pandas Series contain an ordered collection of items.\n# A list is surrounded by brackets and can contain any kind of data.\nmylist = [5,6,7]\n\nsecondlist = [\"cat\",\"dog\",\"fish\"]\n\n# Access items in a list\nmylist[0]\nsecondlist[1]\n\n# A Series is the Pandas version of a list and works the same way.\n# Every column of a DataFrame is its own Series.\nmyseries = pd.Series(mylist)\nmyseries[0]"
  },
  {
    "objectID": "slides/wrangling.html#a-python-dictionary-and-a-pandas-dataframe-contain-keyvalue-pairs.",
    "href": "slides/wrangling.html#a-python-dictionary-and-a-pandas-dataframe-contain-keyvalue-pairs.",
    "title": "Data Wrangling with Python & Pandas",
    "section": "A Python dictionary and a Pandas DataFrame contain key/value pairs.",
    "text": "A Python dictionary and a Pandas DataFrame contain key/value pairs.\nmydictionary = {\"pet_name\": \"Fido\", \"age\": 5, \"pet_type\": \"dog\"}\n\n# Access items in a dictionary\nmydictionary[\"pet_name\"]\nmydictionary[\"age\"]\n\n# Every DataFrame is made up of multiple Series columns\n# You access these like keys in a dictionary.\n\ntaxis[\"distance\"] # Dictionary notation\ntaxis.distance # Dot notation\n\n# Or get a whole set of columns in a new DataFrame \nprices = taxis[['fare','tip','tolls','total']]\nprices"
  },
  {
    "objectID": "slides/wrangling.html#you-try-it-2",
    "href": "slides/wrangling.html#you-try-it-2",
    "title": "Data Wrangling with Python & Pandas",
    "section": "You Try It!",
    "text": "You Try It!\n\nCreate a list of 7 items of different data types.\n\nDisplay the 4th item in the list.\nDisplay the 2nd through 5th items.\nDisplay the 3rd from last item.\n\nDisplay the 8th item in the species column of the penguins DataFrame."
  },
  {
    "objectID": "slides/wrangling.html#loops-and-conditions-let-you-manipulate-stored-data.",
    "href": "slides/wrangling.html#loops-and-conditions-let-you-manipulate-stored-data.",
    "title": "Data Wrangling with Python & Pandas",
    "section": "Loops and Conditions let you manipulate stored data.",
    "text": "Loops and Conditions let you manipulate stored data."
  },
  {
    "objectID": "slides/wrangling.html#you-can-use-the-for-operator-to-iterate-through-a-list.",
    "href": "slides/wrangling.html#you-can-use-the-for-operator-to-iterate-through-a-list.",
    "title": "Data Wrangling with Python & Pandas",
    "section": "You can use the for operator to iterate through a list.",
    "text": "You can use the for operator to iterate through a list.\nmylist = [5,6,7,8]\nnewlist = []\nfor item in mylist:\n  addone = item + 1\n  print(addone)\n  newlist.append(addone)\nprint(newlist)"
  },
  {
    "objectID": "slides/wrangling.html#you-can-use-if-and-else-to-set-conditions.",
    "href": "slides/wrangling.html#you-can-use-if-and-else-to-set-conditions.",
    "title": "Data Wrangling with Python & Pandas",
    "section": "You can use if and else to set conditions.",
    "text": "You can use if and else to set conditions.\n# Let's use the range() function to make a list\nnewlist = range(1,11) \nfor i in newlist:\n  if i-5 == 0:\n    print(\"It's five!\")\n  elif i-5 == 5:\n    print(\"It's ten!\")\n  else:\n    print(\"Nope, try again...\")"
  },
  {
    "objectID": "slides/wrangling.html#pandas-combines-loops-and-conditions-by-letting-you-filter-rows-based-on-a-condition-in-brackets.",
    "href": "slides/wrangling.html#pandas-combines-loops-and-conditions-by-letting-you-filter-rows-based-on-a-condition-in-brackets.",
    "title": "Data Wrangling with Python & Pandas",
    "section": "Pandas combines loops and conditions by letting you filter rows based on a condition in brackets.",
    "text": "Pandas combines loops and conditions by letting you filter rows based on a condition in brackets.\ncheap_fares = taxis[taxis.total &lt; 10]\ncheap_fares\nRemember to save everything in variables"
  },
  {
    "objectID": "slides/wrangling.html#row-selection-uses-standard-comparisons.",
    "href": "slides/wrangling.html#row-selection-uses-standard-comparisons.",
    "title": "Data Wrangling with Python & Pandas",
    "section": "Row selection uses standard comparisons.",
    "text": "Row selection uses standard comparisons.\n\n&gt; greater than\n&gt;= greater than or equal to\n&lt; less than\n&lt;= less than or equal to\n!= not equal\n== equal (note the double equals sign!)"
  },
  {
    "objectID": "slides/wrangling.html#you-can-also-use-logical-operators-to-combine-comparisons.",
    "href": "slides/wrangling.html#you-can-also-use-logical-operators-to-combine-comparisons.",
    "title": "Data Wrangling with Python & Pandas",
    "section": "You can also use logical operators to combine comparisons.",
    "text": "You can also use logical operators to combine comparisons.\n& “and”, | “or”, and ! “not”"
  },
  {
    "objectID": "slides/wrangling.html#logical-operators-can-also-be-combined.",
    "href": "slides/wrangling.html#logical-operators-can-also-be-combined.",
    "title": "Data Wrangling with Python & Pandas",
    "section": "Logical operators can also be combined.",
    "text": "Logical operators can also be combined.\nextreme_fares = taxis[(taxis.total &lt; 7) | (taxis.total &gt; 50)]\nextreme_fares"
  },
  {
    "objectID": "slides/wrangling.html#you-try-it-3",
    "href": "slides/wrangling.html#you-try-it-3",
    "title": "Data Wrangling with Python & Pandas",
    "section": "You Try It!",
    "text": "You Try It!\n\nUse a filter condition to create a dataframe of all the penguins in the Adelie species.\nWith a partner, do the following steps:\n\nCreate a list of numbers from 1 to 100.\nUse a for loop and a conditional statement to create a new list of only the even numbers.\nPut these numbers into a new list using the append() method."
  },
  {
    "objectID": "slides/wrangling.html#why-not-just-edit-the-data-in-the-spreadsheet",
    "href": "slides/wrangling.html#why-not-just-edit-the-data-in-the-spreadsheet",
    "title": "Data Wrangling with Python & Pandas",
    "section": "Why not just edit the data in the spreadsheet?",
    "text": "Why not just edit the data in the spreadsheet?"
  },
  {
    "objectID": "slides/wrangling.html#a-function-is-a-command-that-runs-based-on-some-input-or-parameter.",
    "href": "slides/wrangling.html#a-function-is-a-command-that-runs-based-on-some-input-or-parameter.",
    "title": "Data Wrangling with Python & Pandas",
    "section": "A function is a command that runs based on some input or parameter.",
    "text": "A function is a command that runs based on some input or parameter.\nPython has many built-in functions.\n# Some functions give a number result\nsum([5,6,7])\nmylist = [5,6,7]\nsum(mylist)\nlen(mylist)\n\n# But functions can do anything! \ntype(mydictionary)\nFunctions can do just about anything: calculate values, create graphs, transform data, etc."
  },
  {
    "objectID": "slides/wrangling.html#you-can-create-functions-like-you-create-variables.",
    "href": "slides/wrangling.html#you-can-create-functions-like-you-create-variables.",
    "title": "Data Wrangling with Python & Pandas",
    "section": "You can create functions like you create variables.",
    "text": "You can create functions like you create variables.\ndef get_last_value(some_list):\n  return some_list[len(some_list) - 1]\n\nget_last_value(mylist)"
  },
  {
    "objectID": "slides/wrangling.html#pandas-uses-both-functions-and-methods.",
    "href": "slides/wrangling.html#pandas-uses-both-functions-and-methods.",
    "title": "Data Wrangling with Python & Pandas",
    "section": "Pandas uses both functions and methods.",
    "text": "Pandas uses both functions and methods.\n# Functions are wrapped around a DataFrame or Series\npd.unique(myseries)\n\n# Methods come after a DataFrame or Series\nmyseries.unique()"
  },
  {
    "objectID": "slides/wrangling.html#the-.sort_values-method-lets-you-sort-rows-by-value.",
    "href": "slides/wrangling.html#the-.sort_values-method-lets-you-sort-rows-by-value.",
    "title": "Data Wrangling with Python & Pandas",
    "section": "The .sort_values() method lets you sort rows by value.",
    "text": "The .sort_values() method lets you sort rows by value.\ntaxis.sort_values(\"distance\", ascending=False)"
  },
  {
    "objectID": "slides/wrangling.html#rename-lets-you-rename-columns.",
    "href": "slides/wrangling.html#rename-lets-you-rename-columns.",
    "title": "Data Wrangling with Python & Pandas",
    "section": ".rename() lets you rename columns.",
    "text": ".rename() lets you rename columns.\ntaxis = taxis.rename(columns={\"fare\": \"base_fare\"})\ntaxis\nNotice we kept the same variable name here!"
  },
  {
    "objectID": "slides/wrangling.html#assign-lets-you-add-new-columns-based-on-existing-ones.",
    "href": "slides/wrangling.html#assign-lets-you-add-new-columns-based-on-existing-ones.",
    "title": "Data Wrangling with Python & Pandas",
    "section": ".assign() lets you add new columns based on existing ones.",
    "text": ".assign() lets you add new columns based on existing ones.\ntaxis_new_column = taxis.assign(total_per_person = taxis.total/taxis.passengers)\ntaxis_new_column"
  },
  {
    "objectID": "slides/wrangling.html#you-try-it-4",
    "href": "slides/wrangling.html#you-try-it-4",
    "title": "Data Wrangling with Python & Pandas",
    "section": "You try it!",
    "text": "You try it!\nSort the penguins dataframe by flipper length, with the shortest flippers at the top."
  },
  {
    "objectID": "slides/wrangling.html#we-use-.groupby-with-summary-statistics-to-make-summary-tables.",
    "href": "slides/wrangling.html#we-use-.groupby-with-summary-statistics-to-make-summary-tables.",
    "title": "Data Wrangling with Python & Pandas",
    "section": "We use .groupby() with summary statistics to make summary tables.",
    "text": "We use .groupby() with summary statistics to make summary tables.\nSummary tables are new dataframes that summarize our original data.\nThis paradigm is known as split-apply-combine, and it’s key to data analysis."
  },
  {
    "objectID": "slides/wrangling.html#you-can-use-summary-statistic-methods-to-get-values-for-a-whole-column.",
    "href": "slides/wrangling.html#you-can-use-summary-statistic-methods-to-get-values-for-a-whole-column.",
    "title": "Data Wrangling with Python & Pandas",
    "section": "You can use summary statistic methods to get values for a whole column.",
    "text": "You can use summary statistic methods to get values for a whole column.\ntaxis[\"tip\"].mean() # Dictionary notation\ntaxis.tip.mean() # Dot notation\nStat functions to use: mean(), median(), min(), max(), std()."
  },
  {
    "objectID": "slides/wrangling.html#groupby-lets-you-group-data-to-get-summaries-for-each-group.",
    "href": "slides/wrangling.html#groupby-lets-you-group-data-to-get-summaries-for-each-group.",
    "title": "Data Wrangling with Python & Pandas",
    "section": "Groupby lets you group data, to get summaries for each group.",
    "text": "Groupby lets you group data, to get summaries for each group.\ntaxis.groupby(['dropoff_borough'])\nIt doesn’t look like anything on its own!"
  },
  {
    "objectID": "slides/wrangling.html#now-we-can-put-it-all-together",
    "href": "slides/wrangling.html#now-we-can-put-it-all-together",
    "title": "Data Wrangling with Python & Pandas",
    "section": "Now we can put it all together!",
    "text": "Now we can put it all together!\n# Use multiple methods to \"chain\" operations\ntaxis.groupby([\"dropoff_borough\"]).mean(numeric_only=True)"
  },
  {
    "objectID": "slides/wrangling.html#you-try-it-5",
    "href": "slides/wrangling.html#you-try-it-5",
    "title": "Data Wrangling with Python & Pandas",
    "section": "You try it!",
    "text": "You try it!\nCreate a summary table showing the average bill depth of penguins for each species."
  },
  {
    "objectID": "slides/neuralnetworks.html#jay-alammars-visual-guides",
    "href": "slides/neuralnetworks.html#jay-alammars-visual-guides",
    "title": "Neural Networks 🧠🧠🧠",
    "section": "Jay Alammar’s Visual Guides",
    "text": "Jay Alammar’s Visual Guides\nA Visual and Interactive Guide to the Basics of Neural Networks\n\nA Visual And Interactive Look at Neural Network Math"
  },
  {
    "objectID": "slides/neuralnetworks.html#like-in-linear-or-logistic-regression-neural-nets-optimize-weights-coefficients-and-bias-intercept.",
    "href": "slides/neuralnetworks.html#like-in-linear-or-logistic-regression-neural-nets-optimize-weights-coefficients-and-bias-intercept.",
    "title": "Neural Networks 🧠🧠🧠",
    "section": "Like in linear or logistic regression, neural nets optimize weights (coefficients) and bias (intercept).",
    "text": "Like in linear or logistic regression, neural nets optimize weights (coefficients) and bias (intercept)."
  },
  {
    "objectID": "slides/neuralnetworks.html#neural-nets-often-use-gradient-descent.",
    "href": "slides/neuralnetworks.html#neural-nets-often-use-gradient-descent.",
    "title": "Neural Networks 🧠🧠🧠",
    "section": "Neural nets often use gradient descent.",
    "text": "Neural nets often use gradient descent.\n(Instead of Ordinary Least Squares or other methods.)\n\nChantal Brousseau in Programming Historian"
  },
  {
    "objectID": "slides/neuralnetworks.html#neural-nets-have-hidden-layers.",
    "href": "slides/neuralnetworks.html#neural-nets-have-hidden-layers.",
    "title": "Neural Networks 🧠🧠🧠",
    "section": "Neural nets have “hidden” layers.",
    "text": "Neural nets have “hidden” layers.\nThese activation functions allow you to create nonlinear relationships and get more sophisticated predictions."
  },
  {
    "objectID": "slides/neuralnetworks.html#neural-nets-are-always-trying-to-minimize-the-loss-function.",
    "href": "slides/neuralnetworks.html#neural-nets-are-always-trying-to-minimize-the-loss-function.",
    "title": "Neural Networks 🧠🧠🧠",
    "section": "Neural nets are always trying to minimize the “loss function.”",
    "text": "Neural nets are always trying to minimize the “loss function.”\nI.e. we are trying to eliminate as much loss or error as possible. We can add nodes and layers to our network iteratively to do better at the task."
  },
  {
    "objectID": "slides/neuralnetworks.html#neural-nets-can-be-supervised-or-unsupervised.",
    "href": "slides/neuralnetworks.html#neural-nets-can-be-supervised-or-unsupervised.",
    "title": "Neural Networks 🧠🧠🧠",
    "section": "Neural nets can be supervised or unsupervised.",
    "text": "Neural nets can be supervised or unsupervised."
  },
  {
    "objectID": "slides/neuralnetworks.html#neural-nets-are-not-brains",
    "href": "slides/neuralnetworks.html#neural-nets-are-not-brains",
    "title": "Neural Networks 🧠🧠🧠",
    "section": "Neural nets are not brains!",
    "text": "Neural nets are not brains!"
  },
  {
    "objectID": "slides/neuralnetworks.html#well-focus-on-sklearn-for-now.",
    "href": "slides/neuralnetworks.html#well-focus-on-sklearn-for-now.",
    "title": "Neural Networks 🧠🧠🧠",
    "section": "We’ll focus on SKLearn for now.",
    "text": "We’ll focus on SKLearn for now.\nMLPClassifier: Multi-Layer Perceptron\nOther key libraries: TensorFlow and Keras"
  },
  {
    "objectID": "slides/neuralnetworks.html#using-the-mlpclassifier-will-be-familiar.",
    "href": "slides/neuralnetworks.html#using-the-mlpclassifier-will-be-familiar.",
    "title": "Neural Networks 🧠🧠🧠",
    "section": "Using the MLPClassifier will be familiar.",
    "text": "Using the MLPClassifier will be familiar.\n\nSame workflow as all other sklearn models.\nYou must use one-hot encoding and you must scale your variables.\n\nfrom sklearn.neural_network import MLPClassifier"
  },
  {
    "objectID": "slides/neuralnetworks.html#which-hyperparameters-are-important",
    "href": "slides/neuralnetworks.html#which-hyperparameters-are-important",
    "title": "Neural Networks 🧠🧠🧠",
    "section": "Which hyperparameters are important?",
    "text": "Which hyperparameters are important?\n\nhidden_layer_sizes: number and size of hidden layers\nactivation: type of activation function to use\nsolver: solving method. ‘sgd’ and ‘adam’ are both stochastic gradient descent and useful for larger datasets. ‘lbfgs’ is better for small data.\nalpha: strength of regularization (helps with outliers)"
  },
  {
    "objectID": "slides/neuralnetworks.html#hyperparameters-continued",
    "href": "slides/neuralnetworks.html#hyperparameters-continued",
    "title": "Neural Networks 🧠🧠🧠",
    "section": "Hyperparameters, continued",
    "text": "Hyperparameters, continued\n\nlearning_rate and learning_rate_init: for gradient descent only, determines the size of the steps\nmax_iter: the number of iterations or epochs until the model converges\nrandom_state"
  },
  {
    "objectID": "slides/neuralnetworks.html#try-it-with-the-titanic-dataset",
    "href": "slides/neuralnetworks.html#try-it-with-the-titanic-dataset",
    "title": "Neural Networks 🧠🧠🧠",
    "section": "Try it with the Titanic dataset!",
    "text": "Try it with the Titanic dataset!\n\nLoad dataset and choose predictors.\nWrangle, split, and standardize data.\nChoose hyperparameters and train neural net.\nValidate using usual methods.\nCross-validate model to see mean accuracy score.\n\nCan you get a cross-validation accuracy above 80%?"
  },
  {
    "objectID": "slides/multiple.html",
    "href": "slides/multiple.html",
    "title": "Multiple Regression",
    "section": "",
    "text": "Bivariate regression:\n\\(Y=b_{0}+b_{1}x\\)\nMultivariate regression:\n\\(Y=b_{0}+b_{1}x_{1}+b_{2}x_{2}+b_{3}x_{3}+...\\)\n\n\n\nLet’s stick with the mpg dataset from last time.\nHow would you adjust our bivariate code to accept multiple predictors? How would you display coefficients? Try it now!"
  },
  {
    "objectID": "slides/multiple.html#multiple-regression-lets-you-add-more-independent-variables.",
    "href": "slides/multiple.html#multiple-regression-lets-you-add-more-independent-variables.",
    "title": "Multiple Regression",
    "section": "",
    "text": "Bivariate regression:\n\\(Y=b_{0}+b_{1}x\\)\nMultivariate regression:\n\\(Y=b_{0}+b_{1}x_{1}+b_{2}x_{2}+b_{3}x_{3}+...\\)"
  },
  {
    "objectID": "slides/multiple.html#you-can-add-more-variables-as-predictors.",
    "href": "slides/multiple.html#you-can-add-more-variables-as-predictors.",
    "title": "Multiple Regression",
    "section": "",
    "text": "Let’s stick with the mpg dataset from last time.\nHow would you adjust our bivariate code to accept multiple predictors? How would you display coefficients? Try it now!"
  },
  {
    "objectID": "slides/multiple.html#theres-no-magic-solution-you-can-try-different-options-but-use-your-logic-and-dont-just-throw-everything-in-there.",
    "href": "slides/multiple.html#theres-no-magic-solution-you-can-try-different-options-but-use-your-logic-and-dont-just-throw-everything-in-there.",
    "title": "Multiple Regression",
    "section": "There’s no magic solution! You can try different options, but use your logic and don’t just throw everything in there.",
    "text": "There’s no magic solution! You can try different options, but use your logic and don’t just throw everything in there."
  },
  {
    "objectID": "slides/multiple.html#occams-razor-says-that-the-simplest-model-is-probably-the-best-one.",
    "href": "slides/multiple.html#occams-razor-says-that-the-simplest-model-is-probably-the-best-one.",
    "title": "Multiple Regression",
    "section": "Occam’s Razor says that the simplest model is probably the best one.",
    "text": "Occam’s Razor says that the simplest model is probably the best one.\n\n\n\nThink carefully about how many variables you add."
  },
  {
    "objectID": "slides/multiple.html#as-you-add-variables-r2-will-increase-and-rmse-will-decrease.",
    "href": "slides/multiple.html#as-you-add-variables-r2-will-increase-and-rmse-will-decrease.",
    "title": "Multiple Regression",
    "section": "As you add variables, \\(R^{2}\\) will increase and RMSE will decrease.",
    "text": "As you add variables, \\(R^{2}\\) will increase and RMSE will decrease.\nBut think about how much it increases or decreases."
  },
  {
    "objectID": "slides/multiple.html#avoid-multicollinearity-when-two-predictor-variables-correlate.",
    "href": "slides/multiple.html#avoid-multicollinearity-when-two-predictor-variables-correlate.",
    "title": "Multiple Regression",
    "section": "Avoid Multicollinearity: when two predictor variables correlate.",
    "text": "Avoid Multicollinearity: when two predictor variables correlate.\nThis will confuse the model and mess up your results! It could even result in false predictions."
  },
  {
    "objectID": "slides/multiple.html#how-do-we-find-multicollinearity",
    "href": "slides/multiple.html#how-do-we-find-multicollinearity",
    "title": "Multiple Regression",
    "section": "How do we find multicollinearity?",
    "text": "How do we find multicollinearity?\nYou can do a pairwise comparison of the variables you’re thinking about.\nsns.pairplot(cars[predictors], kind='reg')\nCompare this to the correlation matrix.\ncars[predictors].corr()"
  },
  {
    "objectID": "slides/multiple.html#you-can-consider-categorical-variables-as-predictors-too.",
    "href": "slides/multiple.html#you-can-consider-categorical-variables-as-predictors-too.",
    "title": "Multiple Regression",
    "section": "You can consider categorical variables as predictors, too.",
    "text": "You can consider categorical variables as predictors, too.\nReference coding converts categorical variables to a set of binary variables.\nX = pd.get_dummies(cars[predictors], drop_first=True)\nThe first category should always be left out as the reference (drop_first=True). All the remaining slopes are relative to that reference!"
  },
  {
    "objectID": "slides/multiple.html#when-interpreting-coefficients-watch-out-for-confounding-variables",
    "href": "slides/multiple.html#when-interpreting-coefficients-watch-out-for-confounding-variables",
    "title": "Multiple Regression",
    "section": "When interpreting coefficients, watch out for confounding variables!",
    "text": "When interpreting coefficients, watch out for confounding variables!\nAsk yourself: is there an important variable that the data doesn’t account for?"
  },
  {
    "objectID": "slides/multiple.html#challenge-seattle-housing-data",
    "href": "slides/multiple.html#challenge-seattle-housing-data",
    "title": "Multiple Regression",
    "section": "Challenge: Seattle Housing Data",
    "text": "Challenge: Seattle Housing Data\nTry to make an effective multivariate linear model to predict housing prices in Seattle.\nTake a look at the dataset and logically choose some predictors. Check for multicollinearity before you run your model! When you’re done, try to predict housing price based on some new data points you create.\nDownload house_sales.tsv. You’ll need to open this with:\nhousing = pd.read_csv(\"house_sales.tsv\", sep=\"\\t\")"
  },
  {
    "objectID": "slides/multiple.html#how-does-the-model-do-on-out-of-sample-data",
    "href": "slides/multiple.html#how-does-the-model-do-on-out-of-sample-data",
    "title": "Multiple Regression",
    "section": "How does the model do on out-of-sample data?",
    "text": "How does the model do on out-of-sample data?\noutofsample_fitted = our_model.predict(X_test)\n\n# RMSE\nnp.sqrt(mean_squared_error(y_test, outofsample_fitted))\n\n# r_2\nr2_score(y_test, outofsample_fitted)"
  },
  {
    "objectID": "slides/multiple.html#are-the-residuals-normally-distributed-with-a-mean-near-0",
    "href": "slides/multiple.html#are-the-residuals-normally-distributed-with-a-mean-near-0",
    "title": "Multiple Regression",
    "section": "Are the residuals normally distributed, with a mean near 0?",
    "text": "Are the residuals normally distributed, with a mean near 0?\nresiduals = y_test - outofsample_fitted\n\nsns.displot(x=\"mpg\",data=residuals).set_axis_labels(x=\"Residuals\")\nYou could also use a Q-Q plot for this!"
  },
  {
    "objectID": "slides/multiple.html#does-the-model-suggest-heteroskedasticity",
    "href": "slides/multiple.html#does-the-model-suggest-heteroskedasticity",
    "title": "Multiple Regression",
    "section": "Does the model suggest heteroskedasticity?",
    "text": "Does the model suggest heteroskedasticity?\nIs the variance consistent across the range of predicted values?\n# Plot the absolute value of residuals against the predicted values\nsns.regplot(x=outofsample_fitted, y=np.abs(residuals.mpg), lowess=True)\nIf the line is horizontal, there’s no heterskedasticity."
  },
  {
    "objectID": "slides/multiple.html#other-validation-methods",
    "href": "slides/multiple.html#other-validation-methods",
    "title": "Multiple Regression",
    "section": "Other validation methods",
    "text": "Other validation methods\n\nFinding Outliers\nCook’s Distance and Leverage\nCheck for independence of errors\nPartial residual plots"
  },
  {
    "objectID": "slides/multiple.html#lets-try-this-again-with-your-seattle-housing-models",
    "href": "slides/multiple.html#lets-try-this-again-with-your-seattle-housing-models",
    "title": "Multiple Regression",
    "section": "Let’s try this again with your Seattle housing models!",
    "text": "Let’s try this again with your Seattle housing models!"
  },
  {
    "objectID": "slides/eda.html#john-tukey-1962",
    "href": "slides/eda.html#john-tukey-1962",
    "title": "Exploratory Data Analysis",
    "section": "John Tukey (1962)",
    "text": "John Tukey (1962)\n\nJohn Tukey pioneered Exploratory Data Analysis starting in 1962 and again with a book in 1977."
  },
  {
    "objectID": "slides/eda.html#summary-statistics-are-focused-on-the-location-variability-and-distribution-of-data.",
    "href": "slides/eda.html#summary-statistics-are-focused-on-the-location-variability-and-distribution-of-data.",
    "title": "Exploratory Data Analysis",
    "section": "Summary Statistics are focused on the location, variability, and distribution of data.",
    "text": "Summary Statistics are focused on the location, variability, and distribution of data."
  },
  {
    "objectID": "slides/eda.html#lets-imagine-a-variable-showing-the-heights-of-different-dogs.",
    "href": "slides/eda.html#lets-imagine-a-variable-showing-the-heights-of-different-dogs.",
    "title": "Exploratory Data Analysis",
    "section": "Let’s imagine a variable showing the heights of different dogs.",
    "text": "Let’s imagine a variable showing the heights of different dogs.\n\nThe dog’s heights (in mm) are: 600, 470, 170, 430, and 300"
  },
  {
    "objectID": "slides/eda.html#mean-is-the-sum-of-all-values-divided-by-the-number-of-values.",
    "href": "slides/eda.html#mean-is-the-sum-of-all-values-divided-by-the-number-of-values.",
    "title": "Exploratory Data Analysis",
    "section": "Mean is the sum of all values divided by the number of values.",
    "text": "Mean is the sum of all values divided by the number of values.\nAKA “average”\n\n\\(\\dfrac{600+470+170+430+300}{5} = 394\\)"
  },
  {
    "objectID": "slides/eda.html#we-can-calculate-the-mean-easily-in-python.",
    "href": "slides/eda.html#we-can-calculate-the-mean-easily-in-python.",
    "title": "Exploratory Data Analysis",
    "section": "We can calculate the mean easily in Python.",
    "text": "We can calculate the mean easily in Python.\n# Put the dog heights into a dataframe\ndogs = pd.DataFrame({\"height\": [600, 470, 170, 430, 300]})\n\ndogs.height.mean() # Calculate the mean"
  },
  {
    "objectID": "slides/eda.html#median-is-the-value-such-that-half-of-the-data-lies-above-and-below.",
    "href": "slides/eda.html#median-is-the-value-such-that-half-of-the-data-lies-above-and-below.",
    "title": "Exploratory Data Analysis",
    "section": "Median is the value such that half of the data lies above and below.",
    "text": "Median is the value such that half of the data lies above and below.\nAKA “50th percentile”\n\n600, 470, 170, 430, 300dogs.height.median()"
  },
  {
    "objectID": "slides/eda.html#percentile-is-a-value-such-that-p-percent-of-the-data-lies-below.",
    "href": "slides/eda.html#percentile-is-a-value-such-that-p-percent-of-the-data-lies-below.",
    "title": "Exploratory Data Analysis",
    "section": "Percentile is a value such that P percent of the data lies below.",
    "text": "Percentile is a value such that P percent of the data lies below.\nAKA “quantile”"
  },
  {
    "objectID": "slides/eda.html#the-25th-percentile-is-the-1st-quartile.",
    "href": "slides/eda.html#the-25th-percentile-is-the-1st-quartile.",
    "title": "Exploratory Data Analysis",
    "section": "The 25th Percentile is the 1st Quartile.",
    "text": "The 25th Percentile is the 1st Quartile.\n\n600, 470, 170, 430, 300dogs.describe()"
  },
  {
    "objectID": "slides/eda.html#the-75th-percentile-is-the-3rd-quartile.",
    "href": "slides/eda.html#the-75th-percentile-is-the-3rd-quartile.",
    "title": "Exploratory Data Analysis",
    "section": "The 75th Percentile is the 3rd Quartile.",
    "text": "The 75th Percentile is the 3rd Quartile.\n\n600, 470, 170, 430, 300dogs.describe()"
  },
  {
    "objectID": "slides/eda.html#the-median-is-the-2nd-quartile",
    "href": "slides/eda.html#the-median-is-the-2nd-quartile",
    "title": "Exploratory Data Analysis",
    "section": "The median is the 2nd Quartile!!",
    "text": "The median is the 2nd Quartile!!"
  },
  {
    "objectID": "slides/eda.html#an-outlier-is-a-data-value-thats-different-from-most-of-the-data.",
    "href": "slides/eda.html#an-outlier-is-a-data-value-thats-different-from-most-of-the-data.",
    "title": "Exploratory Data Analysis",
    "section": "An outlier is a data value that’s different from most of the data.",
    "text": "An outlier is a data value that’s different from most of the data.\nAKA “extreme value”"
  },
  {
    "objectID": "slides/eda.html#a-robust-variable-is-not-sensitive-to-extreme-values.",
    "href": "slides/eda.html#a-robust-variable-is-not-sensitive-to-extreme-values.",
    "title": "Exploratory Data Analysis",
    "section": "A robust variable is not sensitive to extreme values.",
    "text": "A robust variable is not sensitive to extreme values."
  },
  {
    "objectID": "slides/eda.html#the-interquartile-range-is-the-difference-between-the-1st-and-3rd-quartiles.",
    "href": "slides/eda.html#the-interquartile-range-is-the-difference-between-the-1st-and-3rd-quartiles.",
    "title": "Exploratory Data Analysis",
    "section": "The interquartile range is the difference between the 1st and 3rd quartiles.",
    "text": "The interquartile range is the difference between the 1st and 3rd quartiles.\ndogs.height.quantile(.75)-dogs.height.quantile(.25)"
  },
  {
    "objectID": "slides/eda.html#a-deviation-is-the-difference-between-an-actual-value-and-an-estimate-of-location-like-the-mean.",
    "href": "slides/eda.html#a-deviation-is-the-difference-between-an-actual-value-and-an-estimate-of-location-like-the-mean.",
    "title": "Exploratory Data Analysis",
    "section": "A deviation is the difference between an actual value and an estimate of location (like the mean).",
    "text": "A deviation is the difference between an actual value and an estimate of location (like the mean)."
  },
  {
    "objectID": "slides/eda.html#the-variance-is-the-sum-of-the-squared-deviations-divided-by-the-number-of-values.",
    "href": "slides/eda.html#the-variance-is-the-sum-of-the-squared-deviations-divided-by-the-number-of-values.",
    "title": "Exploratory Data Analysis",
    "section": "The variance is the sum of the squared deviations, divided by the number of values.",
    "text": "The variance is the sum of the squared deviations, divided by the number of values.\n\n\\(\\dfrac{206^2+76^2+(-224)^2+36^2+(-94)^2}{5} = 21,704\\)"
  },
  {
    "objectID": "slides/eda.html#the-standard-deviation-is-the-square-root-of-the-variance.",
    "href": "slides/eda.html#the-standard-deviation-is-the-square-root-of-the-variance.",
    "title": "Exploratory Data Analysis",
    "section": "The standard deviation is the square root of the variance.",
    "text": "The standard deviation is the square root of the variance.\n\nIt gives us a “standard” way of knowing what is normal, or what is extra large/extra small.\nRottweilers are tall, and dachsunds are short—compared to the standard deviation from the mean.\nOutliers are often more than two standard deviations from the mean."
  },
  {
    "objectID": "slides/eda.html#now-calculate-the-variance-and-standard-deviations-in-python.",
    "href": "slides/eda.html#now-calculate-the-variance-and-standard-deviations-in-python.",
    "title": "Exploratory Data Analysis",
    "section": "Now calculate the variance and standard deviations in Python.",
    "text": "Now calculate the variance and standard deviations in Python.\ndogs.height.var()\n\ndogs.height.std()\nWere these the results you expected?"
  },
  {
    "objectID": "slides/eda.html#population-vs.-sample",
    "href": "slides/eda.html#population-vs.-sample",
    "title": "Exploratory Data Analysis",
    "section": "Population vs. Sample",
    "text": "Population vs. Sample\n\nPopulation: the full data that exists (i.e. all the dogs in the world)\nSample: the actual data that was collected (i.e. our set of 5 dogs)"
  },
  {
    "objectID": "slides/eda.html#population-vs.-sample-1",
    "href": "slides/eda.html#population-vs.-sample-1",
    "title": "Exploratory Data Analysis",
    "section": "Population vs. Sample",
    "text": "Population vs. Sample\nWhen you have “N” data values:\n\nThe Entire Population: divide by N when calculating variance (like we did)\nA Sample: divide by N-1 when calculating variance\nSample variance: \\(\\dfrac{108,520}{4}=27,130\\)\n\nSample standard deviation: \\(\\sqrt{27,130}=164\\)\nThink of it as a “correction” when your data is only a sample. Pandas does this by default!"
  },
  {
    "objectID": "slides/eda.html#neither-the-mean-variance-nor-standard-deviation-are-robust.-they-are-all-very-sensitive-to-outliers",
    "href": "slides/eda.html#neither-the-mean-variance-nor-standard-deviation-are-robust.-they-are-all-very-sensitive-to-outliers",
    "title": "Exploratory Data Analysis",
    "section": "Neither the mean, variance, nor standard deviation are robust. They are all very sensitive to outliers!",
    "text": "Neither the mean, variance, nor standard deviation are robust. They are all very sensitive to outliers!"
  },
  {
    "objectID": "slides/eda.html#histograms-show-distributions-based-on-frequency-counts.",
    "href": "slides/eda.html#histograms-show-distributions-based-on-frequency-counts.",
    "title": "Exploratory Data Analysis",
    "section": "Histograms show distributions based on frequency counts.",
    "text": "Histograms show distributions based on frequency counts.\n\nThe histogram for miles per gallon highway in the mpg dataset."
  },
  {
    "objectID": "slides/eda.html#the-normal-distribution-has-most-values-in-the-middle.",
    "href": "slides/eda.html#the-normal-distribution-has-most-values-in-the-middle.",
    "title": "Exploratory Data Analysis",
    "section": "The normal distribution has most values in the middle.",
    "text": "The normal distribution has most values in the middle.\n\nIn a normal distribution, 95% of the values lie within 2 standard deviations of the mean.Be careful: normal distributions are assumed for many statistical analyses!"
  },
  {
    "objectID": "slides/eda.html#boxplots-show-distribution-based-on-the-median.",
    "href": "slides/eda.html#boxplots-show-distribution-based-on-the-median.",
    "title": "Exploratory Data Analysis",
    "section": "Boxplots show distribution based on the median.",
    "text": "Boxplots show distribution based on the median.\n\nYou can see how the box plot and the histogram are similar but different."
  },
  {
    "objectID": "slides/eda.html#location-variability-and-distribution-are-for-one-variable-at-a-time-univariate-analysis.-correlation-is-for-two-variables-bivariate-analysis.",
    "href": "slides/eda.html#location-variability-and-distribution-are-for-one-variable-at-a-time-univariate-analysis.-correlation-is-for-two-variables-bivariate-analysis.",
    "title": "Exploratory Data Analysis",
    "section": "Location, Variability, and Distribution are for one variable at a time (univariate analysis). Correlation is for two variables (bivariate analysis).",
    "text": "Location, Variability, and Distribution are for one variable at a time (univariate analysis). Correlation is for two variables (bivariate analysis)."
  },
  {
    "objectID": "slides/eda.html#scatter-plots-and-correlation-coefficients-are-used-to-determine-correlation.",
    "href": "slides/eda.html#scatter-plots-and-correlation-coefficients-are-used-to-determine-correlation.",
    "title": "Exploratory Data Analysis",
    "section": "Scatter plots and correlation coefficients are used to determine correlation.",
    "text": "Scatter plots and correlation coefficients are used to determine correlation.\nWe’ll talk more about correlation in a couple weeks!"
  },
  {
    "objectID": "slides/eda.html#resampling-is-simply-drawing-multiple-random-samples-from-observed-data.",
    "href": "slides/eda.html#resampling-is-simply-drawing-multiple-random-samples-from-observed-data.",
    "title": "Exploratory Data Analysis",
    "section": "Resampling is simply drawing multiple random samples from observed data.",
    "text": "Resampling is simply drawing multiple random samples from observed data.\nI can grab a sample of 5 observations. Then I can “resample” 5 more. Then 5 more, and so on and so on."
  },
  {
    "objectID": "slides/eda.html#first-proposed-in-the-1960s-resampling-procedures-werent-practical-until-computing-took-off-in-the-1980s.",
    "href": "slides/eda.html#first-proposed-in-the-1960s-resampling-procedures-werent-practical-until-computing-took-off-in-the-1980s.",
    "title": "Exploratory Data Analysis",
    "section": "First proposed in the 1960s, resampling procedures weren’t practical until computing took off in the 1980s.",
    "text": "First proposed in the 1960s, resampling procedures weren’t practical until computing took off in the 1980s."
  },
  {
    "objectID": "slides/eda.html#resampling-is-an-umbrella-term.-it-can-include",
    "href": "slides/eda.html#resampling-is-an-umbrella-term.-it-can-include",
    "title": "Exploratory Data Analysis",
    "section": "Resampling is an umbrella term. It can include:",
    "text": "Resampling is an umbrella term. It can include:\n\nThe Bootstrap, used to assess the reliability of an estimated statistic\nPermutation Tests, used as an alternative to parametric hypothesis tests"
  },
  {
    "objectID": "slides/eda.html#you-can-resample-with-or-without-replacement.",
    "href": "slides/eda.html#you-can-resample-with-or-without-replacement.",
    "title": "Exploratory Data Analysis",
    "section": "You can resample with or without replacement.",
    "text": "You can resample with or without replacement.\nReplacement means an item is returned to the sample before the next draw (i.e. you could wind up with the same observation multiple times)."
  },
  {
    "objectID": "slides/eda.html#using-bootstrap-sampling-we-can-estimate-a-confidence-interval-for-any-summary-statistic.",
    "href": "slides/eda.html#using-bootstrap-sampling-we-can-estimate-a-confidence-interval-for-any-summary-statistic.",
    "title": "Exploratory Data Analysis",
    "section": "Using bootstrap sampling, we can estimate a confidence interval for any summary statistic.",
    "text": "Using bootstrap sampling, we can estimate a confidence interval for any summary statistic.\n\nRemember: bootstrap sampling is sampling with replacement.\nThe 90% confidence interval tells us where 90% of the data is likely to fall, if the data were random.\nConfidence intervals are used to gauge uncertainty."
  },
  {
    "objectID": "slides/eda.html#confidence-intervals-with-pandas",
    "href": "slides/eda.html#confidence-intervals-with-pandas",
    "title": "Exploratory Data Analysis",
    "section": "Confidence intervals with Pandas",
    "text": "Confidence intervals with Pandas\nWork with a partner to calculate the confidence interval for the mean height in the dogs dataframe (remember to use your Pandas cheatsheet and past slideshows):\n\nFind the number of rows in the dataframe, assign to a variable n_rows.\nCreate a for loop through a list of 5000 numbers using range(5000).\n\nIn the loop, use the sample() function where n= your number of rows and replace=True.\nGet the mean() of the height column of each sample, and assign it to a variable.\nUse append() to add your sample means to an empty list.\n\nTurn the list in to a Pandas Series with pd.Series(your_list).\nFind the 95th percentile (quantile) and the 5th percentile (quantile) and assign each to a variable.\nprint() your results using f-strings.\n\nThe result should read: “The mean dog height in our data is _______, with a 90% confidence interval of _____ to _____.”"
  },
  {
    "objectID": "slides/eda.html#confidence-intervals-with-pandas-1",
    "href": "slides/eda.html#confidence-intervals-with-pandas-1",
    "title": "Exploratory Data Analysis",
    "section": "Confidence intervals with Pandas",
    "text": "Confidence intervals with Pandas\nn_rows = dogs.shape[0] # First find the number of rows in the dataframe.\n\n# Then take a sample with replacement from your dataset, and\n# Calculate the mean each time. Do this 5000 times.\nbootstrap_samples = []\nfor i in range(5000):\n    sample_mean = dogs.sample(n=n_rows, replace=True).height.mean()\n    bootstrap_samples.append(sample_mean)\n\n# Put the results into a pandas Series object\nbootstrap_samples = pd.Series(bootstrap_samples)\n\n# Calculate the 95th percentile and the 5th percentile.\ntop_percentile = bootstrap_samples.quantile(.95)\nbottom_percentile = bootstrap_samples.quantile(.05)\n\n# Print the results using nice f-strings.\nprint(f\"The mean dog height in our data is {dogs.height.mean():.3f}, with a 90% confidence interval of {bottom_percentile:.3f} to {top_percentile:.3f}.\")"
  },
  {
    "objectID": "policies.html",
    "href": "policies.html",
    "title": "Course Policies",
    "section": "",
    "text": "This class is a broad overview of the field of data analysis, and foundational skills in data and programming. We will cover a lot of information during the semester, and you will have many opportunities to practice these skills, discuss ethical aspects of data mining with your peers, and collaborate on projects. Some of you may be entering the classroom with more advanced prior knowledge of these topics, while others may be encountering these concepts for the first time. Group learning, coding, and discussion are key aspects of this course. This means that we all need to do our part to be prepared for each class, and to foster a positive and inquisitive learning environment.\nIn between classes you should:\n\nReview your notes from class\nRead relevant portions of your textbook or any online readings\nRefer to this site for updates to the schedule\nDO NOT wait until the last minute to begin your final project\nProofread your writing and coding assignments\nEMAIL your instructor with any questions. Ask lots of questions!\n\nEach class must create its own learning community as the result of shared efforts on the part of all members. It is your responsibility as a member of this learning community to help your fellow students by attending class and turning in assignments on time. If you must miss a class or turn in an assignment late, please let me know beforehand so that we may work out a way for you to make up the work. You do not need a doctor’s note or other written excuse, but please let me know if there are special circumstances that may prevent you from completing a large amount of coursework.\n\n\n\nGood participation should be understood as consistent and thoughtful contribution to the classroom community, an engagement with course materials and conversations, and a general responsiveness to (and respect for) one’s fellow students and instructor. This isn’t an accounting of how often you speak in class. Instead, it’s about what you offer to the intellectual life of the class, and everyone contributes to this on-going work in different ways. Particularly because so much of the class will consist of hands-on work, you’ll get participation credit simply for attending class and doing the work with care.\nAttending class is not optional: regular attendance is necessary to succeed in this course. Each day will have new content, activities, and learning opportunities. You’ll want to attend as much as possible to avoid falling behind. If you have to miss class for any reason, please let me know in advance, especially if you have to miss more than one class in a row. Missing class is not an excuse for missing assignment deadlines, being unprepared for the next class session, or falling behind on the weekly workshops. You are responsible for keeping up-to-date with the work of the course or for communicating with me about unexpected circumstances which change your ability to do so. You can always reach out to me or a classmate to find out what you missed. We’re all in this together, and I’ll do my best to make sure no one falls behind.\n\n\n\nAll assignments are due by the time listed on the prompt. I know that things don’t always go according to plan. If you need an extension, simply ask for one (using the web form), and you’ll almost always receive it. You don’t need an excuse to receive an extension!\nHowever, you must ask for the extension at least 24 hours before the assignment deadline. To request an extension, simply fill out this form, where you will propose a new deadline for the assignment (a good rule of thumb is a day or two after the original deadline). Any work received late (less than 48 hours) without an agreed-upon extension will receive a point deduction.\nBut keep in mind: I cannot accept any assignment more than 48 hours late. Assignments more than 48 hours late will receive a 0.\n\n\nIf I have to miss class due to illness or any other reason, I will let you know as soon as possible via email. I’ll also post any relevant materials on Sakai or on this website, and my email will let you know what you need to do. It’s a good idea to check your email at least once a day, since that’s the primary way I’ll keep in touch about any changes to the schedule.\n\n\n\n\nIn this course, as in all courses, you are expected to adhere to W&J’s standards of academic honesty and integrity. You should refer to the College Catalog on MyW&J for the details of this policy and how cases of academic misconduct are handled.\nIn general, when completing writing assignments, ensure all work is your own, and give credit where it is due in your citations. Likewise do not collaborate on tests, or homework assignments unless explicitly granted permission. If you have any concerns about whether you might have plagiarized (e.g., if you’re not sure about some particular rule), please get in touch with me immediately—I will gladly discuss the matter with you.\n\n\nThese standards of academic integrity apply to coding as well as other kinds of classwork. Citation isn’t just for papers! It’s very common, and perfectly permissible, to borrow code snippets from a classmate or from somewhere online. When you do, make sure to include a note in your code’s comments about where the code came from. Keep in mind that this includes the use of any automated writing or code assistants like ChatGPT—any use of such programs should be cited like any website, with a link to the chat record. Not only will this let you give appropriate intellectual credit and avoid plagiarism, it will also help you remember what you were trying to do when you revise your code later.\nWith regard to ChatGPT, Gemini, GitHub Copilot, or any related generative AI systems, keep in mind that in this class you are only permitted to use these systems to help with your code, never with your writing. If you do use a code assistant to help, you must cite what you used in a comment and include a link to the chat record. And keep in mind that these tools may not give you the best advice! It’s always better to work from our course materials or ask a classmate for help.\n\n\n\n\nEveryone has the right to be addressed as they feel most comfortable. It’s hard to learn if you cringe every time I call on you or address you in communication. I will ask everyone at the beginning of the semester to tell me their preferred name, pronunciation, and the pronouns they use. I will do my very best to get it right. Please do not feel the need to change your name or pronouns to “make it easy” for me, and please correct me if I get it wrong! This policy goes for everyone—use the names and pronouns dictated by the person to whom they belong. Also, our personal growth does not always align with the semester system: If your name or pronoun changes part way through the class, please send me an update!\n\n\n\nPlease be respectful with your use of laptops and technology in class. I request that you only use them for class related purposes, as I and others may find them distracting (For example, no email or social media should be open in your browser tabs!). Cell phones should be kept silent and put away, and you can expect the same from me.\n\n\n\nI encourage you to email me anytime with questions or thoughts about the class. It can sometimes take me up to 24 hours to respond to your message, but I will do my best to get back to you within that period. On the weekends (Friday 5pm–Monday 9am), the response time is 48 hours. This means that if you have a question about an assignment that you email to me the night before something is due, I may not be able to get back to you until after the assignment was due. In these cases, it’s best to plan ahead. But don’t hesitate to email whenever you have a question, and I’ll get back to you as soon as I can!"
  },
  {
    "objectID": "policies.html#shared-expectations-for-this-class",
    "href": "policies.html#shared-expectations-for-this-class",
    "title": "Course Policies",
    "section": "",
    "text": "This class is a broad overview of the field of data analysis, and foundational skills in data and programming. We will cover a lot of information during the semester, and you will have many opportunities to practice these skills, discuss ethical aspects of data mining with your peers, and collaborate on projects. Some of you may be entering the classroom with more advanced prior knowledge of these topics, while others may be encountering these concepts for the first time. Group learning, coding, and discussion are key aspects of this course. This means that we all need to do our part to be prepared for each class, and to foster a positive and inquisitive learning environment.\nIn between classes you should:\n\nReview your notes from class\nRead relevant portions of your textbook or any online readings\nRefer to this site for updates to the schedule\nDO NOT wait until the last minute to begin your final project\nProofread your writing and coding assignments\nEMAIL your instructor with any questions. Ask lots of questions!\n\nEach class must create its own learning community as the result of shared efforts on the part of all members. It is your responsibility as a member of this learning community to help your fellow students by attending class and turning in assignments on time. If you must miss a class or turn in an assignment late, please let me know beforehand so that we may work out a way for you to make up the work. You do not need a doctor’s note or other written excuse, but please let me know if there are special circumstances that may prevent you from completing a large amount of coursework.\n\n\n\nGood participation should be understood as consistent and thoughtful contribution to the classroom community, an engagement with course materials and conversations, and a general responsiveness to (and respect for) one’s fellow students and instructor. This isn’t an accounting of how often you speak in class. Instead, it’s about what you offer to the intellectual life of the class, and everyone contributes to this on-going work in different ways. Particularly because so much of the class will consist of hands-on work, you’ll get participation credit simply for attending class and doing the work with care.\nAttending class is not optional: regular attendance is necessary to succeed in this course. Each day will have new content, activities, and learning opportunities. You’ll want to attend as much as possible to avoid falling behind. If you have to miss class for any reason, please let me know in advance, especially if you have to miss more than one class in a row. Missing class is not an excuse for missing assignment deadlines, being unprepared for the next class session, or falling behind on the weekly workshops. You are responsible for keeping up-to-date with the work of the course or for communicating with me about unexpected circumstances which change your ability to do so. You can always reach out to me or a classmate to find out what you missed. We’re all in this together, and I’ll do my best to make sure no one falls behind.\n\n\n\nAll assignments are due by the time listed on the prompt. I know that things don’t always go according to plan. If you need an extension, simply ask for one (using the web form), and you’ll almost always receive it. You don’t need an excuse to receive an extension!\nHowever, you must ask for the extension at least 24 hours before the assignment deadline. To request an extension, simply fill out this form, where you will propose a new deadline for the assignment (a good rule of thumb is a day or two after the original deadline). Any work received late (less than 48 hours) without an agreed-upon extension will receive a point deduction.\nBut keep in mind: I cannot accept any assignment more than 48 hours late. Assignments more than 48 hours late will receive a 0.\n\n\nIf I have to miss class due to illness or any other reason, I will let you know as soon as possible via email. I’ll also post any relevant materials on Sakai or on this website, and my email will let you know what you need to do. It’s a good idea to check your email at least once a day, since that’s the primary way I’ll keep in touch about any changes to the schedule.\n\n\n\n\nIn this course, as in all courses, you are expected to adhere to W&J’s standards of academic honesty and integrity. You should refer to the College Catalog on MyW&J for the details of this policy and how cases of academic misconduct are handled.\nIn general, when completing writing assignments, ensure all work is your own, and give credit where it is due in your citations. Likewise do not collaborate on tests, or homework assignments unless explicitly granted permission. If you have any concerns about whether you might have plagiarized (e.g., if you’re not sure about some particular rule), please get in touch with me immediately—I will gladly discuss the matter with you.\n\n\nThese standards of academic integrity apply to coding as well as other kinds of classwork. Citation isn’t just for papers! It’s very common, and perfectly permissible, to borrow code snippets from a classmate or from somewhere online. When you do, make sure to include a note in your code’s comments about where the code came from. Keep in mind that this includes the use of any automated writing or code assistants like ChatGPT—any use of such programs should be cited like any website, with a link to the chat record. Not only will this let you give appropriate intellectual credit and avoid plagiarism, it will also help you remember what you were trying to do when you revise your code later.\nWith regard to ChatGPT, Gemini, GitHub Copilot, or any related generative AI systems, keep in mind that in this class you are only permitted to use these systems to help with your code, never with your writing. If you do use a code assistant to help, you must cite what you used in a comment and include a link to the chat record. And keep in mind that these tools may not give you the best advice! It’s always better to work from our course materials or ask a classmate for help.\n\n\n\n\nEveryone has the right to be addressed as they feel most comfortable. It’s hard to learn if you cringe every time I call on you or address you in communication. I will ask everyone at the beginning of the semester to tell me their preferred name, pronunciation, and the pronouns they use. I will do my very best to get it right. Please do not feel the need to change your name or pronouns to “make it easy” for me, and please correct me if I get it wrong! This policy goes for everyone—use the names and pronouns dictated by the person to whom they belong. Also, our personal growth does not always align with the semester system: If your name or pronoun changes part way through the class, please send me an update!\n\n\n\nPlease be respectful with your use of laptops and technology in class. I request that you only use them for class related purposes, as I and others may find them distracting (For example, no email or social media should be open in your browser tabs!). Cell phones should be kept silent and put away, and you can expect the same from me.\n\n\n\nI encourage you to email me anytime with questions or thoughts about the class. It can sometimes take me up to 24 hours to respond to your message, but I will do my best to get back to you within that period. On the weekends (Friday 5pm–Monday 9am), the response time is 48 hours. This means that if you have a question about an assignment that you email to me the night before something is due, I may not be able to get back to you until after the assignment was due. In these cases, it’s best to plan ahead. But don’t hesitate to email whenever you have a question, and I’ll get back to you as soon as I can!"
  },
  {
    "objectID": "policies.html#important-resources-for-this-class-and-your-college-journey",
    "href": "policies.html#important-resources-for-this-class-and-your-college-journey",
    "title": "Course Policies",
    "section": "Important Resources for this Class and Your College Journey",
    "text": "Important Resources for this Class and Your College Journey\n\nCIS PAL Tutors\nThe CIS department has its own PAL tutors: they’re available to help Sunday–Thursday evenings from 7–10pm in the CIS Lounge on the second floor of the Tech Center. (I’ll post more detailed tutor bios and schedules on Sakai.)\nAll the CIS PAL tutors are students who’ve taken this class before and/or have lots of knowledge about Python and data analysis. They’re a great resource, and they’re there to help you! I encourage you to take advantage of their expertise when you have questions or need help.\n\n\nMental Health\nWhat we do in college is not easy, on many fronts. Students are challenged with feelings of depression, anxiety, and self harm at astonishingly high rates. Learning is hard, and you will likely be challenged in college in ways that you haven’t experienced before. Learning while life is hard is even harder. Please take care of yourself. Drink water, eat well, and get more than seven hours of sleep. Have some hobbies, but don’t feel the need to do everything. If you are feeling depressed, withdrawn, anxious, like an impostor, or you are having specific problems with harassment, assault, bias, etc., please seek help. There are many resources on campus, and my door and email are always open.\nW&J’s Student Health and Counseling Center offers confidential counseling services: https://www.washjeff.edu/student-life/student-health-and-counseling-center/\n\n\nDisability Support Services\nWashington & Jefferson College is committed to providing academic accommodations for students with disabilities. This includes individuals with physical disabilities, learning disabilities, and mental health disorders that meet the definition of a disability under the Americans with Disabilities Act. Students who plan to request accommodations should contact the Director for Academic Success as early as possible, although requests may be made at any time. To determine whether you qualify for accommodations, or if you have questions about services and procedures, please call 724-223-6008 or send an email to dss@washjeff.edu.\n\n\nW&J Library\nI highly recommend that you make use of the W&J Library resources while navigating your work this semester. That includes not only primary literature, access to databases, and book references, but also the friendly members of the library staff. They are excellent resources for finding information efficiently, or learning what you can access through W&J subscriptions that might not be freely available on the internet. The W&J Library page for CIS is https://libguides.washjeff.edu/cis.\n\n\nWriting Center\nStaffed by student Peer Writing Tutors, the Writing Center is a free resource available to all W&J students. Writing Tutors from many majors help writers one-on-one in all phases of the writing process, from deciphering assignments, to discussing ideas, to developing an argument, to finalizing a draft. Because proofreading is a last step in that process, you should leave plenty of time (like at least a week) for getting your ideas right before expecting proofreading help. Consultants also can help writers with personal documents, like job and internship applications. The Center welcomes student writers with all varieties of backgrounds and college preparation, including multilingual writers. Please visit the Writing Center’s page (https://mywj.washjeff.edu/office/writing-center) on MyW&J for specific information regarding hours of availability and how to schedule an appointment.\n\n\nCautions regarding copyright and licensing\nAll documents provided to you (i.e. syllabus, paper prompts, tests, etc…) are the property of the instructor or author. It is a violation of intellectual property to post these online (especially to websites promoting copying/cheating) or to provide them to students not in our class or in future classes. Your papers are your property, and while you can do with them as you wish, it may be a violation of academic integrity to make them available to others who might use them for plagiarism. Basically, keep course materials and your work to yourself except in the process of editing and peer review.\n\n\nInclusion and Diversity\nThis course is open to anyone interested in data mining and analysis. It is my intent to make all students feel welcome and served in this course by addressing their learning needs. We all (including myself) are continuously learning about different lived experiences and in this course we will encounter anti-racist pedagogy and confront inequities in how data is collected and used. In this course, if you encounter anything said (intentionally or unintentionally) that made you feel uncomfortable, please talk to me about it. If your learning is impacted by your background, or any life event going on outside of class, feel free to talk to me. Even if you choose not to share details, I would be happy to direct you to the right resources on campus.\nThis semester we will address topics which may be emotionally difficult. I acknowledge that each of you has their own specific life history, family context, identity, body—and that these realities have an impact on how you understand and interact with our course materials. Therefore, I ask you to generally familiarize yourself with the content of our discussions ahead of time, and if for any reason you believe you will be unable to participate in a discussion of certain themes or elements, please contact me beforehand and/or seek the support of any of the formal or informal resources available to you on campus, some of which are included in this syllabus. I look forward to creating a safe learning environment together this semester!"
  },
  {
    "objectID": "policies.html#grading-scale",
    "href": "policies.html#grading-scale",
    "title": "Course Policies",
    "section": "Grading Scale",
    "text": "Grading Scale\n\n\n\nLetter Grade\nPoint Total\n\n\n\n\nA\n93-100\n\n\nA-\n90-92\n\n\nB+\n87-89\n\n\nB\n83-86\n\n\nB-\n80-82\n\n\nC+\n77-79\n\n\nC\n73-76\n\n\nC-\n70-72\n\n\nD+\n67-69\n\n\nD\n63-66\n\n\nD-\n60-62\n\n\nF\n&lt;60"
  },
  {
    "objectID": "jupyter.html",
    "href": "jupyter.html",
    "title": "Setting Up Jupyter Lab",
    "section": "",
    "text": "This page will help you make sure you are set up to use Python and Jupyter Lab on your own computer as well as in the classroom. You will use the Jupyter Notebook file getting_started.ipynb linked below and also available in the Python folder in the Resources tab to test that you are set up properly.\nhttps://jrladd.com/CIS241/resources/00_getting_started.ipynb"
  },
  {
    "objectID": "jupyter.html#getting-set-up-on-your-own-computer",
    "href": "jupyter.html#getting-set-up-on-your-own-computer",
    "title": "Setting Up Jupyter Lab",
    "section": "Getting Set Up On Your Own Computer",
    "text": "Getting Set Up On Your Own Computer\nTo use python on your own computer, you will install Anaconda, available at https://www.anaconda.com/products/individual\n\nDownload the Individual Edition installer for your system\nRun the installer using the default/recommended options\nDownload the getting_started.ipynb file linked above, keeping track of where you have saved it on your computer\nLaunch the Jupyter Lab application; this may be inside an Anaconda3 folder or an Anaconda Navigator application\nIn the interface that appears, navigate through the directories/folders on your computer to the space where you have saved the getting_started.ipynb file.\nClick on the getting_started.ipynb file to open it; you should see a collection of Python code and markdown comments, broken up between a number of boxes/cells\nFollow the instructions in the file to run the code and review the output"
  },
  {
    "objectID": "jupyter.html#getting-set-up-in-the-classroom",
    "href": "jupyter.html#getting-set-up-in-the-classroom",
    "title": "Setting Up Jupyter Lab",
    "section": "Getting Set Up In The Classroom",
    "text": "Getting Set Up In The Classroom\nImportant Note: while we will be using the same software, Jupyter Lab, in both the classroom and on your own computer, you will start the applications in different ways depending on which system you are on. Specifically, in the classroom, you will use a Jupyter.bat file to launch the software. You SHOULD NOT put this file on your own computer. On your own computer, you will launch Anaconda and Jupyter Lab as you would any other application you have installed.\nTo use python in the classroom, we will use the Anaconda package already installed on these computers:\n\nCreate a folder in your share space (that is, your H: drive) with a name like “python” or “CIS241”.\nDownload and save the getting_started.ipynb file linked above to that folder\nDownload the Jupyter.txt file linked here and save it to the desktop\nRename the Jupyter.txt file to Jupyter.bat\nDouble click the Jupyter.bat icon to launch Jupyter Lab\nIn the interface that appears, navigate to the folder you created with the getting_started.ipynb file in it\nClick on the getting_started.ipynb file to open it; you should see a collection of Python code and markdown comments, broken up between a number of boxes/cells\nFollow the instructions in the file to run the code and review the output"
  },
  {
    "objectID": "criteria.html",
    "href": "criteria.html",
    "title": "Criteria for Good Reports",
    "section": "",
    "text": "In this course, you’ll write data analysis reports in Jupyter notebooks, combining programming in Python with visualizations and written explanations. You’ll turn in a report for each week’s Workshop assignment, and your quizzes and final project will also take the form of Jupyter notebook reports.\nGood data analysis requires the combination of clear writing, well-functioning code, and solid quantitative reasoning. Since these reports are a new genre you are learning in this class, you can follow this list of criteria for crafting good reports. I’ll use the same criteria when I assess your work.\n\nFocus and Organization: All questions in the report are answered and all required sections are complete. Report is organized and easy to follow.\nWriting: Writing is clear, with all visualization and statistical output explained completely, accurately, and in terms of the data.\nCode: Code sections are complete and all code runs without errors. Code is well-commented and easy to read.\nStatistics & Analysis: All analysis is accurate and given in context, both in terms of the data and of the relevant statistical concepts.\nVisualization: Visualizations are clear, accurate, and well-labeled. Good visualizations should be readable on their own but also well-explained in writing.\n\nFor more on what I’m looking for in the writing, visualization, and analysis portions of the reports, you can refer to the How to Explain in CIS241 guide."
  },
  {
    "objectID": "assignments/project-proposal.html",
    "href": "assignments/project-proposal.html",
    "title": "Final Project Proposal",
    "section": "",
    "text": "Complete by: Thursday 3 Apr. at class time"
  },
  {
    "objectID": "assignments/project-proposal.html#description",
    "href": "assignments/project-proposal.html#description",
    "title": "Final Project Proposal",
    "section": "Description",
    "text": "Description\nThe purpose of the final project is to combine the core skills you have gained in the class to produce a polished report on a question of your choosing, ideally something that you’re passionate about or is relevant to your life or interests (some suggestions are offered later on).\nThis final project will incorporate all of the steps involved in the Data Analysis Cycle. You will be in charge of stating an interesting question that doesn’t duplicate previous projects or workshops, conducting exploratory analyses using skills from the entire semester, building a model that you will interpret, then communicating your key findings in a polished, professional narrative.\nRemember that the data cycle is an iterative, not linear, process. You may find that your original question must be revised to match the available data or that your data will need restructuring to match the question effectively. Further, your first prediction/explanation model might not be your final model. Consider revising the model to solidify your ability to interpret a clear finding.\nFinally, the final project will be an opportunity to practice your communication with non-technical collaborators or audience, as your conclusions should be stated in plain language that could be understood by the general public."
  },
  {
    "objectID": "assignments/project-proposal.html#choosing-your-data-and-questions",
    "href": "assignments/project-proposal.html#choosing-your-data-and-questions",
    "title": "Final Project Proposal",
    "section": "Choosing Your Data and Question(s)",
    "text": "Choosing Your Data and Question(s)\nThe question is open for you to determine, and so is the dataset. You can choose to do a project exploring any field that interests you, including (but not limited to):\n\nAnthropology\nBiology\nEconomics/Business\nHistory\nLiterature\nMusic\nPhysics\nPolitical Science\nPsychology\nPhilosophy\nSociology\nSports\nOr anything else that you’re excited about!\n\nn.b. You may choose the same dataset you wrote about in your Documentation assignment, but keep in mind many of the tips for choosing data listed below.\n\nQuestion-asking\nWe can ask questions that are closed (yes or no answer; are the two things different or not?) or open (require more thought and explanation; how much does something change? How is it related to something else?). Likewise, our data analyses can serve one or more purposes as we move through the data analysis cycle: descriptive (describes different measures of the data), exploratory (looking for patterns or unknown relationships in the data); inferential (using a sample to tell us something about a larger population); predictive (use relationships in the current/past data to predict the future); or causal (what happens to one variable when one or more other variables change?).\n\n\nMostly, choose something that you are curious about and will allow you to demonstrate the listed concepts for the project. Have some fun with it!\n\n\nWhere can I find datasets?\nThe Finding Data page of the CIS LibGuide has an extensive list of data resources, including general sites as well as repositories broken down by topic.\n\n\nHow do I choose data and organize my project?\nYour project must analyze a real-world data set, using the course concepts and materials. You should choose a topic and dataset that interests you, and come up with a main question and hypothesis that is answerable. The goal of the project includes demonstrating the breadth of techniques we learned this semester: from data wrangling, visualization, summary stats, hypothesis testing, regression, modeling, and interpretation. Readability is a major component of reports, so use headings, tables, figure captions, etc. to make it easy to follow.\nYou’ll receive a full prompt for the final project very soon. You’ll be asked to create a report that includes data wrangling, visualization, exploratory analysis, and statistical modeling techniques. The variables to include in your model are open for you to determine, as is the interpretation of the model. You should choose a dataset while keeping in mind the techniques and methods that we learned in this class. It’s a good idea to look for relatively tidy datasets that have the kinds of variables that you know how to analyze. Choosing datasets in this way will also make it easier for you to choose models and approaches later on."
  },
  {
    "objectID": "assignments/project-proposal.html#progress-checkpoints",
    "href": "assignments/project-proposal.html#progress-checkpoints",
    "title": "Final Project Proposal",
    "section": "Progress checkpoints",
    "text": "Progress checkpoints\nConsistent work and progress on your final projects, once the topic is chosen, will ensure a strong end to the semester. You will need to work on the project outside of class time to complete it to a high standard. Ask questions of your professor early and often!\nYou will receive feedback from your instructor at the project proposal and progress report stages, and these assignments should also help you focus your thoughts as your explore the dataset. The final week of class, each team will share their progress in a presentation, which you can use as a final way to fine-tune your method, message, and presentation, prior to completing the final report.\nThese checkpoints are graded and are part of your grade for the final project."
  },
  {
    "objectID": "assignments/project-proposal.html#checkpoint-1-project-proposal",
    "href": "assignments/project-proposal.html#checkpoint-1-project-proposal",
    "title": "Final Project Proposal",
    "section": "Checkpoint 1: Project Proposal",
    "text": "Checkpoint 1: Project Proposal\n1 page document stating your name, dataset (with url), and main questions, uploaded to Sakai.\nThis 1-page proposal document will contain:\n\nyour name\ndataset you will use (and hyperlink to cite source)\na list of the big research question(s) you will investigate: these should be specific. I recommend 2-4 questions that might guide you in different parts of the report.\n5-7 sentences explaining your rationale, why is this dataset and question interesting? How will the data dictate your process for problem solving? What possible approaches might you take to answer your research questions?\n\nn.b. Because we need to stay on track as the end of the semester approaches, you cannot receive an extension on any part of final project."
  },
  {
    "objectID": "assignments/presentation.html",
    "href": "assignments/presentation.html",
    "title": "Presentation",
    "section": "",
    "text": "Complete by: Tuesday 22 Apr. at class time\nYou will prepare a 3-5 minute “elevator pitch” video presentation about your project for your classmates. The goal of this video is not to summarize the entire content of your project, but rather to explain to your audience your chosen data set, the questions you have, and the approaches you plan to take it to it, in a way that will generate interest and allow others to offer suggestions.\nSpecifically, your video should meet the following guidelines:\nAudience: Your audience is the other students in this class (not just me!). Remember that they don’t know anything about your data or your research questions yet. The goal of this presentation is to explain to them what you’re trying to find out, why it matters to you, and how you will answer your questions.\nContent: Your presentation should not attempt to be a summary of your final project report. For one thing, you probably haven’t written the whole thing yet! You also shouldn’t simply read your introduction or your conclusion. This presentation should be based on content that addresses three main questions:\nYour content must reflect the expected knowledge of your audience. This means choosing your words carefully and defining technical terminology (though for this context, informal or intuitive definitions can be acceptable so long as they are not incorrect or misleading).\nFormat: Your video must be at least three minutes and may not be longer than five minutes. Note that this means that you can, and must, practice your presentation to ensure it meets these guidelines. You will make your video available through Microsoft Stream by uploading a video in a format such as an mp4 or other Stream compatible file format. Details about submitting your video are provided below.\nYou will be assessed on the content of this video and how well it addresses the Content requirements laid out above in an Audience aware manner. You will not be assessed on the production quality, so long as the audio and video are clear. Your video may simply be a recording of you talking taken through your webcam or phone camera. You may also provide an audio track over visuals if you prefer. However, your goal is to be compelling to a general student audience in an “elevator pitch” style, so do not narrate over a traditional PowerPoint with titles, bullet points, etc.\nOnce videos are posted, you’ll be expected to watch your classmate’s videos and prepare to discuss them during our class’s final exam time. More information on this step coming later."
  },
  {
    "objectID": "assignments/presentation.html#how-to-submit-a-video",
    "href": "assignments/presentation.html#how-to-submit-a-video",
    "title": "Presentation",
    "section": "How to Submit a Video",
    "text": "How to Submit a Video\n\nPlease submit videos to the OneDrive folder for our class (there is a link to the folder on Sakai).\nYou can record the video directly in Microsoft Stream or upload a compatible file to Stream/OneDrive.\nThe video will need to be in a compatible format: .mp4 is the most common, but .flv, .mxf, .gxf, .mpg, .wmv, .asf, .avi. wav, and .mov would also work.\nYou MUST click on your video to make sure it plays properly. You are responsible for ensuring that your video is posted on time and that it works when your classmates attempt to watch it."
  },
  {
    "objectID": "assignments/presentation.html#responding-to-videos",
    "href": "assignments/presentation.html#responding-to-videos",
    "title": "Presentation",
    "section": "Responding to Videos",
    "text": "Responding to Videos\nIn addition to making a video presentation, you will watch and respond to the videos made by your peers. Before the panel presentations, you will watch all the videos. After watching a video, you will write down the following for each one.\n\nOne substantive similarity between the presenter’s project and your own.\nOne question you have about the project.\nOne idea or suggestion you have for the presenter as they finish their project.\n\nBring these similarities, questions, and suggestions with you to class, and we will use them as the basis to discuss all the projects. When class is over, you can post your three items as a comment attached to your classmate’s video on Stream. I’ll read over each response and will include this as part of your presentation grade.\nRemember: the best comments are ones that are substantive and move the conversation forward. So not just “We are both working on golf data,” but “In my project, I found that one challenge with golf data was that it had mostly quantitative variables. You’re dealing with a similar challenge.” And not just “What do you plan to do next?” but “When you model your data with a random forest classifier, do you plan to limit the size of your decision trees?” These comments can be genuinely helpful feedback for your classmates, so give the feedback that you would like to receive!"
  },
  {
    "objectID": "assignments/documentation.html",
    "href": "assignments/documentation.html",
    "title": "Documentation Assignment",
    "section": "",
    "text": "Complete by: Thursday 30 Jan. at class time\nThe goal of this assignment is to get you more familiar with finding, understanding, and documenting a data set. You’ll find a dataset online and create documentation and metadata for it, using the guidelines below."
  },
  {
    "objectID": "assignments/documentation.html#finding-a-dataset",
    "href": "assignments/documentation.html#finding-a-dataset",
    "title": "Documentation Assignment",
    "section": "Finding a Dataset",
    "text": "Finding a Dataset\nYou can choose whatever data set you want so long as it comes from a reputable source (see the links below) and it’s large enough for you to write about. This should be a rectangular dataset with rows and columns, ideally available as a CSV or spreadsheet file. Try to find a data set that has a mix of numerical and categorical variables. You will turn in the original data file along with your documentation.\nYou can choose data from whatever topic you like. Remember that there are data sets out there from almost every area of study that you can imagine! Here are some ideas to get you started:\n\nAnthropology and Sociology\nBiology\nEconomics/Business\nPhysics\nPolitical Science\nPsychology\nPhilosophy\nSports Analytics\nArts & Humanities\n\nDon’t just settle for the very first dataset you find: look around a bit for interesting or unexpected ones!\nLater in the semester, you’ll choose a dataset to work on for your final project. This assignment is unrelated, so you can decide to stick with this dataset later on or choose something completely new: it’s entirely up to you.\nMostly, choose something that you are curious about and will allow you to demonstrate the listed concepts for the assignment. Have some fun with it!\n\nWhere can I find datasets?\nThe Data page of the CIS LibGuide has an extensive list of data resources, including general sites as well as repositories broken down by topic.\nYou may not choose any datasets from Kaggle or Data.world. These are general repositories that often make it more difficult to find the original collectors or purpose of the data."
  },
  {
    "objectID": "assignments/documentation.html#writing-your-documentation",
    "href": "assignments/documentation.html#writing-your-documentation",
    "title": "Documentation Assignment",
    "section": "Writing Your Documentation",
    "text": "Writing Your Documentation\nBelow is a suggested format to use to make sure the useful information is communicated to a reader or potential data user (you too!) needed to interpret and understand it. As you edit, remove any instructional or template text and replace with your own. If you have questions particular to your dataset or another idea for how to present the codebook and documentation, please discuss in advance with me.\n\nDataset Name\nData source: Name of data provider, website, and link\nOriginal data collectors: Names of people or organization\nData size: e.g. number of KB or MB\nSpecial permissions: Note if the data is freely available, published, or has restrictions for use.\n1-2 short paragraphs describing the data table(s) you plan to use. Your description should describe what one row (observation) represents, as well as any potentially “tricky” or difficult aspects of the dataset - for example, how is missing data denoted in the dataset? If the dataset already had a well-defined codebook or metadata provided that can give additional information, please link to it here. You can also mention any potential ethical issues one should be aware of when using this data.\n[n.b. You dataset may already have some written documentation when you find it. It’s okay to read that and think about it as you work, but your final paragraphs should all be in your own words.]\nName_of_your_datafile.csv\nData Dictionary:\nPlease note that if your data set has multiple data tables, you will need to provide more than one of these data dictionary tables, one for each dataset. You should make a note about which column in each dataset contains common information, and represents the “link” or the “key” between them.\n\n\n\n\n\n\n\n\n\n\n\nColumn Name\nVariable Definition\nData Type\nUnits\nVariable Codes and Ranges\nMissing Value Codes\n\n\n\n\nThe name of the column, exactly as it appears in your .csv file\nDescribe what each variable represents, and if known, how it was measured.\nSay whether the data is numerical or categorical, and give a subcategory (e.g. continuous)\nif units needed; grams, days…\nif not a continuous variable, you could list the acceptable values\nif there is missing data, indicate what is used, e.g. blank, NA, NULL, etc.\n\n\n\nAdd more rows as needed… [n.b. You only need to create a chart of 20 variables. If your data set has more than 20 variables, just choose the 20 that seem the most relevant or interesting.]\nFor Variable Definition, If you don’t know or don’t have information on how to interpret a variable, or want to give a word of caution, say so here. If the variable has any special considerations or challenges inherent to its measure, you may note that here, too.\nFor Variable Codes and Ranges, If you don’t need to specify acceptable values, you can just fill this in with NA (for not applicable).\nData Wrangling:\nWrite a paragraph explaining the wrangling steps you will need to take in order to ensure that this data is in tidy form and ready for analysis.\nThis may include: selecting a subset of the data, creating new columns, renaming existing columns, sorting data, grouping and summarizing, or even splitting columns and pivoting the table. Be sure to ask me if you have questions about what wrangling steps should be taken! You may find it easiest to attempt these wrangling steps yourself, but you do not need to submit the code for this assignment. Be specific about exactly what columns, rows, and values you should change and why.\n\nRequirements:\n\nTurn in your documentation (as a PDF) via Sakai\nFormat the documentation according to the template above\nAlso turn in the original data file that you found online (ideally a CSV)"
  },
  {
    "objectID": "sample-final-project.html",
    "href": "sample-final-project.html",
    "title": "Work Acquistion and Gender in the Museum of Modern Art",
    "section": "",
    "text": "Note to students: this sample final project includes only writing and output without code. You can export your HTML file in the usual way, but if you’d like to produce something in this format I can work with you on that. I made this file more readable using the conversion tool Quarto, but again you can simply use the standard JupyterHub HTML export if you prefer."
  },
  {
    "objectID": "sample-final-project.html#hypothesis-test",
    "href": "sample-final-project.html#hypothesis-test",
    "title": "Work Acquistion and Gender in the Museum of Modern Art",
    "section": "3.1 Hypothesis Test",
    "text": "3.1 Hypothesis Test\nNow that we’ve identified some differences between when MoMA acquired artworks by men and women, we might want to know if this difference is statistically significant. As I mentioned previously, this data contains only a subset of the artworks available in MoMA’s collection, and we further limited that dataset above by looking at only single-artist works. Are the differences we see between men and women in this data the result of randomness in our sample, or is it likely that MoMA’s collection overall has more works by women acquired more frequently.\nWe can use a permutation test to compare the mean acquired year for men and women in the MoMA data. To do so, we’ll need to define a null and alternative hypothesis:\n\\(H_0: mean(AcquiredYearMale) = mean(AcquiredYearFemale)\\)\n\\(H_1: mean(AcquiredYearMale) &lt; mean(AcquiredYearFemale)\\)\nMy null hypothesis states that there is no difference between the average year that works by men were acquired and the average year that works by women were acquired. My alternative hypothesis states that on average works by men were acquired earlier than works by women. This is a one-tailed alternative hypothesis, meaning that I am only testing in one direction. To understand why I made that choice, we can plot the difference in distributions between men and women.\n\n\n\n\n\n\n\n\n\nThis box plot shows the difference in the distributions of when artworks by men and women were acquired by the museum. The large difference between the two median lines and the different locations of the two boxes indicates that artworks by women were generally acquired more recently. Since a permutation test compares the means, we can also view this difference as a bar plot.\n\n\n\n\n\n\n\n\n\nThis bar plot shows a comparison of the means instead of the median and interquartile ranges. We can see that though the medians are more different, the means of these two groups are much closer together (indicating that some outliers may be skewing the results). However, we see very small or nonexistent confidence interval error bars on this plot. This could mean that the difference in means is statistically significant, but we will need to run a permutation test to be sure.\nSince the female acquired year average is higher (i.e. more recent) on the both the box plot and the bar plot, I’ve decided to make this a one-tailed hypothesis test. I am trying to find out: are artworks by women really acquired more recently?\n\n\n17.935649315104456\n\n\nNow that I’ve determined the guidelines for my test I can find the observed difference in means. As you can see in the code above, on average works by women are acquired 17 or 18 years later than works by men. The codeblock below creates a function for reshuffling data to create 5000 random permutations. The distribution of these permutation means are then compared to the observed difference above.\n\n\n\n\n\n\n\n\n\nThe plot above shows the permutation distribution (in white) and the observed difference in means (as a red dotted line). The permutations almost never showed a difference greater than 1 year or less than -1 year. The red line is very far way from all of the permuation data, with the entire distribution less than the observed difference in means. To complete this interpretation, we will need to calculate a p-value.\n\n\n0.0\n\n\nBy comparing the permutation data to the observed difference, we can calculate a p-value of 0.0, which is far less than the expected alpha of 0.05. In this case, \\(p&lt;0.05\\), meaning that our observed difference in means of 17 years is statistically significant. It is very unlikely to achieve this same result with a random assortment of artworks. In addition to this, though a difference of 17 years is fewer than we might expect from the exploratory data analysis above, this is also a practically significant result: 17 years is a relatively long amount of time.\nOverall, this hypothesis test has helped us to infer what the full population of data might look like. In order to understand further, it’s equally useful to use this data in a statistical model."
  },
  {
    "objectID": "sample-final-project.html#statistical-modeling-with-random-forest",
    "href": "sample-final-project.html#statistical-modeling-with-random-forest",
    "title": "Work Acquistion and Gender in the Museum of Modern Art",
    "section": "3.2 Statistical Modeling with Random Forest",
    "text": "3.2 Statistical Modeling with Random Forest\nGiven that the museum’s practices around art made by men and women are so different, we might learn more by using a statistical model to predict an artists’ gender based on the attributes of their artworks. Because I am predicting gender categories, I will need to use a classification model. I will attempt to use a few properties of both the artist and the artworks: the nationality of the artist, the year of their birth, the artwork’s height and width, the year it was made, and the year it was acquired by MoMA. (Note that here I need to use the “MadeYear” and “AcquiredYear” numerical variables that I created in my data wrangling section.) Because this is a mixed set of predictors, both numerical and categorical, I have a lot of choices. But since date-related data is more discrete than continuous, I have chosen a model type, the Random Forest, that deals well with a mix of numerical and categorical variables.\nTo begin, I will use a single decision tree to determine if I have chosen my predictors well.\n\n\n\n\n\n\n\n\n\nThis decision tree begins by splitting on the year the artwork was required. On the left side of the tree, when splitting by nationality, the tree struggles to identify any female artists. The model has more success on the right side of the tree, when splitting by date. This suggests that some predictors (features) are better than others. We can confirm this by looking at the feature importances for this tree.\n\n\nBeginYear 0.35232213487884184\nHeight (cm) 0.0\nWidth (cm) 0.0\nMadeYear 0.1075948726810155\nAcquiredYear 0.3944539331608834\nNationality_Albanian 0.0\nNationality_Algerian 0.0\nNationality_American 0.113986571086963\nNationality_Argentine 0.0\nNationality_Australian 0.0\nNationality_Austrian 0.0\nNationality_Azerbaijani 0.0\nNationality_Bahamian 0.0\nNationality_Belgian 0.0\nNationality_Beninese 0.0\nNationality_Bolivian 0.0\nNationality_Bosnian 0.0\nNationality_Brazilian 0.0\nNationality_British 0.0\nNationality_Bulgarian 0.0\nNationality_Burkinabé 0.0\nNationality_Cameroonian 0.0\nNationality_Canadian 0.0\nNationality_Canadian Inuit 0.0\nNationality_Chilean 0.0\nNationality_Chinese 0.0\nNationality_Colombian 0.0\nNationality_Congolese 0.0\nNationality_Costa Rican 0.0\nNationality_Croatian 0.0\nNationality_Cuban 0.0\nNationality_Czech 0.0\nNationality_Danish 0.0\nNationality_Dutch 0.0\nNationality_Ecuadorian 0.0\nNationality_Egyptian 0.0\nNationality_Emirati 0.0\nNationality_Estonian 0.0\nNationality_Ethiopian 0.0\nNationality_Filipino 0.0\nNationality_Finnish 0.0\nNationality_French 0.0\nNationality_Georgian 0.0\nNationality_German 0.0\nNationality_Ghanaian 0.0\nNationality_Greek 0.0\nNationality_Guatemalan 0.0\nNationality_Haitian 0.0\nNationality_Hungarian 0.0\nNationality_Hunkpapa Lakota 0.0\nNationality_Icelandic 0.0\nNationality_Indian 0.0\nNationality_Indonesian 0.0\nNationality_Iranian 0.0\nNationality_Iraqi 0.0\nNationality_Irish 0.0\nNationality_Israeli 0.0\nNationality_Italian 0.0\nNationality_Ivatan 0.0\nNationality_Ivorian 0.0\nNationality_Jamaican American 0.0\nNationality_Japanese 0.0\nNationality_Kenyan 0.0\nNationality_Korean 0.0\nNationality_Kuwaiti 0.0\nNationality_Latvian 0.0\nNationality_Lebanese 0.0\nNationality_Lithuanian 0.0\nNationality_Luxembourger 0.0\nNationality_Macedonian 0.0\nNationality_Malaysian 0.0\nNationality_Malian 0.0\nNationality_Mexican 0.0\nNationality_Moroccan 0.0\nNationality_Mozambican 0.0\nNationality_Namibian 0.0\nNationality_Nationality unknown 0.0\nNationality_Native American 0.0\nNationality_Nepali 0.0\nNationality_New Zealander 0.0\nNationality_Nicaraguan 0.0\nNationality_Nigerian 0.0\nNationality_Norwegian 0.0\nNationality_Oneida 0.0\nNationality_Pakistani 0.0\nNationality_Panamanian 0.0\nNationality_Paraguayan 0.0\nNationality_Peruvian 0.0\nNationality_Polish 0.0\nNationality_Portuguese 0.0\nNationality_Puerto Rican 0.0\nNationality_Romanian 0.0\nNationality_Russian 0.03164248819229636\nNationality_Salvadoran 0.0\nNationality_Scottish 0.0\nNationality_Senegalese 0.0\nNationality_Serbian 0.0\nNationality_Sierra Leonean 0.0\nNationality_Singaporean 0.0\nNationality_Slovak 0.0\nNationality_Slovenian 0.0\nNationality_South African 0.0\nNationality_South Korean 0.0\nNationality_Spanish 0.0\nNationality_Sri Lankan 0.0\nNationality_Sudanese 0.0\nNationality_Swedish 0.0\nNationality_Swiss 0.0\nNationality_Syrian 0.0\nNationality_Taiwanese 0.0\nNationality_Tanzanian 0.0\nNationality_Thai 0.0\nNationality_Turkish 0.0\nNationality_Ugandan 0.0\nNationality_Ukrainian 0.0\nNationality_Uruguayan 0.0\nNationality_Venezuelan 0.0\nNationality_Welsh 0.0\nNationality_Zimbabwean 0.0\n\n\nThe list above shows all the feature importances for the predictors we chose (with the categorical predictor nationality split into its individual dummy variables). The list suggests that the dimension of an artwork (height and width) as well as the nationality of the artist aren’t especially predictive of the artists’ gender in this model. This is a little surprising based on what we discovered about the height of artworks in our exploratory section, but it also logically follows that the gender of the artist wouldn’t affect the shape of the artwork, nor would it have any affect on their nationalities.\nHowever, there’s a problem with this model based on something we already observed in the exploratory section!\n\n\nGender\nmale      120979\nfemale     19608\nName: count, dtype: int64\n\n\nThere are more than 5 times as many male artists in our data than female artists! This will create a rare class problem: any model built on this data will get high accuracy simply by guessing the artist is male every time. To remedy this, I will include some oversampling of the female artists’ data in my training set. Note: this oversampling would typically only occur in the training set, but I have oversampled both the training and test set to simplify the code. This approach will use bootstrap sampling to create a large set of female artists to identify.\n\n\nGender\nmale      111992\nfemale    111992\nName: count, dtype: int64\n\n\nNow we’re ready to continue our modeling code. This will be more reliable than my original model, which had very high precision but low recall.\n\n\nRandomForestClassifier(max_leaf_nodes=20, random_state=42)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestClassifierRandomForestClassifier(max_leaf_nodes=20, random_state=42)\n\n\n\n\n\n\n\n\n\n\n\nfemale\nmale\n\n\n\n\n0\n0.230055\n0.769945\n\n\n1\n0.368141\n0.631859\n\n\n2\n0.112075\n0.887925\n\n\n3\n0.130142\n0.869858\n\n\n4\n0.566794\n0.433206\n\n\n...\n...\n...\n\n\n67191\n0.578679\n0.421321\n\n\n67192\n0.785041\n0.214959\n\n\n67193\n0.446660\n0.553340\n\n\n67194\n0.092276\n0.907724\n\n\n67195\n0.315962\n0.684038\n\n\n\n\n67196 rows × 2 columns\n\n\n\nAfter setting up the random forest classifier and examining the predicted probabilities above, I am reasonably confident in this model. While some of the probabilites show about a 50-50 split in the model’s certainty that an artist is a man or a woman, a lot of the visible probabilities in this list are 60% and above for one of the two categories. This may indicate that our validation (below) will show an accurate model.\n\n\nBeginYear 0.3626260091372285\nMadeYear 0.290751730703907\nAcquiredYear 0.34662226015886444\n\n\nAs I suggested previously, reducing to just these three predictors has left us with relatively high feature importances across the board. This tells us a lot about our data, since it suggests that it’s possible to predict the gender of the artist whose work is in MoMA based only on three dates: when the artist was born, when their artwork was made, and when the artwork was acquired. There’s clearly a pattern in MoMA’s collection practices.\n\n\n\n\n\n\n\n\n\nThe confusing matrix above shows the predicted responses for all the data in our test set. As we observed in the predicted probabilities, the model seemed to do a decent job at predicting artists of both genders. There are many more true positives (in the top left) and true negatives (in bottom right) than there are false positives and false negatives. However, there are still a lot of false predictions (more than 15,000), indicating that our model could have even better performance.\n\n\n              precision    recall  f1-score   support\n\n      female       0.76      0.78      0.77     33571\n        male       0.77      0.75      0.76     33625\n\n    accuracy                           0.76     67196\n   macro avg       0.76      0.76      0.76     67196\nweighted avg       0.76      0.76      0.76     67196\n\n\n\nIn the classfication report above, you can see that overall our model is \\(76\\%\\) accurate, with similar precision for both categories (\\(75\\%\\) for women and \\(76\\%\\) for men), and similar recall as well (\\(77\\%\\) for women and \\(75\\) for men). This is much better than my original model before dealing with the rare class problem, which had precision for men in the 90s but recall only around \\(10\\%\\).\n\n\n\n\n\n\n\n\n\nBecause this is a binary classifier, we can also create an ROC curve. The ROC curve above confirms the overall accuracy of the model: there is a consistent curved line that takes up most of the graph. Area under the curve (AUC) is \\(85\\%\\), which indicates that the true positive rate for our model is higher than the false positive rate. The last thing to determine is whether our model’s accuracy in this split of the data will remain at ~\\(75\\%\\) after cross-validation.\n\n\n0.7 accuracy with standard deviation 0.11\n\n\nIn the code above I ran 5-fold cross-validation, splitting the data differently each time to reserve different data for testing. Across these runs, I got an average of \\(70\\%\\) accuracy, which is not as high as my original run but not bad for a first attempt at building a classifier. The standard deviation was a moderate \\(0.11\\), suggesting that there’s some variance in the results that might be reduced in a better model."
  },
  {
    "objectID": "slides/visualizing.html#visualization-can-be-exploratory-explanatory-or-both",
    "href": "slides/visualizing.html#visualization-can-be-exploratory-explanatory-or-both",
    "title": "Visualizing Data",
    "section": "Visualization can be exploratory, explanatory, or both!",
    "text": "Visualization can be exploratory, explanatory, or both!\n\nExploratory viz helps us (the researchers or analysts) understand the data.\nExplanatory viz helps others (the clients or audience) understand our analysis.\nMany visualizations do both of these things at once!"
  },
  {
    "objectID": "slides/visualizing.html#some-good-resources-on-visualization",
    "href": "slides/visualizing.html#some-good-resources-on-visualization",
    "title": "Visualizing Data",
    "section": "Some Good Resources on Visualization",
    "text": "Some Good Resources on Visualization\n\nClaus Wilke’s Fundamentals of Data Visualzation (The illustrations in this slide show come from here!)\nThe Altair User Guide"
  },
  {
    "objectID": "slides/visualizing.html#viz-can-help-us-see-amounts.",
    "href": "slides/visualizing.html#viz-can-help-us-see-amounts.",
    "title": "Visualizing Data",
    "section": "Viz Can Help Us See Amounts.",
    "text": "Viz Can Help Us See Amounts.\n\nGraph a single value across one set of categories.\nVariable types: 1 categorical and 1 numerical\nCommon graph types: Bar plot (Don’t confuse the dot plot with the scatter plot!)"
  },
  {
    "objectID": "slides/visualizing.html#plot-amounts-with-multiple-categories.",
    "href": "slides/visualizing.html#plot-amounts-with-multiple-categories.",
    "title": "Visualizing Data",
    "section": "Plot Amounts With Multiple Categories.",
    "text": "Plot Amounts With Multiple Categories.\n\n\nVariable types: 2 or more categorical, 1 numerical\nCommon graph types: Grouped or stacked bar, heat map"
  },
  {
    "objectID": "slides/visualizing.html#viz-can-help-us-see-distributions.",
    "href": "slides/visualizing.html#viz-can-help-us-see-distributions.",
    "title": "Visualizing Data",
    "section": "Viz Can Help Us See Distributions.",
    "text": "Viz Can Help Us See Distributions.\n\nGraph a distribution of a single variable.\nVariable type: 1 continuous (numerical)\nCommon graph types: Histograms, Density plots, Q-Q plots"
  },
  {
    "objectID": "slides/visualizing.html#distributions-with-multiple-categories.",
    "href": "slides/visualizing.html#distributions-with-multiple-categories.",
    "title": "Visualizing Data",
    "section": "Distributions with Multiple Categories.",
    "text": "Distributions with Multiple Categories.\n\n\nVariable types: 1 continuous (numerical), 1 categorical\nCommon graph types: Box plots, Violin plots"
  },
  {
    "objectID": "slides/visualizing.html#you-try-it",
    "href": "slides/visualizing.html#you-try-it",
    "title": "Visualizing Data",
    "section": "You Try It!",
    "text": "You Try It!\nLook at the taxis data set. What visualization type would you use to compare the counts of each destination Borough? Which variables would you use, and what kind of variables are they? Jot down your answers."
  },
  {
    "objectID": "slides/visualizing.html#viz-can-help-us-see-proportions.",
    "href": "slides/visualizing.html#viz-can-help-us-see-proportions.",
    "title": "Visualizing Data",
    "section": "Viz Can Help Us See Proportions.",
    "text": "Viz Can Help Us See Proportions.\n\n\nVariable types: 1 numerical, 1 categorical\nCommon graph types: Pie chart, Bar plot"
  },
  {
    "objectID": "slides/visualizing.html#viz-can-help-us-see-relationships.",
    "href": "slides/visualizing.html#viz-can-help-us-see-relationships.",
    "title": "Visualizing Data",
    "section": "Viz Can Help Us See Relationships.",
    "text": "Viz Can Help Us See Relationships.\n\n\nVariable types: 2 continuous (numerical), (3 in a bubble chart)\nCommon graph types: Scatter plot, Bubble Chart, Hex bins, Density contours"
  },
  {
    "objectID": "slides/visualizing.html#you-try-it-1",
    "href": "slides/visualizing.html#you-try-it-1",
    "title": "Visualizing Data",
    "section": "You Try It!",
    "text": "You Try It!\nLook at the taxis data again. What visualization type would you use to compare the distribution of tips among different taxi colors? Which variables would you use, and what kind of variables are they? Jot down your answers."
  },
  {
    "objectID": "slides/visualizing.html#viz-helps-us-see-time-location-uncertainty",
    "href": "slides/visualizing.html#viz-helps-us-see-time-location-uncertainty",
    "title": "Visualizing Data",
    "section": "Viz Helps Us See Time, Location, Uncertainty…",
    "text": "Viz Helps Us See Time, Location, Uncertainty…\n\nConfidence bands are an example of visualized uncertainty.More on these viz types in future lessons!"
  },
  {
    "objectID": "slides/visualizing.html#altair-is-declarative.",
    "href": "slides/visualizing.html#altair-is-declarative.",
    "title": "Visualizing Data",
    "section": "Altair is declarative.",
    "text": "Altair is declarative.\n\nYou use the Grammar of Graphics approach to declare the parts of the visualization.\nFocus on what you want to show rather than how to make it appear.\nBuilds on Vega-Lite, works similarly to ggplot2 and Tableau"
  },
  {
    "objectID": "slides/visualizing.html#importing-altair",
    "href": "slides/visualizing.html#importing-altair",
    "title": "Visualizing Data",
    "section": "Importing Altair",
    "text": "Importing Altair\nimport altair as alt\nalt.data_transformers.enable(\"vegafusion\")\nIn addition to importing, use the VegaFusion Data Transformer for large datasets."
  },
  {
    "objectID": "slides/visualizing.html#you-try-it-2",
    "href": "slides/visualizing.html#you-try-it-2",
    "title": "Visualizing Data",
    "section": "You Try It!",
    "text": "You Try It!\nUse the Altair Cheatsheet to create a plot comparing the high temperature in Seattle to the wind speed using the seattle_weather DataFrame. Then create the same plot but show color as the type of weather.\nfrom vega_datasets import data\n\nseattle_weather = data.seattle_weather()\nIf this is hard to read, you might also show the types of weather as separate columns."
  },
  {
    "objectID": "slides/visualizing.html#you-try-it-3",
    "href": "slides/visualizing.html#you-try-it-3",
    "title": "Visualizing Data",
    "section": "You Try It!",
    "text": "You Try It!\nCreate a plot showing the distribution of precipitation in the seattle_weather dataset. Give the plot a title and labels for both axes. Then show the distributions according to each pickup borough, in different columns. Finally, change the size or number of the bins in each distribution to show more detail (narrower bars).\nHint: you may need to use the Altair User Guide as well as the cheatsheet to accomplish this!"
  },
  {
    "objectID": "slides/visualizing.html#more-examples-of-bad-viz",
    "href": "slides/visualizing.html#more-examples-of-bad-viz",
    "title": "Visualizing Data",
    "section": "More Examples of Bad Viz",
    "text": "More Examples of Bad Viz\nviz.wtf\nr/dataisugly"
  },
  {
    "objectID": "slides/randomforest.html#a-tree-model-is-a-set-of-rules-to-split-data-into-different-categories.",
    "href": "slides/randomforest.html#a-tree-model-is-a-set-of-rules-to-split-data-into-different-categories.",
    "title": "Decision Trees 🌳 and the Random Forest 🌳🌲🌳🌲",
    "section": "A tree model is a set of rules to split data into different categories.",
    "text": "A tree model is a set of rules to split data into different categories."
  },
  {
    "objectID": "slides/randomforest.html#decision-trees-are-trained-using-recursive-partitioning.",
    "href": "slides/randomforest.html#decision-trees-are-trained-using-recursive-partitioning.",
    "title": "Decision Trees 🌳 and the Random Forest 🌳🌲🌳🌲",
    "section": "Decision trees are trained using recursive partitioning.",
    "text": "Decision trees are trained using recursive partitioning.\nLet’s find out more from the sklearn documentation."
  },
  {
    "objectID": "slides/randomforest.html#using-the-documentation-and-plot_tree-lets-fit-a-tree-model-predicting-species-and-recreate-this-plot.",
    "href": "slides/randomforest.html#using-the-documentation-and-plot_tree-lets-fit-a-tree-model-predicting-species-and-recreate-this-plot.",
    "title": "Decision Trees 🌳 and the Random Forest 🌳🌲🌳🌲",
    "section": "Using the documentation and plot_tree(), let’s fit a tree model predicting species and recreate this plot.",
    "text": "Using the documentation and plot_tree(), let’s fit a tree model predicting species and recreate this plot."
  },
  {
    "objectID": "slides/randomforest.html#decision-trees-create-nodes-branching-rules-based-on-optimal-split-values.",
    "href": "slides/randomforest.html#decision-trees-create-nodes-branching-rules-based-on-optimal-split-values.",
    "title": "Decision Trees 🌳 and the Random Forest 🌳🌲🌳🌲",
    "section": "Decision Trees create nodes (branching rules) based on optimal split values.",
    "text": "Decision Trees create nodes (branching rules) based on optimal split values."
  },
  {
    "objectID": "slides/randomforest.html#tree-models-can-be-used-as-both-classifiers-and-regressors.",
    "href": "slides/randomforest.html#tree-models-can-be-used-as-both-classifiers-and-regressors.",
    "title": "Decision Trees 🌳 and the Random Forest 🌳🌲🌳🌲",
    "section": "Tree models can be used as both classifiers and regressors.",
    "text": "Tree models can be used as both classifiers and regressors.\nBut we will focus on their more common use as classifiers!"
  },
  {
    "objectID": "slides/randomforest.html#decision-trees-can-help-you-determine-which-predictors-features-are-most-important.",
    "href": "slides/randomforest.html#decision-trees-can-help-you-determine-which-predictors-features-are-most-important.",
    "title": "Decision Trees 🌳 and the Random Forest 🌳🌲🌳🌲",
    "section": "Decision Trees can help you determine which predictors (features) are most important.",
    "text": "Decision Trees can help you determine which predictors (features) are most important.\nThis is referred to as “variable (or feature) importance” and takes advantage of decision trees’ skill at finding patterns in the data."
  },
  {
    "objectID": "slides/randomforest.html#trees-can-find-hidden-patterns-and-help-you-interpret-interactions-between-variables.",
    "href": "slides/randomforest.html#trees-can-find-hidden-patterns-and-help-you-interpret-interactions-between-variables.",
    "title": "Decision Trees 🌳 and the Random Forest 🌳🌲🌳🌲",
    "section": "Trees can find hidden patterns and help you interpret interactions between variables.",
    "text": "Trees can find hidden patterns and help you interpret interactions between variables.\nBut they are not so reliable one-at-a-time, and often cause overfitting. We need to think about the bias-variance tradeoff!"
  },
  {
    "objectID": "slides/randomforest.html#to-get-more-accurate-predictions-its-best-to-use-many-trees-together.",
    "href": "slides/randomforest.html#to-get-more-accurate-predictions-its-best-to-use-many-trees-together.",
    "title": "Decision Trees 🌳 and the Random Forest 🌳🌲🌳🌲",
    "section": "To get more accurate predictions, it’s best to use many trees together.",
    "text": "To get more accurate predictions, it’s best to use many trees together.\nAnd what do you call a lot of trees? A forest!"
  },
  {
    "objectID": "slides/randomforest.html#the-random-forest-is-an-ensemble-method.",
    "href": "slides/randomforest.html#the-random-forest-is-an-ensemble-method.",
    "title": "Decision Trees 🌳 and the Random Forest 🌳🌲🌳🌲",
    "section": "The random forest is an ensemble method.",
    "text": "The random forest is an ensemble method.\nYou can see all the metaphors here: a forest, a musical ensemble, etc.\nThe decision trees are put together using “bagging”: bootstrap aggregating."
  },
  {
    "objectID": "slides/randomforest.html#for-both-decision-trees-and-random-forest-pay-attention-to-your-models-hyperparameters.",
    "href": "slides/randomforest.html#for-both-decision-trees-and-random-forest-pay-attention-to-your-models-hyperparameters.",
    "title": "Decision Trees 🌳 and the Random Forest 🌳🌲🌳🌲",
    "section": "For both decision trees and random forest, pay attention to your model’s hyperparameters.",
    "text": "For both decision trees and random forest, pay attention to your model’s hyperparameters.\n\nmin_samples_leaf: the minimum number of records in a terminal node (leaf)\nmax_leaf_nodes: the maximum number of nodes in the entire tree\nsplitter and criterion: the kind of trees you will create\n\nSetting these can help you create smaller trees and avoid spurious results!"
  },
  {
    "objectID": "slides/randomforest.html#section",
    "href": "slides/randomforest.html#section",
    "title": "Decision Trees 🌳 and the Random Forest 🌳🌲🌳🌲",
    "section": "???",
    "text": "???\nBy now, you’re equipped to find out how to do this on your own, so let’s try an example.\nHere’s a hint:\nfrom sklearn.ensemble import RandomForestClassifier"
  },
  {
    "objectID": "slides/randomforest.html#create-a-random-forest-classifier-for-the-penguins-dataset.-good-luck",
    "href": "slides/randomforest.html#create-a-random-forest-classifier-for-the-penguins-dataset.-good-luck",
    "title": "Decision Trees 🌳 and the Random Forest 🌳🌲🌳🌲",
    "section": "Create a Random Forest Classifier for the penguins dataset. Good luck! 🌲🌳🌲🌳",
    "text": "Create a Random Forest Classifier for the penguins dataset. Good luck! 🌲🌳🌲🌳\n\nJust like the Decision Tree, you will predict the species of the penguins.\nUse what you learned from the Decision Tree to determine your predictors and hyperparameters!\nFit a random forest classification model.\nDo some out-of-sample validation of your model, using the usual metrics."
  },
  {
    "objectID": "slides/logit.html#how-do-we-predict-a-category",
    "href": "slides/logit.html#how-do-we-predict-a-category",
    "title": "Logistic Regression",
    "section": "How do we predict a category?",
    "text": "How do we predict a category?\nLogistic Regression is our first classification method."
  },
  {
    "objectID": "slides/logit.html#logistic-regression-is-a-linear-model.",
    "href": "slides/logit.html#logistic-regression-is-a-linear-model.",
    "title": "Logistic Regression",
    "section": "Logistic regression is a linear model.",
    "text": "Logistic regression is a linear model.\n\nImage via Towards Data Science, Data Camp"
  },
  {
    "objectID": "slides/logit.html#instead-of-predicting-a-value-we-predict-the-probability-of-a-category.",
    "href": "slides/logit.html#instead-of-predicting-a-value-we-predict-the-probability-of-a-category.",
    "title": "Logistic Regression",
    "section": "Instead of predicting a value, we predict the probability of a category.",
    "text": "Instead of predicting a value, we predict the probability of a category."
  },
  {
    "objectID": "slides/logit.html#traditional-logistic-regression-is-a-binary-classifier.",
    "href": "slides/logit.html#traditional-logistic-regression-is-a-binary-classifier.",
    "title": "Logistic Regression",
    "section": "Traditional logistic regression is a binary classifier.",
    "text": "Traditional logistic regression is a binary classifier."
  },
  {
    "objectID": "slides/logit.html#lets-create-a-model-to-classify-penguins-by-species.",
    "href": "slides/logit.html#lets-create-a-model-to-classify-penguins-by-species.",
    "title": "Logistic Regression",
    "section": "Let’s create a model to classify penguins by species.",
    "text": "Let’s create a model to classify penguins by species.\nFirst, load in the penguins dataset in Seaborn.\npenguins = pd.read_csv(\"https://jrladd.com/CIS241/data/penguins.csv\")\nNow create a scatter plot showing two numeric variables from this dataset, using the species variable as different colors for the dots."
  },
  {
    "objectID": "slides/logit.html#make-this-about-just-two-variables.",
    "href": "slides/logit.html#make-this-about-just-two-variables.",
    "title": "Logistic Regression",
    "section": "Make this about just two variables.",
    "text": "Make this about just two variables.\nWe will learn to train a multiclass logistic regression later. For now, we should filter our data so we have just two variables. Let’s create a gentoo_chinstrap dataframe that has just those two species."
  },
  {
    "objectID": "slides/logit.html#now-lets-select-some-predictors.",
    "href": "slides/logit.html#now-lets-select-some-predictors.",
    "title": "Logistic Regression",
    "section": "Now let’s select some predictors.",
    "text": "Now let’s select some predictors.\nMake a pairplot showing the relationship between all the numerical variables in this dataset. Also visualize the correlation matrix for the same variables.\nDo we have any multicollinearity here? What should we do about it?"
  },
  {
    "objectID": "slides/logit.html#split-the-data-into-training-and-test-sets.",
    "href": "slides/logit.html#split-the-data-into-training-and-test-sets.",
    "title": "Logistic Regression",
    "section": "Split the data into training and test sets.",
    "text": "Split the data into training and test sets.\nThis works just like it did for linear regression. We don’t have any categorical predictors this time, but that would be the same too.\nRun the train_test_split function now. What should you use as a test size?"
  },
  {
    "objectID": "slides/logit.html#fit-a-logistic-regression-model",
    "href": "slides/logit.html#fit-a-logistic-regression-model",
    "title": "Logistic Regression",
    "section": "Fit a logistic regression model",
    "text": "Fit a logistic regression model\n# We need a different class from sklearn\nfrom sklearn.linear_model import LogisticRegression\n\n# See next slide for discussion of parameters\nlogit_model = LogisticRegression(penalty=None, \n                                 solver='lbfgs', \n                                 random_state=42)\nlogit_model.fit(X_train, y_train)\nDo you need to drop null values?"
  },
  {
    "objectID": "slides/logit.html#setting-model-parameters",
    "href": "slides/logit.html#setting-model-parameters",
    "title": "Logistic Regression",
    "section": "Setting model parameters",
    "text": "Setting model parameters\n\npenalty: By default, scikit-learn regularizes your predictors. This could lead to unpredictable results for non-normalized data! For now, always set this to ‘none’.\nsolver: This is the underlying algorithm scikit-learn will use to calculate the coefficients. The lbfgs solver is the default and is good for small datasets.\nrandom_state: As in train_test_split, this should always be set to ensure repeatability.\n\nFor more on this, read Scikit-learns Defaults Are Wrong."
  },
  {
    "objectID": "slides/logit.html#we-can-print-the-intercept-and-the-coefficents-just-like-in-linear-regression.",
    "href": "slides/logit.html#we-can-print-the-intercept-and-the-coefficents-just-like-in-linear-regression.",
    "title": "Logistic Regression",
    "section": "We can print the intercept and the coefficents, just like in linear regression.",
    "text": "We can print the intercept and the coefficents, just like in linear regression.\nprint(f\"Intercept: {logit_model.intercept_[0]:.3f}\")\nprint(\"Coefficients:\")\nfor name, coef in zip(X_train.columns, logit_model.coef_[0]):\n    print(f\"\\t{name}: {coef:.4f}\")\nHow do the odds change for each unit of the predictor?"
  },
  {
    "objectID": "slides/logit.html#instead-of-predicting-a-value-we-can-predict-the-probability-that-our-new-data-will-fall-into-category.",
    "href": "slides/logit.html#instead-of-predicting-a-value-we-can-predict-the-probability-that-our-new-data-will-fall-into-category.",
    "title": "Logistic Regression",
    "section": "Instead of predicting a value, we can predict the probability that our new data will fall into category.",
    "text": "Instead of predicting a value, we can predict the probability that our new data will fall into category.\n# We can get prediction probabilities\nprobabilities = logit_model.predict_proba(X_test)\n# We can get the predictions themselves\npredictions = logit_model.predict(X_test)\n# We can get the categories or classes we predicted\ncategories = logit_model.classes_\n\n# Let's make the probabilities look nicer\nprobabilities = pd.DataFrame(probabilities, columns=categories)\nprobabilities"
  },
  {
    "objectID": "slides/logit.html#there-is-no-rmse-or-r2-for-logistic-regression.",
    "href": "slides/logit.html#there-is-no-rmse-or-r2-for-logistic-regression.",
    "title": "Logistic Regression",
    "section": "There is no RMSE or \\(R^{2}\\) for logistic regression.",
    "text": "There is no RMSE or \\(R^{2}\\) for logistic regression.\nSo how do we assess our model instead?"
  },
  {
    "objectID": "slides/logit.html#we-need-another-set-of-metric-functions",
    "href": "slides/logit.html#we-need-another-set-of-metric-functions",
    "title": "Logistic Regression",
    "section": "We need another set of metric functions",
    "text": "We need another set of metric functions\n# Add cross_val_score to your train_test_split line\nfrom sklearn.model_selection import train_test_split, cross_val_score\n# These replace the r-squared score and RMSE\n# You could put these all on one line\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metric import RocCurveDisplay\n\n# You'll also need matplotlib this time\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "slides/logit.html#validate-classifiers-with-the-confusion-matrix.",
    "href": "slides/logit.html#validate-classifiers-with-the-confusion-matrix.",
    "title": "Logistic Regression",
    "section": "Validate classifiers with the confusion matrix.",
    "text": "Validate classifiers with the confusion matrix.\n\nConfusion matrix for our penguin model."
  },
  {
    "objectID": "slides/logit.html#from-the-confusion-matrix-we-get-scores-for-our-model.",
    "href": "slides/logit.html#from-the-confusion-matrix-we-get-scores-for-our-model.",
    "title": "Logistic Regression",
    "section": "From the confusion matrix, we get scores for our model.",
    "text": "From the confusion matrix, we get scores for our model.\n\naccuracy: the proportion of cases classified correctly\nprecision: the proportion of predicted values that are correct\nrecall: the proportion of all values that are correctly classified\nspecificity: the recall score for the other category"
  },
  {
    "objectID": "slides/logit.html#calculating-these-scores-is-simple-in-scikit-learn.",
    "href": "slides/logit.html#calculating-these-scores-is-simple-in-scikit-learn.",
    "title": "Logistic Regression",
    "section": "Calculating these scores is simple in scikit-learn.",
    "text": "Calculating these scores is simple in scikit-learn.\n# You must use print to make this readable\nprint(classification_report(y_test, predictions))\nThere are individual functions for these, too."
  },
  {
    "objectID": "slides/logit.html#cross-validation-lets-you-compare-multiple-runs-of-the-model-with-different-training-data.",
    "href": "slides/logit.html#cross-validation-lets-you-compare-multiple-runs-of-the-model-with-different-training-data.",
    "title": "Logistic Regression",
    "section": "Cross-validation lets you compare multiple runs of the model with different training data.",
    "text": "Cross-validation lets you compare multiple runs of the model with different training data.\nscores = cross_val_score(logit_model, X, y, cv=5)\nprint(f\"{scores.mean():.2} accuracy with standard deviation {scores.std():.2}\")"
  },
  {
    "objectID": "slides/logit.html#plot-the-models-recall-with-the-roc-curve.",
    "href": "slides/logit.html#plot-the-models-recall-with-the-roc-curve.",
    "title": "Logistic Regression",
    "section": "Plot the model’s recall with the ROC Curve.",
    "text": "Plot the model’s recall with the ROC Curve.\nThis only works for binary classifiers!\n# Create our ROC Curve plot\nRocCurveDisplay.from_predictions(y_test,\n                                 probabilities[categories[0]],\n                                 pos_label=categories[0])\n\n# Draw a green line for 0\nplt.plot([0, 1], [0, 1], color = 'g')\nROC: Receiver Operating Characteristics"
  },
  {
    "objectID": "slides/logit.html#another-helpful-measure-is-the-area-under-the-roc-curve-auc.",
    "href": "slides/logit.html#another-helpful-measure-is-the-area-under-the-roc-curve-auc.",
    "title": "Logistic Regression",
    "section": "Another helpful measure is the area under the ROC curve (AUC).",
    "text": "Another helpful measure is the area under the ROC curve (AUC).\nThis measure is written right on the ROC Curve plot!"
  },
  {
    "objectID": "slides/hypothesis.html#sample-population",
    "href": "slides/hypothesis.html#sample-population",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "Sample & Population",
    "text": "Sample & Population\n\nA sample is the data we actually have, some subset of all possible data.\nThe population is the full data, the entire thing. (It’s usually impossible to collect it all.)"
  },
  {
    "objectID": "slides/hypothesis.html#hypothesis-tests-help-us-to-know-if-the-observed-statistic-in-the-sample-is-the-result-of-random-chance.",
    "href": "slides/hypothesis.html#hypothesis-tests-help-us-to-know-if-the-observed-statistic-in-the-sample-is-the-result-of-random-chance.",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "Hypothesis tests help us to know if the observed statistic in the sample is the result of random chance.",
    "text": "Hypothesis tests help us to know if the observed statistic in the sample is the result of random chance.\nHypothesis tests protect researchers from being fooled by random chance!"
  },
  {
    "objectID": "slides/hypothesis.html#hypothesis-tests-can-be-used-to-test-many-different-statistics-and-relationships-in-your-data.",
    "href": "slides/hypothesis.html#hypothesis-tests-can-be-used-to-test-many-different-statistics-and-relationships-in-your-data.",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "Hypothesis tests can be used to test many different statistics and relationships in your data.",
    "text": "Hypothesis tests can be used to test many different statistics and relationships in your data.\n\nMeans: is the average you calculated in the sample representative of the full population?\nCorrelation: is the relationship between two variables in the sample the same in the full population?\nYou can use virtually any test statistic that you want, if you set up your test correctly.\nToday we’re working on means, and next week we’ll work on correlation."
  },
  {
    "objectID": "slides/hypothesis.html#lets-consider-an-example-for-comparison-of-means",
    "href": "slides/hypothesis.html#lets-consider-an-example-for-comparison-of-means",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "Let’s consider an example for comparison of means:",
    "text": "Let’s consider an example for comparison of means:\n\nYou have two species of penguin, and you want to know which species has “deeper” (i.e. taller) bills.\nYou get a sample of penguins from both species, and you calculate the mean “bill depth” for each. Now you know what the difference in means is, and which penguins have deeper bills in your sample."
  },
  {
    "objectID": "slides/hypothesis.html#looking-at-the-sample-distribution-in-means-the-observed-difference",
    "href": "slides/hypothesis.html#looking-at-the-sample-distribution-in-means-the-observed-difference",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "Looking at the sample distribution in means, the observed difference:",
    "text": "Looking at the sample distribution in means, the observed difference:\n\n\n\n\n\n\n\n\n\n\n\nThe mean depth of Chinstrap penguin bills is 18.42mm, and the mean depth of Adelie penguin bills is 18.35mm. The observed difference in means is 0.074mm. Does that mean Chinstrap penguins really have taller bills?"
  },
  {
    "objectID": "slides/hypothesis.html#example-cont.",
    "href": "slides/hypothesis.html#example-cont.",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "Example (cont.)",
    "text": "Example (cont.)\n\nBut you’re not sure whether this is true in the population, so you want to compare your difference in means to a random model that makes assumptions about what bill depth should look like.\nIf your observed difference of means from the sample is significantly different from the random model’s means, then you know your initial result holds up, and you have a better idea of what the population will look like."
  },
  {
    "objectID": "slides/hypothesis.html#comparing-the-observed-difference-to-a-random-model",
    "href": "slides/hypothesis.html#comparing-the-observed-difference-to-a-random-model",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "Comparing the observed difference to a random model:",
    "text": "Comparing the observed difference to a random model:\n\n\n\n\n\n\n\n\n\n\n\nIf we assume there’s no difference between the two species’ bills in our random model, then we can see that our observed difference is not far from the assumed mean of 0. In this case, more than 30% of our data could be “more extreme” than this result!"
  },
  {
    "objectID": "slides/hypothesis.html#the-null-hypothesis-is-a-baseline-assumption-that-the-result-is-due-to-chance.",
    "href": "slides/hypothesis.html#the-null-hypothesis-is-a-baseline-assumption-that-the-result-is-due-to-chance.",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "The Null Hypothesis is a baseline assumption that the result is due to chance.",
    "text": "The Null Hypothesis is a baseline assumption that the result is due to chance."
  },
  {
    "objectID": "slides/hypothesis.html#the-null-hypothesis-often-assumes-equality.",
    "href": "slides/hypothesis.html#the-null-hypothesis-often-assumes-equality.",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "The Null Hypothesis often assumes equality.",
    "text": "The Null Hypothesis often assumes equality.\nIn a comparison of means test, the null hypothesis would assume that the means of Adelie and Chinstrap bill depth are equal, that there is no difference between them, and that any observed difference we see is the result of randomness."
  },
  {
    "objectID": "slides/hypothesis.html#in-a-hypothesis-test-we-try-to-prove-the-null-hypothesis-wrong.",
    "href": "slides/hypothesis.html#in-a-hypothesis-test-we-try-to-prove-the-null-hypothesis-wrong.",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "In a hypothesis test, we try to prove the null hypothesis wrong.",
    "text": "In a hypothesis test, we try to prove the null hypothesis wrong.\nWe attempt to disprove the null hypothesis by showing that the observed data isn’t the result of randomness. This is a reductio ad absurdum."
  },
  {
    "objectID": "slides/hypothesis.html#the-alternative-hypothesis-accounts-for-all-possibilities-that-arent-the-null-hypothesis.",
    "href": "slides/hypothesis.html#the-alternative-hypothesis-accounts-for-all-possibilities-that-arent-the-null-hypothesis.",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "The Alternative Hypothesis accounts for all possibilities that aren’t the Null Hypothesis.",
    "text": "The Alternative Hypothesis accounts for all possibilities that aren’t the Null Hypothesis.\nIf there’s a null hypothesis, there has to be an alternative hypothesis.\nIf the null hypothesis is that A and B are equal, then the alternative hypothesis would be that A and B are not equal (either smaller or bigger)."
  },
  {
    "objectID": "slides/hypothesis.html#the-alternative-hypothesis-can-be-one--or-two-tailed.",
    "href": "slides/hypothesis.html#the-alternative-hypothesis-can-be-one--or-two-tailed.",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "The Alternative Hypothesis can be One- or Two-Tailed.",
    "text": "The Alternative Hypothesis can be One- or Two-Tailed.\n\nOne-tailed: We only care about a non-equal result in one direction, i.e. if A &gt; B but not if A &lt; B.\nTwo-tailed: We care about differences in both directions, i.e. A != B but could be larger or smaller.\n\nDifferent research questions lead to different alternative hypotheses."
  },
  {
    "objectID": "slides/hypothesis.html#what-are-the-null-and-alternative-hypotheses",
    "href": "slides/hypothesis.html#what-are-the-null-and-alternative-hypotheses",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "What are the Null and Alternative Hypotheses?",
    "text": "What are the Null and Alternative Hypotheses?\n\nIs the median house price in Pittsburgh larger than the median price in Washington?\nIs the mean number of mountain lions per 100 km^2 equal in North and South America?\nNHANES reports the average starting age of smoking is 19. Is this correct, or is the true mean lower than this?\nIs the bill depth of Chinstrap penguins greater than the bill depth of Adelie penguins?"
  },
  {
    "objectID": "slides/hypothesis.html#in-data-science-we-often-do-create-our-models-using-resampling.",
    "href": "slides/hypothesis.html#in-data-science-we-often-do-create-our-models-using-resampling.",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "In data science, we often do create our models using resampling.",
    "text": "In data science, we often do create our models using resampling.\n\nIn traditional statistics, you would do this with a parametric significance test, like a T-test.\nThe permutation approach for hypothesis testing is like the bootstrap sampling we did last week, but now we’ll resample without replacement."
  },
  {
    "objectID": "slides/hypothesis.html#permute-means-to-change-the-order-of-a-set-of-values.",
    "href": "slides/hypothesis.html#permute-means-to-change-the-order-of-a-set-of-values.",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "Permute means to change the order of a set of values.",
    "text": "Permute means to change the order of a set of values.\nIn a permutation test, you rearrange groups randomly to determine a permutation distribution."
  },
  {
    "objectID": "slides/hypothesis.html#a-permutation-distribution-embodies-the-null-hypothesis.",
    "href": "slides/hypothesis.html#a-permutation-distribution-embodies-the-null-hypothesis.",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "A permutation distribution embodies the null hypothesis.",
    "text": "A permutation distribution embodies the null hypothesis.\nIt shows you what the distribution would look like if the difference between the groups was the result of random variation."
  },
  {
    "objectID": "slides/hypothesis.html#the-steps-of-a-permutation-test",
    "href": "slides/hypothesis.html#the-steps-of-a-permutation-test",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "The steps of a permutation test:",
    "text": "The steps of a permutation test:\n\nRandomly resample (without replacement) a group the same size at the first group.\nFrom the remaining data, randomly resample (without replacement) a group the same size as the second group.\nCalculate the difference in means between the two resamples. This is one permutation.\nRepeat these steps as many times as you want to create a permutation distribution.\nCompare the observed difference in the real groups to the permutation distribution."
  },
  {
    "objectID": "slides/hypothesis.html#you-can-use-the-permutation-distribution-to-calculate-a-p-value.",
    "href": "slides/hypothesis.html#you-can-use-the-permutation-distribution-to-calculate-a-p-value.",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "You can use the permutation distribution to calculate a p-value.",
    "text": "You can use the permutation distribution to calculate a p-value."
  },
  {
    "objectID": "slides/hypothesis.html#lets-look-at-the-penguins-dataset.",
    "href": "slides/hypothesis.html#lets-look-at-the-penguins-dataset.",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "Let’s look at the penguins dataset.",
    "text": "Let’s look at the penguins dataset.\nimport pandas as pd\nimport numpy as np\nimport altair as alt\n\npenguins = pd.read_csv('https://jrladd.com/CIS241/data/penguins.csv')\npenguins\n\nalt.Chart(penguins,title=\"Comparing Penguins' Bill Depth by Species\").mark_boxplot().encode(\n    x=alt.X('species:N').title(\"Species of Penguin\"),\n    y=alt.Y('bill_depth_mm:Q').title(\"Bill Depth (mm)\").scale(zero=False),\n    color=alt.Color('species:N').legend(None)\n).properties(width=200)"
  },
  {
    "objectID": "slides/hypothesis.html#whats-the-difference-in-means",
    "href": "slides/hypothesis.html#whats-the-difference-in-means",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "What’s the difference in means?",
    "text": "What’s the difference in means?\n# Get two groups\nchinstrap_bill_depth = penguins[penguins.species == \"Chinstrap\"].bill_depth_mm\nadelie_bill_depth = penguins[penguins.species == \"Adelie\"].bill_depth_mm\n\n# Calculate the difference in means\nobserved_difference = chinstrap_bill_depth.mean() - adelie_bill_depth.mean()\nobserved_difference"
  },
  {
    "objectID": "slides/hypothesis.html#lets-create-a-function-for-permutation",
    "href": "slides/hypothesis.html#lets-create-a-function-for-permutation",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "Let’s create a function for permutation!",
    "text": "Let’s create a function for permutation!\ndef simulate_two_groups(data1, data2):\n    n = len(data1) #Get length of first group\n    data = pd.concat([data1, data2]) #Get all data\n    data = data.sample(frac=1) #Reshuffle all data\n    group1 = data.iloc[:n] #Get random first group\n    group2 = data.iloc[n:] #Get random second group\n    return group1.mean() - group2.mean() #Calculate mean difference\nYou can reuse this code!"
  },
  {
    "objectID": "slides/hypothesis.html#now-we-can-make-5000-permutations.",
    "href": "slides/hypothesis.html#now-we-can-make-5000-permutations.",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "Now we can make 5000 permutations.",
    "text": "Now we can make 5000 permutations.\n# This is similar to how we\n# calculated confidence intervals\npermutations = []\nfor i in range(5000):\n    one_perm = simulate_two_groups(chinstrap_bill_depth, adelie_bill_depth)\n    permutations.append(one_perm)\n\npermutations = pd.DataFrame({'permutations':permutations})"
  },
  {
    "objectID": "slides/hypothesis.html#lets-look-at-the-results-in-a-histogram",
    "href": "slides/hypothesis.html#lets-look-at-the-results-in-a-histogram",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "Let’s look at the results in a histogram",
    "text": "Let’s look at the results in a histogram\nalt.data_transformers.disable_max_rows() # Don't limit the data\n# Create a histogram\nhistogram = alt.Chart(permutations).mark_bar().encode(\n    x=alt.X(\"permutations:Q\").bin(maxbins=20),\n    y=alt.Y(\"count():Q\")\n)\npermutations = permutations.assign(observed_difference=observed_difference) # Add the mean to the dataframe\n# Add a vertical line\nobserved_line = alt.Chart(permutations).mark_rule(color=\"red\", strokeDash=(8,4)).encode(\n    x=alt.X(\"observed_difference\")\n)\n# Combine the two plots\nhistogram + observed_line\nHow is this different from previous Altair plots?"
  },
  {
    "objectID": "slides/hypothesis.html#finally-we-can-calculate-a-p-value",
    "href": "slides/hypothesis.html#finally-we-can-calculate-a-p-value",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "Finally, we can calculate a p-value:",
    "text": "Finally, we can calculate a p-value:\np_value = np.mean(permutations.permutations &gt; observed_difference)\np_value\nWhy does this code work?\nIs our result statistically significant? Is it practically significant?"
  },
  {
    "objectID": "slides/hypothesis.html#we-could-keep-looking-at-graphs-like-these-but-thats-imprecise.",
    "href": "slides/hypothesis.html#we-could-keep-looking-at-graphs-like-these-but-thats-imprecise.",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "We could keep looking at graphs like these, but that’s imprecise.",
    "text": "We could keep looking at graphs like these, but that’s imprecise.\nInstead, we can measure the probability of obtaining results as unusual as the observed result.\nThis probability is called the p-value!"
  },
  {
    "objectID": "slides/hypothesis.html#the-p-values-formal-definition",
    "href": "slides/hypothesis.html#the-p-values-formal-definition",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "The p-value’s formal definition:",
    "text": "The p-value’s formal definition:\nGiven a random model that embodies the null hypothesis, the p-value is the probability of obtaining results as unusual or extreme as the observed result.\nIn our example, our 32% was a p-value of .32!"
  },
  {
    "objectID": "slides/hypothesis.html#is-a-common-alpha-or-pre-determined-cutoff-for-significance.",
    "href": "slides/hypothesis.html#is-a-common-alpha-or-pre-determined-cutoff-for-significance.",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": ".05 is a common alpha, or pre-determined cutoff for significance.",
    "text": ".05 is a common alpha, or pre-determined cutoff for significance.\nIf the p-value is lower than .05 (5%), we can reject the null hypothesis and our result is statistically significant.\nIf the p-value is higher than .05 (5%), we fail to reject the null hypothesis and our result is not statistically significant.\nThis is just a rule of thumb!"
  },
  {
    "objectID": "slides/hypothesis.html#we-calculated-a-p-value-for-a-difference-in-means.",
    "href": "slides/hypothesis.html#we-calculated-a-p-value-for-a-difference-in-means.",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "We calculated a p-value for a difference in means.",
    "text": "We calculated a p-value for a difference in means.\nDifferent permutation tests calculate p-values for other kinds of differences."
  },
  {
    "objectID": "slides/hypothesis.html#all-other-things-being-equal",
    "href": "slides/hypothesis.html#all-other-things-being-equal",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "All other things being equal…",
    "text": "All other things being equal…\n\nThe observed difference increasing will decrease the p-value (more likely to find significance)\nThe sample size increasing will decrease the p-value (more likely to find significance)\nThe variability increasing will increase the p-value (less likely to find significance)"
  },
  {
    "objectID": "slides/hypothesis.html#dont-only-consider-the-p-value",
    "href": "slides/hypothesis.html#dont-only-consider-the-p-value",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "Don’t only consider the p-value!",
    "text": "Don’t only consider the p-value!\nConsider results that are:\n\nStatistically significant and practically significant (i.e. useful)\nStatistically significant and not practically significant (i.e. not useful)\nStatistically insignificant and practically significant\nMarginally significant and practically significant"
  },
  {
    "objectID": "slides/hypothesis.html#error-in-hypothesis-testing",
    "href": "slides/hypothesis.html#error-in-hypothesis-testing",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "Error in Hypothesis Testing",
    "text": "Error in Hypothesis Testing\n\n\nType I Error (alpha-error) is rejecting the null hypothesis when it is true.\nType II Error (beta-error) is failing to reject the null hypothesis when it is false.\n\nMisreading or overemphasizing the p-value can lead us to error!"
  },
  {
    "objectID": "slides/hypothesis.html#permutation-exercise",
    "href": "slides/hypothesis.html#permutation-exercise",
    "title": "Hypothesis Testing 1: Comparison of Means",
    "section": "Permutation Exercise",
    "text": "Permutation Exercise\nDetermine if users spend significantly more time on Page B than they do on Page A.\n\nCopy the URL for web_page_data.csv.\nMake a boxplot of session times for Pages A and B.\nCalculate the observed difference in means.\nRun 2000 permutations of randomly resampled groups.\nMake a histogram of permutation results and show the observed difference as a vertical line.\nCalculate the p-value for your permutation test."
  },
  {
    "objectID": "slides/correlation.html#our-first-form-of-bivariate-analysis.",
    "href": "slides/correlation.html#our-first-form-of-bivariate-analysis.",
    "title": "Hypothesis Testing 2: Correlation",
    "section": "Our first form of bivariate analysis.",
    "text": "Our first form of bivariate analysis.\nCorrelation always involves two or more variables (columns)."
  },
  {
    "objectID": "slides/correlation.html#the-correlation-coefficient-measures-the-extent-to-which-two-variables-are-related-from--1-to-1.",
    "href": "slides/correlation.html#the-correlation-coefficient-measures-the-extent-to-which-two-variables-are-related-from--1-to-1.",
    "title": "Hypothesis Testing 2: Correlation",
    "section": "The correlation coefficient measures the extent to which two variables are related, from -1 to 1.",
    "text": "The correlation coefficient measures the extent to which two variables are related, from -1 to 1.\nPearson’s correlation coefficient multiplies the deviations from the mean for two variables, and divides by the product of the standard deviation.\nTells us the strength of a correlation."
  },
  {
    "objectID": "slides/correlation.html#pearsons-correlation-r-is-the-default-in-pandas.",
    "href": "slides/correlation.html#pearsons-correlation-r-is-the-default-in-pandas.",
    "title": "Hypothesis Testing 2: Correlation",
    "section": "Pearson’s correlation, r, is the default in Pandas.",
    "text": "Pearson’s correlation, r, is the default in Pandas.\n# Load cars sample dataset\ncars = data.cars()\n\n# Calculate correlations between all columns in a dataframe \ncars.corr(numeric_only=True)\n\n# Calculate correlation between just two variables\ncars.Miles_per_Gallon.corr(cars.Displacement)"
  },
  {
    "objectID": "slides/correlation.html#scatterplots-show-potential-correlation-between-two-variables",
    "href": "slides/correlation.html#scatterplots-show-potential-correlation-between-two-variables",
    "title": "Hypothesis Testing 2: Correlation",
    "section": "Scatterplots show potential correlation between two variables",
    "text": "Scatterplots show potential correlation between two variables\nThe y-axis shows the dependent variable, while the x-axis shows the independent variable."
  },
  {
    "objectID": "slides/correlation.html#make-a-scatterplot-with-altair",
    "href": "slides/correlation.html#make-a-scatterplot-with-altair",
    "title": "Hypothesis Testing 2: Correlation",
    "section": "Make a scatterplot with Altair",
    "text": "Make a scatterplot with Altair\n\nalt.Chart(cars, title=\"Fuel Efficiency and Engine Displacement\").mark_point().encode(\n    x=alt.X(\"Displacement:Q\", title=\"Engine Displacement (liters)\"),\n    y=alt.Y(\"Miles_per_Gallon:Q\", title=\"Fuel Efficiency (mpg)\")\n).interactive()"
  },
  {
    "objectID": "slides/correlation.html#make-a-scatterplot-with-altair-output",
    "href": "slides/correlation.html#make-a-scatterplot-with-altair-output",
    "title": "Hypothesis Testing 2: Correlation",
    "section": "Make a scatterplot with Altair",
    "text": "Make a scatterplot with Altair"
  },
  {
    "objectID": "slides/correlation.html#add-a-line-of-best-fit-to-make-a-regression-plot",
    "href": "slides/correlation.html#add-a-line-of-best-fit-to-make-a-regression-plot",
    "title": "Hypothesis Testing 2: Correlation",
    "section": "Add a line of best fit to make a regression plot",
    "text": "Add a line of best fit to make a regression plot\n\nscatter = alt.Chart(cars, title=\"Fuel Efficiency and Engine Displacement\").mark_point().encode(\n    x=alt.X(\"Displacement:Q\", title=\"Engine Displacement (liters)\"),\n    y=alt.Y(\"Miles_per_Gallon:Q\", title=\"Fuel Efficiency (mpg)\")\n).interactive()\n\nscatter + scatter.transform_regression('Displacement','Miles_per_Gallon').mark_line()"
  },
  {
    "objectID": "slides/correlation.html#add-a-line-of-best-fit-to-make-a-regression-plot-output",
    "href": "slides/correlation.html#add-a-line-of-best-fit-to-make-a-regression-plot-output",
    "title": "Hypothesis Testing 2: Correlation",
    "section": "Add a line of best fit to make a regression plot",
    "text": "Add a line of best fit to make a regression plot"
  },
  {
    "objectID": "slides/correlation.html#avoid-overplotting-with-heatmaps-or-kernel-density-estimation.",
    "href": "slides/correlation.html#avoid-overplotting-with-heatmaps-or-kernel-density-estimation.",
    "title": "Hypothesis Testing 2: Correlation",
    "section": "Avoid overplotting with heatmaps or kernel density estimation.",
    "text": "Avoid overplotting with heatmaps or kernel density estimation.\n\n# Heatmap example\nalt.Chart(cars, title=\"Fuel Efficiency and Engine Displacement\").mark_rect().encode(\n    x=alt.X(\"Displacement:Q\", title=\"Engine Displacement (liters)\").bin(),\n    y=alt.Y(\"Miles_per_Gallon:Q\", title=\"Fuel Efficiency (mpg)\").bin(),\n    color=alt.Color(\"count():Q\")\n)"
  },
  {
    "objectID": "slides/correlation.html#avoid-overplotting-with-heatmaps-or-kernel-density-estimation.-output",
    "href": "slides/correlation.html#avoid-overplotting-with-heatmaps-or-kernel-density-estimation.-output",
    "title": "Hypothesis Testing 2: Correlation",
    "section": "Avoid overplotting with heatmaps or kernel density estimation.",
    "text": "Avoid overplotting with heatmaps or kernel density estimation."
  },
  {
    "objectID": "slides/correlation.html#correlation-matrix-shows-all-possible-correlations.",
    "href": "slides/correlation.html#correlation-matrix-shows-all-possible-correlations.",
    "title": "Hypothesis Testing 2: Correlation",
    "section": "Correlation matrix shows all possible correlations.",
    "text": "Correlation matrix shows all possible correlations.\n\n# Re-arrange correlation matrix data\ncars_corr = (cars.corr(numeric_only=True)\n             .stack()\n             .reset_index()\n             .rename(columns={0:'corr','level_0':'var1','level_1':'var2'})\n            )\n# Create correlation heatmap\nbase = alt.Chart(cars_corr, title=\"Cars Correlation Matrix\").mark_rect().encode(\n    x=alt.X(\"var1:N\",title=None),\n    y=alt.Y(\"var2:N\",title=None),\n    color=alt.Color(\"corr\",title=\"Correlation coefficient\").scale(scheme='blueorange')\n).properties(width=300,height=300)\n# Add text labels for coefficients\ntext = base.mark_text(baseline='middle').encode(\n    alt.Text('corr:Q', format=\".2f\"),\n    color=alt.condition(\n        (alt.datum.corr &lt; -0.5) | (alt.datum.corr &gt; 0.5),\n        alt.value('white'),\n        alt.value('black')\n    )\n)\nbase+text # Display visualization"
  },
  {
    "objectID": "slides/correlation.html#correlation-matrix-shows-all-possible-correlations.-output",
    "href": "slides/correlation.html#correlation-matrix-shows-all-possible-correlations.-output",
    "title": "Hypothesis Testing 2: Correlation",
    "section": "Correlation matrix shows all possible correlations.",
    "text": "Correlation matrix shows all possible correlations."
  },
  {
    "objectID": "slides/correlation.html#how-do-we-know-if-a-correlation-coefficient-is-statistically-significant",
    "href": "slides/correlation.html#how-do-we-know-if-a-correlation-coefficient-is-statistically-significant",
    "title": "Hypothesis Testing 2: Correlation",
    "section": "How do we know if a correlation coefficient is statistically significant?",
    "text": "How do we know if a correlation coefficient is statistically significant?\nThere are standard parametric approaches to this, but we can use permutation!"
  },
  {
    "objectID": "slides/correlation.html#we-need-a-new-simulation-function-for-correlation.",
    "href": "slides/correlation.html#we-need-a-new-simulation-function-for-correlation.",
    "title": "Hypothesis Testing 2: Correlation",
    "section": "We need a new simulation function for correlation.",
    "text": "We need a new simulation function for correlation.\ndef simulate_correlation(df,var1,var2):\n    shuffled = df[var1].sample(frac=1).reset_index(drop=True)\n    corr = shuffled.corr(df[var2])\n    return corr"
  },
  {
    "objectID": "slides/correlation.html#lets-try-it",
    "href": "slides/correlation.html#lets-try-it",
    "title": "Hypothesis Testing 2: Correlation",
    "section": "Let’s Try It!",
    "text": "Let’s Try It!\nUsing the function from the previous slide, run 5000 permutations of the correlation between engine displacement and miles per gallon.\nGraph the results as a histogram and calculate a p-value. Is this a statistically significant correlation?"
  },
  {
    "objectID": "slides/correlation.html#if-we-have-the-same-mean-standard-deviation-and-correlation-we-might-expect-the-data-sets-to-be-similar",
    "href": "slides/correlation.html#if-we-have-the-same-mean-standard-deviation-and-correlation-we-might-expect-the-data-sets-to-be-similar",
    "title": "Hypothesis Testing 2: Correlation",
    "section": "If we have the same mean, standard deviation, and correlation we might expect the data sets to be similar…",
    "text": "If we have the same mean, standard deviation, and correlation we might expect the data sets to be similar…"
  },
  {
    "objectID": "slides/correlation.html#data-challenge",
    "href": "slides/correlation.html#data-challenge",
    "title": "Hypothesis Testing 2: Correlation",
    "section": "Data Challenge",
    "text": "Data Challenge\nUse pandas to find the summary statistics for each dataset in the datasaurus_dozen.\n\nFind mean, standard deviation, and correlation for both x and y of each dataset. (You may need to group things by the “dataset” column.)\nWhen you’re done, try making scatter plots! (You may need to use the column encoding.)"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Course Schedule",
    "section": "",
    "text": "Date\nTopics & Slides\nWorkshops\nAssignments\n\n\n\n\n14 & 16 Jan.\nWhat Is Data? & Responsible Data Collection\nJupyter\n\n\n\n21 & 23 Jan.\nPython & Data Wrangling\nMovies\n\n\n\n28 & 30 Jan.\nExploratory Data Analysis & Visualization\nMovies\nDocumentation Assignment Due 30 Jan.\n\n\n4 & 6 Feb.\nHypothesis Testing: Comparison of Means\nSports\n\n\n\n11 & 13 Feb.\nHypothesis Testing: Correlation\nSports\n\n\n\n18 & 20 Feb.\nLinear Regression\nBusiness\nTake-Home Test I Due 20 Feb.\n\n\n25 & 27 Feb.\nLogistic Regression\nBusiness\n\n\n\n4 & 6 Mar.\nK-Nearest Neighbors\nHealth\nTutorial Assignment Due 6 Mar.\n\n\n11 & 13 Mar.\nSPRING BREAK\n\n\n\n\n18 & 20 Mar.\nNaive Bayes Classifier\n\n\n\n\n25 & 27 Mar.\nDecision Trees and the Random Forest\nHealth\nTake-Home Test II Due 25 Mar.\n\n\n1 & 3 Apr.\nClustering and Unsupervised Approaches\nLiterature\nProject Proposal Due 3 Apr.\n\n\n8 & 10 Apr.\nNeural Networks\nLiterature\n\n\n\n15 & 17 Apr.\nEthical Data Science & Project Discussion\n\nProgress Report Due 15 Apr.\n\n\n22 & 24 Apr.\nSample Final Project & Project Discussion\n\nVideo Presentations Due 22 Apr.\n\n\n1 May 2-5pm\nPanel Presentations\n\nFinal Project Due 1 May at 2pm"
  },
  {
    "objectID": "schedule.html#software",
    "href": "schedule.html#software",
    "title": "Course Schedule",
    "section": "Software",
    "text": "Software\nAll projects in this course will be scripted and analyzed using Python, an open source programming language and environment. Specifically, we will be using JupyterHub as our programming environment. No previous experience with Python, statistical software packages, or computer programming is required."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Data Science",
    "section": "",
    "text": "CIS 241. Washington & Jefferson College. Spring 2025.\nMeeting Time: TR 9:00-10:45pm\nDr. Ladd’s Student Drop-In Hours: MW 10am–12pm TECH 201\nor email for appointment, jladd@washjeff.edu\nPAL Tutoring Hours: 7-10pm Sunday–Thursday in the CIS Lounge (TECH 217)\nTutor bios and additional info"
  },
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "Introduction to Data Science",
    "section": "Course Description",
    "text": "Course Description\nFrom social media to the James Webb telescope, from Shakespeare’s plays to the U.S. Census, data is being collected all around us, all the time. How can we make sense of these near-constant streams of information?\nThis course will attempt to answer this question by introducing the concepts and practices involved in data analysis: data collection and preparation, exploratory analysis, and prediction and classification. Using the programming language Python and other industry-standard tools, we will practice ways of working with data from simple summary statistics to advanced machine learning models. At each step of the way, we’ll discuss how to approach data analysis critically and ethically. And we’ll explore data sets from a wide range of fields and disciplines, including sociology, ecology, business, film, and history."
  },
  {
    "objectID": "index.html#learning-goals",
    "href": "index.html#learning-goals",
    "title": "Introduction to Data Science",
    "section": "Learning Goals",
    "text": "Learning Goals\nAt the end of this course, you should be able to:\n\nUnderstand and implement the data analysis process, from data collection to communicating results.\nUse exploratory data analysis to quickly understand a complex dataset.\nApply modeling techniques to make predictions.\nEvaluate the effectiveness of different modeling techniques.\nThink and act ethically at all steps of the data analysis process.\n\nBanner image: The Library Computer Access/Retrieval System (LCARS), a fictional operating system and data analysis interface from Star Trek: The Next Generation"
  },
  {
    "objectID": "slides/clustering.html#so-far-we-have-learned-supervised-learning-techniques.",
    "href": "slides/clustering.html#so-far-we-have-learned-supervised-learning-techniques.",
    "title": "Unsupervised Learning & Clustering 🪁🪁🪁",
    "section": "So far we have learned supervised learning techniques.",
    "text": "So far we have learned supervised learning techniques.\nPredicting a known target from a set of predictor variables.\ne.g. Logistic Regression, Naive Bayes, KNN, Random Forest, etc."
  },
  {
    "objectID": "slides/clustering.html#unsupervised-learning-has-no-target-variables.",
    "href": "slides/clustering.html#unsupervised-learning-has-no-target-variables.",
    "title": "Unsupervised Learning & Clustering 🪁🪁🪁",
    "section": "Unsupervised learning has no target variables.",
    "text": "Unsupervised learning has no target variables.\nIt constructs a model of the data without learning from existing labels."
  },
  {
    "objectID": "slides/clustering.html#unsupervised-learning-can-have-different-uses.",
    "href": "slides/clustering.html#unsupervised-learning-can-have-different-uses.",
    "title": "Unsupervised Learning & Clustering 🪁🪁🪁",
    "section": "Unsupervised learning can have different uses.",
    "text": "Unsupervised learning can have different uses.\n\nDimension reduction: get a more manageable set of variables.\nClustering: identify meaningful categories in the data.\nExploration: analyze variables and discover relationships."
  },
  {
    "objectID": "slides/clustering.html#types-of-unsupervised-learning",
    "href": "slides/clustering.html#types-of-unsupervised-learning",
    "title": "Unsupervised Learning & Clustering 🪁🪁🪁",
    "section": "Types of unsupervised learning",
    "text": "Types of unsupervised learning\n\nPrincipal component analysis (PCA): dimension reduction\nCorrespondence analysis: dimension reduction\nK-Means Clustering: clustering and exploration\nHierarchical Clustering: clustering and exploration"
  },
  {
    "objectID": "slides/clustering.html#like-knn-this-method-is-based-on-distance.",
    "href": "slides/clustering.html#like-knn-this-method-is-based-on-distance.",
    "title": "Unsupervised Learning & Clustering 🪁🪁🪁",
    "section": "Like KNN, this method is based on distance.",
    "text": "Like KNN, this method is based on distance."
  },
  {
    "objectID": "slides/clustering.html#k-means-attempts-to-minimize-the-distance-of-each-point-to-the-centroid-mean-of-its-assigned-cluster.",
    "href": "slides/clustering.html#k-means-attempts-to-minimize-the-distance-of-each-point-to-the-centroid-mean-of-its-assigned-cluster.",
    "title": "Unsupervised Learning & Clustering 🪁🪁🪁",
    "section": "K-Means attempts to minimize the distance of each point to the centroid (mean) of its assigned cluster.",
    "text": "K-Means attempts to minimize the distance of each point to the centroid (mean) of its assigned cluster."
  },
  {
    "objectID": "slides/clustering.html#k-means-is-typically-used-to-locate-natural-clusters-in-the-data.",
    "href": "slides/clustering.html#k-means-is-typically-used-to-locate-natural-clusters-in-the-data.",
    "title": "Unsupervised Learning & Clustering 🪁🪁🪁",
    "section": "K-Means is typically used to locate “natural” clusters in the data.",
    "text": "K-Means is typically used to locate “natural” clusters in the data.\nIt can’t find clusters that aren’t there!"
  },
  {
    "objectID": "slides/clustering.html#k-refers-to-the-number-of-clusterscentroids-that-the-method-will-find.",
    "href": "slides/clustering.html#k-refers-to-the-number-of-clusterscentroids-that-the-method-will-find.",
    "title": "Unsupervised Learning & Clustering 🪁🪁🪁",
    "section": "K refers to the number of clusters/centroids that the method will find.",
    "text": "K refers to the number of clusters/centroids that the method will find.\nJust like in KNN, you have to choose K based on the data! (More on this later.)"
  },
  {
    "objectID": "slides/clustering.html#the-best-way-to-choose-k-is-based-on-your-knowledge-of-the-data.",
    "href": "slides/clustering.html#the-best-way-to-choose-k-is-based-on-your-knowledge-of-the-data.",
    "title": "Unsupervised Learning & Clustering 🪁🪁🪁",
    "section": "The best way to choose K is based on your knowledge of the data.",
    "text": "The best way to choose K is based on your knowledge of the data.\nYou can review the documentation and use every exploratory tool in the book to get a sense of how many clusters there might be in the data."
  },
  {
    "objectID": "slides/clustering.html#you-might-also-have-a-procedural-reason-for-choosing-a-number.",
    "href": "slides/clustering.html#you-might-also-have-a-procedural-reason-for-choosing-a-number.",
    "title": "Unsupervised Learning & Clustering 🪁🪁🪁",
    "section": "You might also have a procedural reason for choosing a number.",
    "text": "You might also have a procedural reason for choosing a number.\nMaybe your company needs to split customers into exactly 4 categories, for instance."
  },
  {
    "objectID": "slides/clustering.html#if-youre-lost-when-choosing-k-you-can-try-the-elbow-method.",
    "href": "slides/clustering.html#if-youre-lost-when-choosing-k-you-can-try-the-elbow-method.",
    "title": "Unsupervised Learning & Clustering 🪁🪁🪁",
    "section": "If you’re lost when choosing K, you can try the “elbow method.”",
    "text": "If you’re lost when choosing K, you can try the “elbow method.”\n\nRun K-Means multiple times, with a different value for K each time.\nLook at how close the values are to their centroid. (This is called inertia.)\nCreate a graph to see at what value for K this inertia measure begins to settle."
  },
  {
    "objectID": "slides/clustering.html#heres-what-the-elbow-method-looks-like-in-python.",
    "href": "slides/clustering.html#heres-what-the-elbow-method-looks-like-in-python.",
    "title": "Unsupervised Learning & Clustering 🪁🪁🪁",
    "section": "Here’s what the elbow method looks like in Python.",
    "text": "Here’s what the elbow method looks like in Python.\n# Steps 1 & 2: Run K-means with different K and get inertia\ninertia = []\nfor n_clusters in range(2,14):\n    kmeans = KMeans(n_clusters=n_clusters, n_init='auto', random_state=0).fit(X_std)\n    inertia.append(kmeans.inertia_ / n_clusters)\n\n# Step 3: Put into a dataframe and create a line plot\ninertia = pd.DataFrame({'n_clusters': range(2,14), 'inertia': inertia})\n# Make your line plot here!"
  },
  {
    "objectID": "slides/clustering.html#an-example-of-the-elbow-method-plot-for-the-penguins-dataset.",
    "href": "slides/clustering.html#an-example-of-the-elbow-method-plot-for-the-penguins-dataset.",
    "title": "Unsupervised Learning & Clustering 🪁🪁🪁",
    "section": "An example of the elbow method plot for the penguins dataset.",
    "text": "An example of the elbow method plot for the penguins dataset.\n\nSee how the “elbow” bends around 3 or 4 clusters? 💪"
  },
  {
    "objectID": "slides/clustering.html#just-like-knn-you-must-scale-your-data",
    "href": "slides/clustering.html#just-like-knn-you-must-scale-your-data",
    "title": "Unsupervised Learning & Clustering 🪁🪁🪁",
    "section": "Just like KNN, you must scale your data!",
    "text": "Just like KNN, you must scale your data!\nFor a dataset of all quantitative variables, use StandardScaler() as usual.\nIt is best to stick with numerical variables for clustering, but if you must use categorical variables, remember to use one-hot encoding before scaling. A MinMaxScaler() may also be useful in this case."
  },
  {
    "objectID": "slides/clustering.html#you-dont-need-to-split-your-data.",
    "href": "slides/clustering.html#you-dont-need-to-split-your-data.",
    "title": "Unsupervised Learning & Clustering 🪁🪁🪁",
    "section": "You don’t need to split your data.",
    "text": "You don’t need to split your data.\nBecause this is an unsupervised method, there’s no need to reserve a test set. There would be nothing to test on!"
  },
  {
    "objectID": "slides/clustering.html#code-for-running-k-means.",
    "href": "slides/clustering.html#code-for-running-k-means.",
    "title": "Unsupervised Learning & Clustering 🪁🪁🪁",
    "section": "Code for running K-Means.",
    "text": "Code for running K-Means.\nThis isn’t the whole workflow, it’s just the model code.\nfrom sklearn.cluster import KMeans\n\nkmeans = KMeans(n_clusters=3, n_init='auto', max_iter=300, random_state=0)\nkmeans.fit(X_std)\nBefore running this, you should try the elbow method to determine a good K value!"
  },
  {
    "objectID": "slides/clustering.html#as-always-pay-attention-to-the-hyperparameters.",
    "href": "slides/clustering.html#as-always-pay-attention-to-the-hyperparameters.",
    "title": "Unsupervised Learning & Clustering 🪁🪁🪁",
    "section": "As always pay attention to the hyperparameters.",
    "text": "As always pay attention to the hyperparameters.\n\nn_clusters: the number of clusters the model will produce. This is “K”!\nn_init: the total number of times the model will be run.\nmax_iter: the number of iterations the model will take to find centroids.\nrandom_state: keeps the model the same every time."
  },
  {
    "objectID": "slides/clustering.html#we-can-interpret-the-clusters-in-two-ways.",
    "href": "slides/clustering.html#we-can-interpret-the-clusters-in-two-ways.",
    "title": "Unsupervised Learning & Clustering 🪁🪁🪁",
    "section": "We can interpret the clusters in two ways.",
    "text": "We can interpret the clusters in two ways.\nFirst, we can look at the relative size of the clusters. Are they relatively balanced? Unbalanced clusters may mean we need to try again.\n# Using the .labels_ attribute of our model\npd.Series(kmeans.labels_).value_counts()"
  },
  {
    "objectID": "slides/clustering.html#we-can-interpret-the-clusters-in-two-ways.-cont.",
    "href": "slides/clustering.html#we-can-interpret-the-clusters-in-two-ways.-cont.",
    "title": "Unsupervised Learning & Clustering 🪁🪁🪁",
    "section": "We can interpret the clusters in two ways. (cont.)",
    "text": "We can interpret the clusters in two ways. (cont.)\nNext, we can look at the cluster means for each cluster. This tells us where the centroid is and gives us a sense of how the different variables interact.\n# Using the .cluster_centers_ attribute of our model\n# Get the centers into a dataframe:\ncenters = pd.DataFrame(kmeans.cluster_centers_, columns=predictors)\n\n# Tidy our dataset with .melt() (the opposite of pivot):\ncenters = centers.melt(ignore_index=False).reset_index()\n\n# Create bar plots to compare the centers"
  },
  {
    "objectID": "slides/clustering.html#try-k-means-clustering-for-the-penguins-dataset.",
    "href": "slides/clustering.html#try-k-means-clustering-for-the-penguins-dataset.",
    "title": "Unsupervised Learning & Clustering 🪁🪁🪁",
    "section": "Try K-Means Clustering for the penguins dataset.",
    "text": "Try K-Means Clustering for the penguins dataset.\n\nSelect features and prepare data. Consider standardizations as well as null values.\nUse the elbow method to determine a good value for K.\nRun K-Means clustering. Be thoughtful about the hyperparameters, especially K (n_clusters)!\nAssess your model using the cluster sizes and a bar plot of the cluster means.\n\nGood luck! 🐧🐧🐧"
  },
  {
    "objectID": "slides/ethics.html#ethics-in",
    "href": "slides/ethics.html#ethics-in",
    "title": "Ethics, Bias, and Diversity in Data Science",
    "section": "Ethics in…",
    "text": "Ethics in…\n\nData Collection and Study Design\nVisualization and Analysis\nInterpretation and Communication"
  },
  {
    "objectID": "slides/ethics.html#ethics-isnt-only-about-human-subjects",
    "href": "slides/ethics.html#ethics-isnt-only-about-human-subjects",
    "title": "Ethics, Bias, and Diversity in Data Science",
    "section": "Ethics isn’t only about human subjects!",
    "text": "Ethics isn’t only about human subjects!"
  },
  {
    "objectID": "slides/ethics.html#ethical-principles-are-general-values-that-guide-decision-making.",
    "href": "slides/ethics.html#ethical-principles-are-general-values-that-guide-decision-making.",
    "title": "Ethics, Bias, and Diversity in Data Science",
    "section": "Ethical principles are general values that guide decision making.",
    "text": "Ethical principles are general values that guide decision making.\nThey are distinct from specific rules."
  },
  {
    "objectID": "slides/ethics.html#ethical-standards-are-specific-applications-of-general-principles.",
    "href": "slides/ethics.html#ethical-standards-are-specific-applications-of-general-principles.",
    "title": "Ethics, Bias, and Diversity in Data Science",
    "section": "Ethical standards are specific applications of general principles.",
    "text": "Ethical standards are specific applications of general principles.\nThey are sometimes prescriptive or legally required."
  },
  {
    "objectID": "slides/ethics.html#belmont-report-ethical-principles-1979",
    "href": "slides/ethics.html#belmont-report-ethical-principles-1979",
    "title": "Ethics, Bias, and Diversity in Data Science",
    "section": "Belmont Report Ethical Principles (1979)",
    "text": "Belmont Report Ethical Principles (1979)\n\nRespect for Persons\nBeneficence\nJustice"
  },
  {
    "objectID": "slides/ethics.html#international-statistical-institute-2010",
    "href": "slides/ethics.html#international-statistical-institute-2010",
    "title": "Ethics, Bias, and Diversity in Data Science",
    "section": "International Statistical Institute (2010)",
    "text": "International Statistical Institute (2010)\n\nRespect\nProfessionalism\nTruthfulness and Integrity"
  },
  {
    "objectID": "slides/ethics.html#academic-data-science-alliance-2024",
    "href": "slides/ethics.html#academic-data-science-alliance-2024",
    "title": "Ethics, Bias, and Diversity in Data Science",
    "section": "Academic Data Science Alliance (2024)",
    "text": "Academic Data Science Alliance (2024)\n\nPositionality\nSociotechnical Systems\nPower\nNarratives"
  },
  {
    "objectID": "slides/ethics.html#bias-in-data",
    "href": "slides/ethics.html#bias-in-data",
    "title": "Ethics, Bias, and Diversity in Data Science",
    "section": "Bias in Data",
    "text": "Bias in Data\nThinking beyond garbage in/garbage out. How do models amplify bias and problems in large datasets?"
  },
  {
    "objectID": "slides/ethics.html#bias-in-researchers",
    "href": "slides/ethics.html#bias-in-researchers",
    "title": "Ethics, Bias, and Diversity in Data Science",
    "section": "Bias in Researchers",
    "text": "Bias in Researchers\nHow do personal beliefs interact with good and ethical data analysis?"
  },
  {
    "objectID": "slides/ethics.html#bias-in-approaches",
    "href": "slides/ethics.html#bias-in-approaches",
    "title": "Ethics, Bias, and Diversity in Data Science",
    "section": "Bias in Approaches",
    "text": "Bias in Approaches\nWhen do certain approaches/algorithms/models bring assumptions that embed bias?"
  },
  {
    "objectID": "slides/knn.html#knn-is-both-a-regressor-and-a-classifier.",
    "href": "slides/knn.html#knn-is-both-a-regressor-and-a-classifier.",
    "title": "K-Nearest Neighbors",
    "section": "KNN is both a regressor and a classifier.",
    "text": "KNN is both a regressor and a classifier.\nIt can predict either numerical values or categories!"
  },
  {
    "objectID": "slides/knn.html#a-machine-learning-method-based-on-distances.",
    "href": "slides/knn.html#a-machine-learning-method-based-on-distances.",
    "title": "K-Nearest Neighbors",
    "section": "A machine learning method based on distances.",
    "text": "A machine learning method based on distances."
  },
  {
    "objectID": "slides/knn.html#there-are-many-ways-to-calculate-distance.",
    "href": "slides/knn.html#there-are-many-ways-to-calculate-distance.",
    "title": "K-Nearest Neighbors",
    "section": "There are many ways to calculate distance.",
    "text": "There are many ways to calculate distance.\n\nEuclidean distance is the default in scikit-learn.\\[\\sqrt[]{(x_2 - x_1)^2 + (y_2 - y_1)^2}\\]"
  },
  {
    "objectID": "slides/knn.html#the-key-to-knn-is-setting-the-correct-k.",
    "href": "slides/knn.html#the-key-to-knn-is-setting-the-correct-k.",
    "title": "K-Nearest Neighbors",
    "section": "The key to KNN is setting the correct K.",
    "text": "The key to KNN is setting the correct K.\n\nIn machine learning, K or k refers to any integer.\nIf K is too low, you may be overfitting.\nIf K is too high, you may be oversmoothing.\nUsually between 1-20, and an odd number avoids ties.\nYou must decide based on the data!"
  },
  {
    "objectID": "slides/knn.html#the-bias-variance-trade-off",
    "href": "slides/knn.html#the-bias-variance-trade-off",
    "title": "K-Nearest Neighbors",
    "section": "The Bias-Variance Trade-Off",
    "text": "The Bias-Variance Trade-Off\n\nVariance: the error in your model due to the choice of training data (sensitivity to small changes in the training data)\nBias: the error in your model due to not accounting for the real-world scenario (bad assumptions in the learning algorithm)\nAs variance goes up, bias goes down and vice versa.\nOverfitting leads to variance, Oversmoothing (underfitting) leads to bias\nYou’re trying to find a balance"
  },
  {
    "objectID": "slides/knn.html#you-can-use-one-hot-encoding-to-handle-factor-variables.",
    "href": "slides/knn.html#you-can-use-one-hot-encoding-to-handle-factor-variables.",
    "title": "K-Nearest Neighbors",
    "section": "You can use one-hot encoding to handle factor variables.",
    "text": "You can use one-hot encoding to handle factor variables.\nHow is this different from reference coding?"
  },
  {
    "objectID": "slides/knn.html#you-must-standardize-your-variables.",
    "href": "slides/knn.html#you-must-standardize-your-variables.",
    "title": "K-Nearest Neighbors",
    "section": "You must standardize your variables.",
    "text": "You must standardize your variables.\nAlso called “normalization”, this keeps variables in the same scale.\nNot “how much” but “how different from the average.”"
  },
  {
    "objectID": "slides/knn.html#the-most-common-standardization-is-the-z-score.",
    "href": "slides/knn.html#the-most-common-standardization-is-the-z-score.",
    "title": "K-Nearest Neighbors",
    "section": "The most common standardization is the z-score.",
    "text": "The most common standardization is the z-score.\n\\[z=\\frac{x-\\bar{x}}{s}\\]\nThe z-score is the original value minus the mean and divided by the standard deviation."
  },
  {
    "objectID": "slides/knn.html#new-scikit-learn-classes",
    "href": "slides/knn.html#new-scikit-learn-classes",
    "title": "K-Nearest Neighbors",
    "section": "New scikit-learn classes",
    "text": "New scikit-learn classes\n# For standardization\nfrom sklearn.preprocessing import StandardScaler\n# For KNN\nfrom sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\nYou will also need plenty of classes and functions that we’ve used previously!"
  },
  {
    "objectID": "slides/knn.html#standardizing-with-z-scores",
    "href": "slides/knn.html#standardizing-with-z-scores",
    "title": "K-Nearest Neighbors",
    "section": "Standardizing with z-scores",
    "text": "Standardizing with z-scores\n# Using the penguins dataset\npredictors = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"sex\"]\ntarget = \"body_mass_g\" # A numerical target for now\n\n# Remove null values and use one-hot encoding\npenguins = penguins.dropna()\nX = pd.get_dummies(penguins[predictors])\ny = penguins[target]\n\n# Split data BEFORE standardizing\nX_train, X_test, y_train, y_test = train_test_split(\n    X, \n    y, \n    test_size=0.3, \n    random_state=0)\n\n# Standardizing using the training data\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train_std = scaler.transform(X_train)"
  },
  {
    "objectID": "slides/knn.html#predict-a-value-with-knn",
    "href": "slides/knn.html#predict-a-value-with-knn",
    "title": "K-Nearest Neighbors",
    "section": "Predict a value with KNN",
    "text": "Predict a value with KNN\n# Fit the KNN Regressor\n# Choose a sensible value for K (n_neighbors)\nknn = KNeighborsRegressor(n_neighbors=5)\nknn.fit(X_train_std, y_train)\n\n# Standardize test data before predicting!\nX_test_std = scaler.transform(X_test)\npredictions = knn.predict(X_test_std)\nThere are no coefficients in KNN!"
  },
  {
    "objectID": "slides/knn.html#predict-a-category-with-knn",
    "href": "slides/knn.html#predict-a-category-with-knn",
    "title": "K-Nearest Neighbors",
    "section": "Predict a category with KNN",
    "text": "Predict a category with KNN\n# First you must split and standardize the data with a new target.\n# Decide on your predictors and targets\npredictors = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"sex\"]\ntarget = \"species\" # A categorical target now\n\npenguins = penguins.dropna()\nX = pd.get_dummies(penguins[predictors])\ny = penguins[target]\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, \n    y, \n    test_size=0.3, \n    random_state=0)\n\n# Standardizing using the training data\nscaler = StandardScaler()\nscaler.fit(X_train)\n\nX_train_std = scaler.transform(X_train)"
  },
  {
    "objectID": "slides/knn.html#predict-a-category-with-knn-cont.",
    "href": "slides/knn.html#predict-a-category-with-knn-cont.",
    "title": "K-Nearest Neighbors",
    "section": "Predict a category with KNN (cont.)",
    "text": "Predict a category with KNN (cont.)\n# Fit the classification model\n# Decide on a good value for K (n_neighbors)\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train_std, y_train)\n\n# Standardize test data\nX_test_std = scaler.transform(X_test)\n\n# Get both probabilities and predictions!\nprobabilities = knn.predict_proba(X_test_std)\npredictions = knn.predict(X_test_std)"
  },
  {
    "objectID": "slides/knn.html#for-a-knn-regressor-use-residuals.",
    "href": "slides/knn.html#for-a-knn-regressor-use-residuals.",
    "title": "K-Nearest Neighbors",
    "section": "For a KNN Regressor, use residuals.",
    "text": "For a KNN Regressor, use residuals.\nThis works like it would for a linear regression: you can use RMSE to understand how your model performed."
  },
  {
    "objectID": "slides/knn.html#for-a-knn-classifier-use-the-confusion-matrix.",
    "href": "slides/knn.html#for-a-knn-classifier-use-the-confusion-matrix.",
    "title": "K-Nearest Neighbors",
    "section": "For a KNN Classifier, use the confusion matrix.",
    "text": "For a KNN Classifier, use the confusion matrix.\nAll the usual measures (accuracy, precision, recall, etc.) are valuable here."
  },
  {
    "objectID": "slides/pythonbasics.html#python-is-a-programming-language.",
    "href": "slides/pythonbasics.html#python-is-a-programming-language.",
    "title": "Python Basics",
    "section": "Python is a programming language.",
    "text": "Python is a programming language.\nIt’s the code you write.\nsomevariable = 5 + 6"
  },
  {
    "objectID": "slides/pythonbasics.html#jupyter-is-a-program-an-integrated-development-environment-ide.",
    "href": "slides/pythonbasics.html#jupyter-is-a-program-an-integrated-development-environment-ide.",
    "title": "Python Basics",
    "section": "Jupyter is a program, an “integrated development environment” (IDE).",
    "text": "Jupyter is a program, an “integrated development environment” (IDE).\nYou can write Python in different places, but in this class we will write and run Python inside Jupyter Lab."
  },
  {
    "objectID": "slides/pythonbasics.html#jupyter-lab-lets-you-see-and-access-files-on-your-computer.",
    "href": "slides/pythonbasics.html#jupyter-lab-lets-you-see-and-access-files-on-your-computer.",
    "title": "Python Basics",
    "section": "Jupyter Lab lets you see and access files on your computer.",
    "text": "Jupyter Lab lets you see and access files on your computer.\nFiles are organized in a hierarchy of directories."
  },
  {
    "objectID": "slides/pythonbasics.html#variables-store-information",
    "href": "slides/pythonbasics.html#variables-store-information",
    "title": "Python Basics",
    "section": "Variables store information",
    "text": "Variables store information\nmyvar = 5\n\nmyvar #or print(myvar)"
  },
  {
    "objectID": "slides/pythonbasics.html#you-try-it",
    "href": "slides/pythonbasics.html#you-try-it",
    "title": "Python Basics",
    "section": "You Try It!",
    "text": "You Try It!\nCreate a variable called “newVar” that is equal to the value of five plus seven. Then display your variable to see what its value is."
  },
  {
    "objectID": "slides/pythonbasics.html#use-descriptive-variable-names-and-avoid-spaces.",
    "href": "slides/pythonbasics.html#use-descriptive-variable-names-and-avoid-spaces.",
    "title": "Python Basics",
    "section": "Use descriptive variable names, and avoid spaces.",
    "text": "Use descriptive variable names, and avoid spaces.\ni_use_snake_case\notherPeopleUseCamelCase\nsome.people.use.periods\nAnd_aFew.People_RENOUNCEconvention"
  },
  {
    "objectID": "slides/pythonbasics.html#add-frequent-comments-to-explain-what-your-code-does.",
    "href": "slides/pythonbasics.html#add-frequent-comments-to-explain-what-your-code-does.",
    "title": "Python Basics",
    "section": "Add frequent comments to explain what your code does.",
    "text": "Add frequent comments to explain what your code does.\nComments in Python begin with a # symbol.\n# This variable contains a continuous value\nsome_variable = 2.5\nYou should also use comments for citations!"
  },
  {
    "objectID": "slides/pythonbasics.html#variables-have-types.",
    "href": "slides/pythonbasics.html#variables-have-types.",
    "title": "Python Basics",
    "section": "Variables have types.",
    "text": "Variables have types.\n\nString or Character: a piece of text (ex. \"five\")\nInteger: a discrete numerical value (ex. 5)\nFloat or Double: a continuous numerical value (ex. 5.0)\n\nstringvar = \"five\"\n\ntype(stringvar)"
  },
  {
    "objectID": "slides/pythonbasics.html#you-try-it-1",
    "href": "slides/pythonbasics.html#you-try-it-1",
    "title": "Python Basics",
    "section": "You Try It!",
    "text": "You Try It!\nFind the type of the new variable you created in the last exercise."
  },
  {
    "objectID": "slides/pythonbasics.html#you-can-put-reusable-code-in-jupyter-notebooks.",
    "href": "slides/pythonbasics.html#you-can-put-reusable-code-in-jupyter-notebooks.",
    "title": "Python Basics",
    "section": "You can put reusable code in Jupyter Notebooks.",
    "text": "You can put reusable code in Jupyter Notebooks.\nThese are “.ipynb” files, and you can create them by clicking the + icon at the top left of the Jupyter Lab window and selecting a Python 3 notebook.\nAlways comment your code so you can remember things when you come back later!"
  },
  {
    "objectID": "slides/pythonbasics.html#a-list-is-surrounded-by-brackets-and-can-contain-any-kind-of-data.",
    "href": "slides/pythonbasics.html#a-list-is-surrounded-by-brackets-and-can-contain-any-kind-of-data.",
    "title": "Python Basics",
    "section": "A list is surrounded by brackets and can contain any kind of data.",
    "text": "A list is surrounded by brackets and can contain any kind of data.\nmylist = [5,6,7]\n\nsecondlist = [\"cat\",\"dog\",\"fish\"]\n\n# Access items in a list\nmylist[0]\nsecondlist[1]"
  },
  {
    "objectID": "slides/pythonbasics.html#a-dictionary-is-surrounded-by-braces-and-contains-keyvalue-pairs.",
    "href": "slides/pythonbasics.html#a-dictionary-is-surrounded-by-braces-and-contains-keyvalue-pairs.",
    "title": "Python Basics",
    "section": "A dictionary is surrounded by braces and contains key/value pairs.",
    "text": "A dictionary is surrounded by braces and contains key/value pairs.\nmydictionary = {\"pet_name\": \"Fido\", \"age\": 5, \"pet_type\": \"dog\"}\n\n# Access items in a dictionary\nmydictionary[\"pet_name\"]\nmydictionary[\"age\"]"
  },
  {
    "objectID": "slides/pythonbasics.html#you-try-it-2",
    "href": "slides/pythonbasics.html#you-try-it-2",
    "title": "Python Basics",
    "section": "You Try It!",
    "text": "You Try It!\n\nCreate a list of 7 items of different data types.\nDisplay the 4th item in the list.\nDisplay the 2nd through 5th items.\nDisplay the 3rd from last item."
  },
  {
    "objectID": "slides/pythonbasics.html#a-function-is-a-command-that-runs-based-on-some-input-or-parameter.",
    "href": "slides/pythonbasics.html#a-function-is-a-command-that-runs-based-on-some-input-or-parameter.",
    "title": "Python Basics",
    "section": "A function is a command that runs based on some input or parameter.",
    "text": "A function is a command that runs based on some input or parameter.\nPython has many built-in functions.\n# Some functions give a number result\nsum([5,6,7])\nmylist = [5,6,7]\nsum(mylist)\nlen(mylist)\n\n# But functions can do anything! \ntype(mydictionary)\nFunctions can do just about anything: calculate values, create graphs, transform data, etc."
  },
  {
    "objectID": "slides/pythonbasics.html#you-can-create-functions-like-you-create-variables.",
    "href": "slides/pythonbasics.html#you-can-create-functions-like-you-create-variables.",
    "title": "Python Basics",
    "section": "You can create functions like you create variables.",
    "text": "You can create functions like you create variables.\ndef myfunction(arg1, arg2, ... ):\n    statements\n    return object\nA real example:\ndef get_last_value(some_list):\n  return some_list[len(some_list) - 1]\n\n# But you can do this with some_list[-1]"
  },
  {
    "objectID": "slides/pythonbasics.html#you-can-use-the-for-operator-to-iterate-through-a-list.",
    "href": "slides/pythonbasics.html#you-can-use-the-for-operator-to-iterate-through-a-list.",
    "title": "Python Basics",
    "section": "You can use the for operator to iterate through a list.",
    "text": "You can use the for operator to iterate through a list.\nmylist = [5,6,7,8]\nfor item in mylist:\n  addone = item + 1\n  print(addone)"
  },
  {
    "objectID": "slides/pythonbasics.html#you-can-use-if-and-else-to-set-conditions.",
    "href": "slides/pythonbasics.html#you-can-use-if-and-else-to-set-conditions.",
    "title": "Python Basics",
    "section": "You can use if and else to set conditions.",
    "text": "You can use if and else to set conditions.\n# Let's use the range() function to make a list\nnewlist = range(1,11) \nfor i in newlist:\n  if i-5 == 0:\n    print(\"It's five!\")\n  elif i-5 == 5:\n    print(\"It's ten!\")\n  else:\n    print(\"Nope, try again...\")"
  },
  {
    "objectID": "slides/pythonbasics.html#you-try-it-3",
    "href": "slides/pythonbasics.html#you-try-it-3",
    "title": "Python Basics",
    "section": "You Try It!",
    "text": "You Try It!\n\nLoop through the list you created in the last exercise.\nPrint each item one-by-one."
  },
  {
    "objectID": "slides/pythonbasics.html#librariespackages-contain-reusable-functions-made-by-someone-else.",
    "href": "slides/pythonbasics.html#librariespackages-contain-reusable-functions-made-by-someone-else.",
    "title": "Python Basics",
    "section": "Libraries/Packages contain reusable functions made by someone else.",
    "text": "Libraries/Packages contain reusable functions made by someone else.\n# Install libraries only once in the Terminal \npip install packagename\n\n# Import a library every time you run your code\nimport packagename\n\n# You can also rename packages to make it easier\nimport packagename as pn"
  },
  {
    "objectID": "slides/pythonbasics.html#you-try-it-4",
    "href": "slides/pythonbasics.html#you-try-it-4",
    "title": "Python Basics",
    "section": "You Try It!",
    "text": "You Try It!\nImport the pandas package and abbreviate it pd. If it works, there will be no output!"
  },
  {
    "objectID": "slides/pythonbasics.html#all-this-and-more-in-chapters-2-3-of-python-for-data-analysis",
    "href": "slides/pythonbasics.html#all-this-and-more-in-chapters-2-3-of-python-for-data-analysis",
    "title": "Python Basics",
    "section": "All this and more in Chapters 2 & 3 of Python for Data Analysis!",
    "text": "All this and more in Chapters 2 & 3 of Python for Data Analysis!"
  },
  {
    "objectID": "slides/regression.html#we-can-use-correlation-coefficients-and-correlation-tests-to-learn-the-strength-of-a-relationship-but-how-do-we-learn-the-nature-of-a-relationship",
    "href": "slides/regression.html#we-can-use-correlation-coefficients-and-correlation-tests-to-learn-the-strength-of-a-relationship-but-how-do-we-learn-the-nature-of-a-relationship",
    "title": "Linear Regression",
    "section": "We can use correlation coefficients and correlation tests to learn the strength of a relationship, but how do we learn the nature of a relationship?",
    "text": "We can use correlation coefficients and correlation tests to learn the strength of a relationship, but how do we learn the nature of a relationship?"
  },
  {
    "objectID": "slides/regression.html#questions-we-might-want-to-answer-with-regression",
    "href": "slides/regression.html#questions-we-might-want-to-answer-with-regression",
    "title": "Linear Regression",
    "section": "Questions we might want to answer with regression:",
    "text": "Questions we might want to answer with regression:\n\nDoes x influence y?\nIs crop growth rate improved by fertilizer?\nDo taller sprinters run faster?"
  },
  {
    "objectID": "slides/regression.html#linear-prediction-models-also-called-regression-models-help-us-to-answer-these-kind-of-questions-which-explore-relationships.",
    "href": "slides/regression.html#linear-prediction-models-also-called-regression-models-help-us-to-answer-these-kind-of-questions-which-explore-relationships.",
    "title": "Linear Regression",
    "section": "Linear prediction models, also called regression models, help us to answer these kind of questions, which explore relationships.",
    "text": "Linear prediction models, also called regression models, help us to answer these kind of questions, which explore relationships."
  },
  {
    "objectID": "slides/regression.html#a-prediction-model-analyzes-data-that-the-researcher-you-supplies-and-calculates-numerical-coefficients-to-help-with-prediction.",
    "href": "slides/regression.html#a-prediction-model-analyzes-data-that-the-researcher-you-supplies-and-calculates-numerical-coefficients-to-help-with-prediction.",
    "title": "Linear Regression",
    "section": "A prediction model analyzes data that the researcher (you!) supplies, and calculates numerical coefficients to help with prediction.",
    "text": "A prediction model analyzes data that the researcher (you!) supplies, and calculates numerical coefficients to help with prediction."
  },
  {
    "objectID": "slides/regression.html#linear-regression-is-just-one-type-of-prediction-model",
    "href": "slides/regression.html#linear-regression-is-just-one-type-of-prediction-model",
    "title": "Linear Regression",
    "section": "Linear regression is just one type of prediction model!",
    "text": "Linear regression is just one type of prediction model!"
  },
  {
    "objectID": "slides/regression.html#for-many-kinds-of-data-it-is-possible-to-fit-a-line-to-a-set-of-data-points.",
    "href": "slides/regression.html#for-many-kinds-of-data-it-is-possible-to-fit-a-line-to-a-set-of-data-points.",
    "title": "Linear Regression",
    "section": "For many kinds of data, it is possible to “fit” a line to a set of data points.",
    "text": "For many kinds of data, it is possible to “fit” a line to a set of data points."
  },
  {
    "objectID": "slides/regression.html#that-line-represents-the-connection-between-an-________-x-axis-and-a-________-y-axis-variable.",
    "href": "slides/regression.html#that-line-represents-the-connection-between-an-________-x-axis-and-a-________-y-axis-variable.",
    "title": "Linear Regression",
    "section": "That line represents the connection between an ________ (x-axis) and a ________ (y-axis) variable.",
    "text": "That line represents the connection between an ________ (x-axis) and a ________ (y-axis) variable."
  },
  {
    "objectID": "slides/regression.html#and-in-this-case-the-target-dependent-variable-is-a-function-of-the-predictor-independent-variables.",
    "href": "slides/regression.html#and-in-this-case-the-target-dependent-variable-is-a-function-of-the-predictor-independent-variables.",
    "title": "Linear Regression",
    "section": "And in this case, the target (dependent) variable is a function of the predictor (independent) variables.",
    "text": "And in this case, the target (dependent) variable is a function of the predictor (independent) variables.\nWhen using linear regression for prediction, you typically have more than one \\(x\\) (predictor) variable—sometimes you have hundreds!"
  },
  {
    "objectID": "slides/regression.html#to-define-predictors-and-a-target-variable-you-need-to-use-your-human-brain.",
    "href": "slides/regression.html#to-define-predictors-and-a-target-variable-you-need-to-use-your-human-brain.",
    "title": "Linear Regression",
    "section": "To define predictors and a target variable, you need to use your human brain.",
    "text": "To define predictors and a target variable, you need to use your human brain.\nCome up with a rationale for why you think they would be related."
  },
  {
    "objectID": "slides/regression.html#this-does-not-mean-that-x-causes-y-a-regression-cant-show-that.",
    "href": "slides/regression.html#this-does-not-mean-that-x-causes-y-a-regression-cant-show-that.",
    "title": "Linear Regression",
    "section": "This does not mean that x causes y! A regression can’t show that.",
    "text": "This does not mean that x causes y! A regression can’t show that.\nIt’s not a good idea to just try to regress any set of variables together.\nCorrelation does not mean causation!!"
  },
  {
    "objectID": "slides/regression.html#regression-can-be-for-explanation-or-prediction.",
    "href": "slides/regression.html#regression-can-be-for-explanation-or-prediction.",
    "title": "Linear Regression",
    "section": "Regression can be for explanation or prediction.",
    "text": "Regression can be for explanation or prediction."
  },
  {
    "objectID": "slides/regression.html#ymxb",
    "href": "slides/regression.html#ymxb",
    "title": "Linear Regression",
    "section": "\\(Y=mX+b\\)",
    "text": "\\(Y=mX+b\\)\nCan also be written as: \\(Y=b_{1}X+b_{0}\\)"
  },
  {
    "objectID": "slides/regression.html#yb_1xb_0",
    "href": "slides/regression.html#yb_1xb_0",
    "title": "Linear Regression",
    "section": "\\(Y=b_{1}X+b_{0}\\)",
    "text": "\\(Y=b_{1}X+b_{0}\\)\n\\(Y\\) is your target (dependent) variable.\n\\(X\\) is your predictor (independent) variable. (There will eventually be many predictors.)"
  },
  {
    "objectID": "slides/regression.html#yb_1xb_0-1",
    "href": "slides/regression.html#yb_1xb_0-1",
    "title": "Linear Regression",
    "section": "\\(Y=b_{1}X+b_{0}\\)",
    "text": "\\(Y=b_{1}X+b_{0}\\)\nCoefficients:\n\\(b_{1}\\) (or \\(m\\)) describes the slope of the line (and its direction).\n\\(b_{0}\\) (or \\(b\\)) describes the height of the line when \\(X\\) is 0. This is called the y-intercept or simply the intercept."
  },
  {
    "objectID": "slides/regression.html#we-can-provide-numeric-variables-x-and-y-and-python-will-calculate-the-b_0-and-b_1-values.",
    "href": "slides/regression.html#we-can-provide-numeric-variables-x-and-y-and-python-will-calculate-the-b_0-and-b_1-values.",
    "title": "Linear Regression",
    "section": "We can provide numeric variables (\\(X\\) and \\(Y\\)), and Python will calculate the \\(b_{0}\\) and \\(b_{1}\\) values.",
    "text": "We can provide numeric variables (\\(X\\) and \\(Y\\)), and Python will calculate the \\(b_{0}\\) and \\(b_{1}\\) values.\nThis is what it means to “fit” a linear model."
  },
  {
    "objectID": "slides/regression.html#in-theory-if-you-know-any-b_0-and-b_1-you-can-use-any-new-x-value-to-predict-a-y-value.-wow",
    "href": "slides/regression.html#in-theory-if-you-know-any-b_0-and-b_1-you-can-use-any-new-x-value-to-predict-a-y-value.-wow",
    "title": "Linear Regression",
    "section": "In theory, if you know any \\(b_{0}\\) and \\(b_{1}\\), you can use any new X value to predict a Y value. Wow!",
    "text": "In theory, if you know any \\(b_{0}\\) and \\(b_{1}\\), you can use any new X value to predict a Y value. Wow!"
  },
  {
    "objectID": "slides/regression.html#bivariate-regression-is-great-at-explanation-but-lousy-at-prediction.",
    "href": "slides/regression.html#bivariate-regression-is-great-at-explanation-but-lousy-at-prediction.",
    "title": "Linear Regression",
    "section": "Bivariate regression is great at explanation but lousy at prediction.",
    "text": "Bivariate regression is great at explanation but lousy at prediction."
  },
  {
    "objectID": "slides/regression.html#multiple-regression-lets-you-add-more-independent-variables.",
    "href": "slides/regression.html#multiple-regression-lets-you-add-more-independent-variables.",
    "title": "Linear Regression",
    "section": "Multiple Regression lets you add more independent variables.",
    "text": "Multiple Regression lets you add more independent variables.\nBivariate regression:\n\\(Y=b_{0}+b_{1}x\\)\nMultivariate regression:\n\\(Y=b_{0}+b_{1}x_{1}+b_{2}x_{2}+b_{3}x_{3}+...\\)"
  },
  {
    "objectID": "slides/regression.html#you-can-add-more-variables-as-predictors.",
    "href": "slides/regression.html#you-can-add-more-variables-as-predictors.",
    "title": "Linear Regression",
    "section": "You can add more variables as predictors.",
    "text": "You can add more variables as predictors.\nAs many as you want, but make sure you develop a rationale (use your human brain)!"
  },
  {
    "objectID": "slides/regression.html#always-start-with-exploratory-analysis.",
    "href": "slides/regression.html#always-start-with-exploratory-analysis.",
    "title": "Linear Regression",
    "section": "Always start with exploratory analysis.",
    "text": "Always start with exploratory analysis.\nDo you have good reason to believe that a linear regression or predictive model would help? Is there a relationship between variables that’s worth learning about?\nLet’s make a scatter plot of engine displacement and fuel efficiency, in the cars dataset."
  },
  {
    "objectID": "slides/regression.html#it-looks-like-there-might-be-a-linear-relationship",
    "href": "slides/regression.html#it-looks-like-there-might-be-a-linear-relationship",
    "title": "Linear Regression",
    "section": "It looks like there might be a linear relationship!",
    "text": "It looks like there might be a linear relationship!\nWe can see a general trend: as engine size goes up, fuel efficiency goes down. Now we’re ready to try modeling this relationship as part of a larger linear regression model."
  },
  {
    "objectID": "slides/regression.html#beware",
    "href": "slides/regression.html#beware",
    "title": "Linear Regression",
    "section": "Beware!",
    "text": "Beware!\n\nxkcd.com/1725"
  },
  {
    "objectID": "slides/regression.html#but-wait-at-every-step-of-the-modeling-process-we-must-validate.",
    "href": "slides/regression.html#but-wait-at-every-step-of-the-modeling-process-we-must-validate.",
    "title": "Linear Regression",
    "section": "But wait! At every step of the modeling process, we must validate.",
    "text": "But wait! At every step of the modeling process, we must validate."
  },
  {
    "objectID": "slides/regression.html#how-do-you-choose-and-validate-predictor-variables",
    "href": "slides/regression.html#how-do-you-choose-and-validate-predictor-variables",
    "title": "Linear Regression",
    "section": "How do you choose and validate predictor variables?",
    "text": "How do you choose and validate predictor variables?\nThere’s no magic solution! You can try different options, but use your logic and don’t just throw everything in there."
  },
  {
    "objectID": "slides/regression.html#occams-razor-says-that-the-simplest-model-is-probably-the-best-one.",
    "href": "slides/regression.html#occams-razor-says-that-the-simplest-model-is-probably-the-best-one.",
    "title": "Linear Regression",
    "section": "Occam’s Razor says that the simplest model is probably the best one.",
    "text": "Occam’s Razor says that the simplest model is probably the best one.\n\nThink carefully about how many variables you add."
  },
  {
    "objectID": "slides/regression.html#avoid-multicollinearity-when-two-predictor-variables-correlate.",
    "href": "slides/regression.html#avoid-multicollinearity-when-two-predictor-variables-correlate.",
    "title": "Linear Regression",
    "section": "Avoid Multicollinearity: when two predictor variables correlate.",
    "text": "Avoid Multicollinearity: when two predictor variables correlate.\nThis will confuse the model and mess up your results! It could even result in false predictions.\nYou must test for multicollinearity before you select your predictors and run your model."
  },
  {
    "objectID": "slides/regression.html#how-do-we-find-multicollinearity",
    "href": "slides/regression.html#how-do-we-find-multicollinearity",
    "title": "Linear Regression",
    "section": "How do we find multicollinearity?",
    "text": "How do we find multicollinearity?\nYou can do a pairwise comparison of the variables you’re thinking about.\n\npotential_predictors = ['Cylinders', 'Displacement', 'Horsepower',\n       'Weight_in_lbs', 'Acceleration']\nalt.Chart(cars).mark_point().encode(\n    alt.X(alt.repeat(\"column\"), type='quantitative'),\n    alt.Y(alt.repeat(\"row\"), type='quantitative')\n).properties(\n    width=150,\n    height=150\n).repeat(\n    row=potential_predictors,\n    column=potential_predictors\n)"
  },
  {
    "objectID": "slides/regression.html#how-do-we-find-multicollinearity-output",
    "href": "slides/regression.html#how-do-we-find-multicollinearity-output",
    "title": "Linear Regression",
    "section": "How do we find multicollinearity?",
    "text": "How do we find multicollinearity?"
  },
  {
    "objectID": "slides/regression.html#compare-your-pairplot-to-the-correlation-matrix.",
    "href": "slides/regression.html#compare-your-pairplot-to-the-correlation-matrix.",
    "title": "Linear Regression",
    "section": "Compare your pairplot to the correlation matrix.",
    "text": "Compare your pairplot to the correlation matrix."
  },
  {
    "objectID": "slides/regression.html#when-interpreting-coefficients-watch-out-for-confounding-variables",
    "href": "slides/regression.html#when-interpreting-coefficients-watch-out-for-confounding-variables",
    "title": "Linear Regression",
    "section": "When interpreting coefficients, watch out for confounding variables!",
    "text": "When interpreting coefficients, watch out for confounding variables!\nAsk yourself: is there an important variable that the data doesn’t account for?"
  },
  {
    "objectID": "slides/regression.html#for-statistical-modeling-in-python-we-can-use-sklearn.",
    "href": "slides/regression.html#for-statistical-modeling-in-python-we-can-use-sklearn.",
    "title": "Linear Regression",
    "section": "For statistical modeling in Python, we can use sklearn.",
    "text": "For statistical modeling in Python, we can use sklearn.\n# You only need to import the functions you will use\n# This may be different every time\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score"
  },
  {
    "objectID": "slides/regression.html#the-scikit-learn-modeling-workflow",
    "href": "slides/regression.html#the-scikit-learn-modeling-workflow",
    "title": "Linear Regression",
    "section": "The scikit-learn modeling workflow",
    "text": "The scikit-learn modeling workflow\n\nChoose your model\nChoose predictor and target variables, test for validity\nSplit the data into train and test portions\nFit the model to your training data\nSummarize or predict based on the model\nValidate and assess the model\n\nFull scikit-learn documentation here"
  },
  {
    "objectID": "slides/regression.html#why-do-we-split-the-data",
    "href": "slides/regression.html#why-do-we-split-the-data",
    "title": "Linear Regression",
    "section": "Why do we split the data?",
    "text": "Why do we split the data?\nA training set will determine the model’s coefficients, and a test set will let us see how well it works on new data that it hasn’t already seen."
  },
  {
    "objectID": "slides/regression.html#first-we-select-our-model-linear-regression",
    "href": "slides/regression.html#first-we-select-our-model-linear-regression",
    "title": "Linear Regression",
    "section": "First we select our model: linear regression",
    "text": "First we select our model: linear regression\nThat’s why we imported the LinearRegression class above."
  },
  {
    "objectID": "slides/regression.html#the-full-model-workflow",
    "href": "slides/regression.html#the-full-model-workflow",
    "title": "Linear Regression",
    "section": "The full model workflow",
    "text": "The full model workflow\n# Select target and predictors based on validation\ntarget = \"Miles_per_Gallon\" # Our target variable\npredictors = [\"Displacement\", \"Horsepower\", \"Acceleration\"] # A list of predictors\n\n# Create variables and split data\nX = cars[predictors]\ny = cars[target]\nX_train, X_test, y_train, y_test = train_test_split(\n    X, \n    y, \n    test_size=0.4, \n    random_state=0)\n\n# Fit the model\nour_model = LinearRegression()\nour_model.fit(X_train, y_train)\n\n# View coefficients\nprint(f\"Intercept: {our_model.intercept_:.3f}\")\nfor c,p in zip(our_model.coef_,X.columns):\n    print(f\"Coefficient for {p}: {c:.4f}\")"
  },
  {
    "objectID": "slides/regression.html#interpreting-the-results",
    "href": "slides/regression.html#interpreting-the-results",
    "title": "Linear Regression",
    "section": "Interpreting the results",
    "text": "Interpreting the results\nWith a coefficient for displacement of -0.0384, this linear regression provides evidence that as engine displacment increases, fuel efficiency decreases slightly!\nFor every additional unit of engine displacement, the expected fuel efficiency decreases by 0.0384.\nWhat would the other coefficients mean?\nThe intercept indicates that if all predictor variables were 0, fuel efficiency would be 45.392 miles per gallon. Why doesn’t this number make any sense?\nBe careful not to imply that there is a direct causal link, especially without more evidence or studies."
  },
  {
    "objectID": "slides/regression.html#you-can-consider-categorical-variables-as-predictors-too.",
    "href": "slides/regression.html#you-can-consider-categorical-variables-as-predictors-too.",
    "title": "Linear Regression",
    "section": "You can consider categorical variables as predictors, too.",
    "text": "You can consider categorical variables as predictors, too.\nReference coding converts categorical variables to a set of binary variables.\nX = pd.get_dummies(cars[predictors], drop_first=True)\nThe first category should always be left out as the reference (drop_first=True). All the remaining slopes are relative to that reference!"
  },
  {
    "objectID": "slides/regression.html#did-our-model-do-a-good-job",
    "href": "slides/regression.html#did-our-model-do-a-good-job",
    "title": "Linear Regression",
    "section": "Did our model do a good job?",
    "text": "Did our model do a good job?"
  },
  {
    "objectID": "slides/regression.html#lets-predict-based-on-our-model.",
    "href": "slides/regression.html#lets-predict-based-on-our-model.",
    "title": "Linear Regression",
    "section": "Let’s predict based on our model.",
    "text": "Let’s predict based on our model.\nThe predict() method uses coefficients to calculate new values.\n# Let's focus on out-of-sample prediction for validation\npredictions = our_model.predict(X_test)\npredictions\nWe can predict with our training data (in-sample prediction) or with our test data (out-of-sample prediction)."
  },
  {
    "objectID": "slides/regression.html#we-can-look-at-the-predictions-fitted-values-compared-to-the-residuals.",
    "href": "slides/regression.html#we-can-look-at-the-predictions-fitted-values-compared-to-the-residuals.",
    "title": "Linear Regression",
    "section": "We can look at the predictions (fitted values) compared to the residuals.",
    "text": "We can look at the predictions (fitted values) compared to the residuals.\nResiduals are the differences between the actual observed values and the ones the model predicted.\n# Our out-of-sample residuals:\nresiduals = y_test - predictions\nresiduals\nThink of these as the “errors” that the modeling method produced. If the residuals are symmetrically distributed with the median close to zero, the model may fit the data well."
  },
  {
    "objectID": "slides/regression.html#root-mean-squared-error-measures-how-much-the-residuals-stray-from-the-fitted-values.",
    "href": "slides/regression.html#root-mean-squared-error-measures-how-much-the-residuals-stray-from-the-fitted-values.",
    "title": "Linear Regression",
    "section": "Root Mean Squared Error measures how much the residuals stray from the fitted values.",
    "text": "Root Mean Squared Error measures how much the residuals stray from the fitted values.\n# The raw value, in-sample\nnp.sqrt(mean_squared_error(y_test, predictions))\n\n# Or neatly printed\nprint(f\"Root mean squared error: {np.sqrt(mean_squared_error(y_test, predictions)):.2f}\")\nThis is a good metric for comparing models."
  },
  {
    "objectID": "slides/regression.html#r2-shows-the-amount-proportion-of-variation-in-y-that-is-accounted-for-by-x.",
    "href": "slides/regression.html#r2-shows-the-amount-proportion-of-variation-in-y-that-is-accounted-for-by-x.",
    "title": "Linear Regression",
    "section": "\\(R^{2}\\) shows the amount (proportion) of variation in \\(Y\\) that is accounted for by \\(X\\).",
    "text": "\\(R^{2}\\) shows the amount (proportion) of variation in \\(Y\\) that is accounted for by \\(X\\).\nprint(f\"Coefficient of determination: {r2_score(y_test, predictions):.2f}\")\nThis is also called the “coefficient of determination.”\n\\(R^{2}\\) ranges from 0 to 1. If it were 1, the variables would make a straight line. If it were 0, the x variable wouldn’t predict the y variable at all."
  },
  {
    "objectID": "slides/regression.html#interpreting-validation-scores",
    "href": "slides/regression.html#interpreting-validation-scores",
    "title": "Linear Regression",
    "section": "Interpreting Validation Scores",
    "text": "Interpreting Validation Scores\nIn this example, \\(R^{2}=0.67\\), so our predictors account for about 67% of the variation in fuel efficiency.\nThere’s no rule for what makes an \\(R^{2}\\) “good.” Consider the context and purpose of your analysis!\nIn an analysis of ecology or human behavior (very unpredictable) an \\(R^{2}\\) of 0.20 or 0.30, might be considered good. In an analysis predicting mechanical repairs, or recovery from medical procedures, an \\(R^{2}\\) of 0.60 or 0.70 might be considered very poor."
  },
  {
    "objectID": "slides/regression.html#as-you-add-variables-r2-will-increase-and-rmse-will-decrease.",
    "href": "slides/regression.html#as-you-add-variables-r2-will-increase-and-rmse-will-decrease.",
    "title": "Linear Regression",
    "section": "As you add variables, \\(R^{2}\\) will increase and RMSE will decrease.",
    "text": "As you add variables, \\(R^{2}\\) will increase and RMSE will decrease.\nBut think about how much it increases or decreases."
  },
  {
    "objectID": "slides/regression.html#are-the-residuals-normally-distributed-with-a-mean-near-0",
    "href": "slides/regression.html#are-the-residuals-normally-distributed-with-a-mean-near-0",
    "title": "Linear Regression",
    "section": "Are the residuals normally distributed, with a mean near 0?",
    "text": "Are the residuals normally distributed, with a mean near 0?\n# First put the results into a dataframe\nresults = pd.DataFrame({'Predictions': predictions, 'Residuals':residuals})\n\nalt.Chart(results, title=\"Histogram of Residuals\").mark_bar().encode(\n    x=alt.X('Residuals:Q', title=\"Residuals\").bin(maxbins=20),\n    y=alt.Y('count():Q', title=\"Value Counts\")\n)\nYou could also use a Q-Q plot for this!"
  },
  {
    "objectID": "slides/regression.html#does-the-model-suggest-heteroskedasticity",
    "href": "slides/regression.html#does-the-model-suggest-heteroskedasticity",
    "title": "Linear Regression",
    "section": "Does the model suggest heteroskedasticity?",
    "text": "Does the model suggest heteroskedasticity?\nIs the variance consistent across the range of predicted values?\n# Plot the absolute value of residuals against the predicted values\nchart = alt.Chart(results, title=\"Testing for Heteroskedasticity\").mark_point().encode(\n    x=alt.X('Predictions:Q').title(\"Predicted Values\"),\n    y=alt.Y('y:Q').title(\"Absolute value of Residuals\") \n).transform_calculate(y='abs(datum.Residuals)')\n\nchart + chart.transform_loess('Predictions', 'y').mark_line()\nIf the line is horizontal, there’s no heterskedasticity."
  },
  {
    "objectID": "slides/regression.html#other-validation-methods",
    "href": "slides/regression.html#other-validation-methods",
    "title": "Linear Regression",
    "section": "Other validation methods",
    "text": "Other validation methods\n\nFinding Outliers\nCook’s Distance and Leverage\nCheck for independence of errors\nPartial residual plots"
  },
  {
    "objectID": "slides/regression.html#lets-try-these-validation-steps-with-your-seattle-housing-models",
    "href": "slides/regression.html#lets-try-these-validation-steps-with-your-seattle-housing-models",
    "title": "Linear Regression",
    "section": "Let’s try these validation steps with your Seattle housing models!",
    "text": "Let’s try these validation steps with your Seattle housing models!"
  },
  {
    "objectID": "how-to-explain.html",
    "href": "how-to-explain.html",
    "title": "How to Explain in CIS241",
    "section": "",
    "text": "This file includes code and examples for explaining graphs and statistical output in DA101. Communicating results is a crucial part of good data analysis, and we try to communicate all results completely and accurately and in terms of the data.\nThese short examples are designed to give you general guidance. I cannot provide a comprehensive example or answer that you could “copy” every time to have an A+ explanation, but I can provide an example and some pointers to help you get started.\n(This is adapted from “How to explain in DA101”.)"
  },
  {
    "objectID": "how-to-explain.html#how-to-explain-a-visualization",
    "href": "how-to-explain.html#how-to-explain-a-visualization",
    "title": "How to Explain in CIS241",
    "section": "1 How to Explain a Visualization",
    "text": "1 How to Explain a Visualization\nThe way you explain your graphs will change throughout the semester as you learn more details about what the graph shows and also learn more technical lingo for how to identify different aspects of the graph, including visual interpretation of summary statistics, and how to identify potentially significant differences or outliers.\nIn the beginning of class (let’s say weeks 1-2) I won’t assume you have prior technical knowledge of data analysis, and it is okay to stick to general descriptive and observational descriptions of what you’re seeing in a graph that you make. What are you noticing? What stands out to you? Do you see anything that looks like a pattern in the points or that indicates similarity among groups?\nLater on (let’s say weeks 3+) you will increasingly gain technical language to be able to talk about your graphs and describe your observations. As you gain these skills you can still describe what you are noticing and seeing in your graphs, but you will increasingly describe summary statistics…\n\n1.1 Explaining a Boxplot\n\n\nCode\nimport pandas as pd\nimport altair as alt\nimport numpy as np\n\nmpg = pd.read_csv(\"workshops/sample_data/mpg.csv\")\nmpg.drop(\"Unnamed: 0\",axis=1,inplace=True)\n\n\n\n\nCode\nalt.Chart(mpg, title=\"Fuel Efficiency Among Different Vehicle Types\").mark_boxplot(size=40).encode(\n    x=alt.X(\"class:N\", title=\"Type or Class of Vehicle\"),\n    y=alt.Y(\"hwy:Q\", title=\"Highway miles per gallon\"),\n    color=alt.Color(\"class:N\", legend=None)\n).properties(width=500)\n\n\n\n\n\n\n\n\n\n1.1.1 Basic Explanation (Weeks 1-2)\nThis boxplot of the mpg data set shows the distributions of highway fuel efficiency across the seven different kinds of cars in the data. Pickups and SUVs seem to have lower fuel efficiency than the other cars, which makes sense because they are bigger, heavier vehicles. Smaller vehicles like compact and midsize cars have greater fuel efficiency, and subcompacts have similarly high fuel efficiency but the data seems to be more spread out because the box is longer. Overall it seems like vehicle class is related to fuel efficiency, with smaller cars tending to have greater efficiency.\n\n\n1.1.2 Detailed Explanation (Weeks 3+)\nThis boxplot of the mpg data set shows the distributions of highway fuel efficiency across the seven different kinds of cars in the data. Pickups and SUVs have medians and interquartile ranges well below the other vehicles, suggesting a statistically significant difference. Compact cars have a nearly identical IQR and median to midsize cars, as evidenced by the size of the two boxes, though there are a handful of outliers in the compact group. Subcompacts have a larger interquartile range than any of the other groups, which suggests greater variability in their fuel efficiency distribution. Overall the graph suggests that larger vehicle classes tend to have lower fuel efficiency distributions, while smaller vehicles seem to have greater fuel efficiency.\n\n\n\n1.2 Explaining a Scatterplot\n\n\nCode\nalt.Chart(mpg, title=\"Relationship Between Engine Size and City Fuel Efficiency\").mark_point().encode(\n    x=alt.X(\"displ:Q\", title=\"Engine Displacement, in liters\").scale(zero=False),\n    y=alt.Y(\"cty:Q\", title=\"City miles per gallon\").scale(zero=False)\n).properties(width=500).interactive()\n\n\n\n\n\n\n\n\n\n1.2.1 Basic Explanation (Weeks 1-2)\nThis scatter plot of the mpg data set shows the relationship between the size of a car’s engine (using the engine displacement variable) and a car’s city fuel efficiency. Because of the downward slope of the dots as the graph goes from left to right, it appears that as engines get bigger the city fuel efficiency gets smaller. After about 4.5 liters the slope levels off, suggesting there isn’t as strong a relationship past this point. Overall, we could conclude that a car’s city fuel efficiency may partially depend on the size of the engine.\n\n\n1.2.2 Detailed Explanation (Weeks 3+)\nThis scatter plot of the mpg data set shows the relationship between the size of a car’s engine (using the engine displacement variable) and a car’s city fuel efficiency. There looks to be a negative correlation between the two variables: as engine displacement goes up, city miles per gallon goes down. Adding a line of best fit to this graph or calculating a correlation coefficient would give us a better indication of the possible correlation. After about 4.5 liters, the points no longer slope downward, which may indicate that after a certain threshold, engine displacement has no direct correlation to fuel efficiency. Overall we could conclude that our dependent variable, city miles per gallon, negatively correlates with our independent variable, engine displacement, and therefore that as engine size gets larger fuel efficiency drops."
  },
  {
    "objectID": "how-to-explain.html#how-to-explain-statistical-output",
    "href": "how-to-explain.html#how-to-explain-statistical-output",
    "title": "How to Explain in CIS241",
    "section": "2 How to explain statistical output",
    "text": "2 How to explain statistical output\nWe will learn several statistical tests and models throughout the semester. In data analysis, there is much more to do than to simply write the code for the model and generate “correct” output or report a p-value. In most cases, explaining the output and validation from the models will require several sentences that help to translate the quantitative results in terms of the data. In general, when running these models and interpreting output, there are a few key things to keep in mind.\n\nDo you have a logical reason for running the test or model?\nAfter you’ve run the code, were you able to calculate and report the key values from the statistical output?\nAfter you have identified and reported the key values, can you connect them back to the data and the question at hand?\nFinally, can you describe the results in terms of statistical and practical significance?\n\nI’ll provide a few examples below to walk through a t-test, a correlation test, and a linear regression. These are not “perfect” or “set in stone” formats for explaining, but rather think of them as an aid to thought to help guide you in your journey of learning how to explain and translate like a data analyst.\n\n2.1 Explaining a permutation test for comparing means\n\n\nCode\ndef simulate_two_groups(data1, data2):\n    n, m = len(data1), len(data2)\n    data = np.append(data1, data2)\n    np.random.shuffle(data)\n    group1 = data[:n]\n    group2 = data[n:]\n    return group1.mean() - group2.mean()\n\ncompact_hwy = mpg[mpg[\"class\"] == \"compact\"].hwy\nmidsize_hwy = mpg[mpg[\"class\"] == \"midsize\"].hwy\nprint(f\"Mean mpg of compact: {compact_hwy.mean():.2f}\")\nprint(f\"Mean mpg of midsize: {midsize_hwy.mean():.2f}\")\n\nobserved_diff = compact_hwy.mean()-midsize_hwy.mean()\nprint(f\"Difference in means of compact and midsize cars: {observed_diff:.3f} miles per gallon\")\n\nmean_perms = pd.DataFrame({\"mean_perms\":[simulate_two_groups(compact_hwy,midsize_hwy) for i in range(10000)]})\n\n\nMean mpg of compact: 28.30\nMean mpg of midsize: 27.29\nDifference in means of compact and midsize cars: 1.005 miles per gallon\n\n\n\n\nCode\nalt.data_transformers.disable_max_rows() # Don't limit the data\n# Create a histogram\nhistogram = alt.Chart(mean_perms).mark_bar().encode(\n    x=alt.X(\"mean_perms:Q\").bin(maxbins=50),\n    y=alt.Y(\"count():Q\")\n).properties(width=500)\nmean_perms = mean_perms.assign(mean_diff=observed_diff) # Add the mean to the dataframe\n# Add a vertical line\nobserved_difference = alt.Chart(mean_perms).mark_rule(color=\"red\", strokeDash=(8,4)).encode(\n    x=alt.X(\"mean_diff\")\n)\n# Combine the two plots\nhistogram + observed_difference\n\n\n\n\n\n\n\n\n\n\nCode\np_value = np.mean(mean_perms.mean_perms &gt; observed_diff)\nprint(f\"p-value = {p_value}\")\n\n\np-value = 0.0641\n\n\nThe permutation test suggests there is no significant difference in the mean highway miles per gallon of the midsize and compact vehicle classes (p=0.06), though the p-value is very close to 0.05. I was expecting this because these vehicles are very similar in size and because their ranges seem to overlap on the boxplot. The true difference in the means is 1.005 miles per gallon, which doesn’t seem like very much. The mean highway miles per gallon used for compact cars was 28.30 mpg and the mean for midsize cars was 27.29 mpg. The result is not statistically significant, and it’s not practically significant either (1 more mile per gallon doesn’t seem like that much greater fuel efficiency).\n\n\n2.2 Explaining a Linear Regression\n\n\nCode\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n\nTarget variable: miles per gallon city (cty)\nPredictor variables: engine displacement (displ), model year (year), number of cylinders (cyl), vehicle class (class)\n\n\nCode\ntarget = \"cty\"\npredictors = [\"displ\", \"year\", \"cyl\", \"class\"]\n\nalt.Chart(mpg).mark_point().encode(\n    alt.X(alt.repeat(\"column\"), type='quantitative'),\n    alt.Y(alt.repeat(\"row\"), type='quantitative')\n).properties(\n    width=150,\n    height=150\n).repeat(\n    row=[\"displ\", \"year\", \"cyl\"],\n    column=[\"displ\", \"year\", \"cyl\"]\n)\n\n\n\n\n\n\n\n\n\n\nCode\nmpg[predictors].corr(numeric_only=True)\n\n\n\n\n\n\n\n\n\ndispl\nyear\ncyl\n\n\n\n\ndispl\n1.000000\n0.147843\n0.930227\n\n\nyear\n0.147843\n1.000000\n0.122245\n\n\ncyl\n0.930227\n0.122245\n1.000000\n\n\n\n\n\n\n\nThe pairplot and correlation matrix above show correlations for the three numerical predictor variables I chose (engine displacement, model year, and number of cylinders). The last predictor variable, vehicle class, was excluded because it is categorical. As you can see from the steep regression line in the pairplot and the high correlation coefficient of 0.93, engine displacement and number of cylinders are highly correlated. It wouldn’t be valid to use both in a regression model, so I will exclude number of cylinders going forward and use only engine displacement, model year, and vehicle class.\n\n\nCode\npredictors = [\"displ\", \"year\", \"class\"]\n\nX = pd.get_dummies(mpg[predictors], drop_first=True)\nY = mpg[target]\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, \n    Y, \n    test_size=0.4, \n    random_state=0)\n\nour_model = LinearRegression()\nour_model.fit(X_train, y_train)\n\nprint(f\"Intercept: {our_model.intercept_:.3f}\")\nfor c,p in zip(our_model.coef_,X.columns):\n    print(f\"Coefficient for {p}: {c:.4f}\")\n\n\nIntercept: -50.633\nCoefficient for displ: -2.1743\nCoefficient for year: 0.0399\nCoefficient for class_compact: -4.4195\nCoefficient for class_midsize: -4.3175\nCoefficient for class_minivan: -6.2129\nCoefficient for class_pickup: -6.6474\nCoefficient for class_subcompact: -3.6546\nCoefficient for class_suv: -5.7987\n\n\n\n\nCode\npredictions = our_model.predict(X_test)\nresiduals = y_test - predictions\nprint(f\"Root mean squared error: {np.sqrt(mean_squared_error(y_test, predictions)):.2f}\")\nprint(f\"Coefficient of determination (R-squared): {r2_score(y_test, predictions):.2f}\")\n\n\nRoot mean squared error: 2.59\nCoefficient of determination (R-squared): 0.69\n\n\nThis linear regression model looks at the effect engine displacement in liters, the year the vehicle was made, and the type or class of vehicle have on city miles per gallon fuel efficiency. The coefficient for engine displacement suggests a negative relationship: for each liter of engine displacement, city miles per gallon decreases by 2.17. The coefficient for model year suggest that fuel efficiency increases very slightly (0.04 mpg) for each year in which the car is made. Compared to our “baseline” category of a two-seater car, all other vehicle classes have lower fuel efficiency. All of these coefficients make sense: we would expect newer cars that are smaller (like a two-seater with low engine displacement) to have greater fuel efficiency.\n\\(R^2\\) is .69, suggesting that 69% of the variation in city fuel efficiency is accounted for by engine displacement. I am unsure if this result is practically signficant. For a mechanical process like the fuel efficiency of an engine, we might expect to see an \\(R^2\\) higher than 67%. The root mean squared error is 2.59, meaning that the residuals are off on average by more than 2 miles per gallon. This seems like a fair amount and raises some questions about the accuracy of the model.\n\n\nCode\nresults = pd.DataFrame({'Predictions': predictions, 'Residuals':residuals})\n\nalt.Chart(results, title=\"Histogram of Residuals\").mark_bar().encode(\n    x=alt.X('Residuals:Q', title=\"Residuals\").bin(maxbins=20),\n    y=alt.Y('count():Q', title=\"Value Counts\")\n).properties(width=500)\n\n\n\n\n\n\n\n\nThe histogram above shows the distribution of residuals for the model. While it appears that the residuals are centered near 0, there are some outliers to the right of the graph that prevent the residuals from having a normal distribution. This suggests that our model may not be totally reliable.\n\n\nCode\n# Plot the absolute value of residuals against the predicted values\nchart = alt.Chart(results, title=\"Testing for Heteroskedasticity\").mark_point().encode(\n    x=alt.X('Predictions:Q').title(\"Predicted Values\").scale(zero=False),\n    y=alt.Y('y:Q').title(\"Absolute value of Residuals\") \n).transform_calculate(y='abs(datum.Residuals)').properties(width=500)\n\nchart + chart.transform_loess('Predictions', 'y').mark_line()\n\n\n\n\n\n\n\n\nThe above plot shows the predicted values plotted against the absolute value of the residuals. Like in the histogram of residuals, we see a few outliers that are slightly skewing the results. But overall the line across the plot is mostly horizontal, suggesting that we do not see much heteroskedasticity in our model. While our model may not be ideal, it is probably valid."
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "On this page you’ll find prompts for the different assignments in our course, as well as a breakdown of assignments. Additional information about assignments and grading can be found on the Course Policies page.\nSome of these assignments, especially the Weekly Workshops, the Final Project and the Quizzes, will take the form of Jupyter notebook reports. You can refer to the Criteria for Good Reports as a guide to what is expected in these assignments."
  },
  {
    "objectID": "assignments.html#assignment-breakdown",
    "href": "assignments.html#assignment-breakdown",
    "title": "Assignments",
    "section": "Assignment Breakdown",
    "text": "Assignment Breakdown\n\n\n\nAssignment\nPercentage\n\n\n\n\nWeekly Workshops\n20%\n\n\nDocumentation Assignment\n10%\n\n\nTutorial Assignment\n10%\n\n\nTests\n20%\n\n\nFinal Presentation\n10%\n\n\nFinal Project (in 3 stages)\n30%"
  },
  {
    "objectID": "assignments/final-report.html",
    "href": "assignments/final-report.html",
    "title": "Final Written Report",
    "section": "",
    "text": "Complete by: Thursday 1 May at 2pm\nPlease note that I cannot accept any work past this deadline.\nA polished Jupyter Notebook HTML file reporting the results of your final data analysis project. Roughly, 5-7 written pages (though this is hard to measure in a Jupyter notebook, so consider it a guideline). Think about this report as a “final takeaway” of all the skills you’ve learned in class over the semester. Below is a rough structure of your final written report. This should be a ready-to-deliver report with clear section headers and interpretations of any statistical or graphical output (like several of our previous projects).\nIntroduction\n\nProvide a one-to-three paragraph introduction, professionally written, that gives an overview of the essentials someone needs to know to make sense of the data you show.\nConsider some of the ethical and logistical challenges that your data presents, and discuss this in your introduction. Address the ethical issues in your project in terms of the ADSA’s four lenses.\nYou must cite and link to your dataset, and you can use Markdown to create contextual links like so: [text here](website).\n\nData Explanation and Exploration\n\nProvide some details describing the data you are working with. What are the observations? The key variables you will be looking at? Are there any particular challenges in the data you will need to work through or be aware of during analysis?\nProvide four polished visuals that describe the data in a way relevant to your question (descriptive, not related to your statistical model specifically–not a regression plot). No more than two of these should be the same visualization type. Write text that describes the data and what the visuals tell you about your data or decisions you will need to make for the analysis.\n\nStatistical Analysis and Interpretation\n\nProvide at least two distinct statistical models (for example: multivariate regression and hypothesis test; naive bayes classification and Kmeans clustering; logistic regression and random forest classification; etc.) that you interpret correctly and fully in the text. These can be whatever you choose, but you should explain why you chose the model you did, and why they fit the data.\nProvide at least three polished visuals that specifically support and validate the model(s) you have developed (e.g., residual and regression line/scatter, histogram showing normality of data or residuals, confusion matrix, etc.), or help to communicate your main result. Visuals should have captions and be referred to clearly in your text, and they should not all be the same (e.g., not three scatterplots).\nText should fully explain what you show and your findings, to someone who is unfamiliar with your data, code, and models, in terms of the data and in plain language.\n\nConclusions\n\nProvide one or two paragraphs concluding about the data: what does it tell us, what are the limitations to this data/model, and what is one future direction you could envision for future data analysts or data collectors?\nFind at least one secondary reference that is relevant to or supports your insights, and cite it in this section. You may cite a reference by linking directly to it in your markdown [text here](link here), and listing the full citation below the conclusions section. Please ask me if you aren’t sure how to cite references."
  },
  {
    "objectID": "assignments/progress-report.html",
    "href": "assignments/progress-report.html",
    "title": "Progress Report",
    "section": "",
    "text": "Complete by: Tuesday 15 Apr. at class time\nThe report should demonstrate significant coding and data exploration or analysis progress since the previous week. You should be beginning to move beyond initial data wrangling and exploration at this point.\nThe progress report is the final “check-in” before preparing your presentation and final report. I encourage you to use this progress report as a way to reflect on your work so far, and to begin to create visuals, summary statistics, and statistical models that can answer the questions you posed at the beginning of your progress. Consider what you’ll still need to accomplish between now and the final deadline to have a final project you can be proud of, that meets the requirements stated in the Final Written Report prompt.\nYour progress report can be relatively short, but it should contain enough detail to demonstrate significant progress on your coding and analysis since the previous week. More detail will also help you gain useful feedback and help at this stage, setting you up better for writing your final report. Below you can find what must be included in your progress report.\n\n1 paragraph on where you are currently at in your data analysis\nAt least 3 polished visuals using your dataset, well-labeled and described\nDraft of code and explanations for one of your modeling approaches: what method will you use, what will be your target, and what will be your predictors? Begin the modeling process with some visualizations and validation.\nShare something that you have learned\nShare something that you have found difficult, confusing, or haven’t figured out yet\n\nYou will submit this progress report as an exported Jupyter notebook in HTML."
  },
  {
    "objectID": "assignments/tutorial.html",
    "href": "assignments/tutorial.html",
    "title": "Tutorial Assignment",
    "section": "",
    "text": "Complete by: Thursday 6 Mar. at class time\nA great way to learn a new skill is to teach it to others. In this assignment, you’ll make a tutorial to explain a topic from our class."
  },
  {
    "objectID": "assignments/tutorial.html#writing-your-tutorial",
    "href": "assignments/tutorial.html#writing-your-tutorial",
    "title": "Tutorial Assignment",
    "section": "Writing Your Tutorial",
    "text": "Writing Your Tutorial\nThis assignment is based on a similar assignment from Carnegie Mellon. I quote their instructions here:\n\nYour tutorial should be in the form of a Jupyter notebook, which mixes together written markdown and code portions. You will walk your readers through the algorithm, library, methodology, or data that you are presenting, explaining high-level concepts with code examples. You want to make the tutorial read like an actual explanation of the process or technique, not just as a listing of code. As a general rule of thumb, you should have a paragraph or two of prose explaining any function or class method you include in the code.\nAll written prose, code, and figures must be your own work. Note that unlike in homework assignments, you cannot use any writing or code from third-party sources, even with citations. You additionally cannot use any figures from third-party sources (even with citations): if you want to use a figure to explain a concept or idea, you need to create a version of the figure yourself.\n\nThe prose of your tutorial should be at least 1,000 words, but you may need more to get your point across. Make sure there is a good back-and-forth between code and writing, and don’t leave any code unexplained. This should read a little bit like our workshop assignments, but with more detail on exactly what your reader should do.\nChoose a single example data set to work with, either something we’ve used for a previous workshop or the one you used for your documentation assignment. You can’t choose one of the built-in Altair datasets or the exact data from our slides: it should be something from an external CSV. Make sure the data you choose is suitable for the technique you’re explaining."
  },
  {
    "objectID": "assignments/tutorial.html#choosing-a-topic",
    "href": "assignments/tutorial.html#choosing-a-topic",
    "title": "Tutorial Assignment",
    "section": "Choosing a Topic",
    "text": "Choosing a Topic\nYou may choose one of the following topics:\n\nData Wrangling with Pandas (filtering, renaming, grouping, etc.)\nVisualizations with Altair (box plots, scatter plots, histograms, etc.)\nSummary Statistics and Confidence Intervals\nHypothesis testing (to compare two groups)\nCorrelation: visualization and coefficients\nCorrelation: hypothesis test\nLinear Regression\n\nRemember that all of these topics include multiple steps and possibilities. Reach out with questions about what you should cover and/or how to approach the topic.\nIf you’d like to cover a topic that’s not on this list, feel free to ask me about it.\n\nRequirements:\n\nTurn in your tutorial (as an HTML file) via Sakai\nAlso turn in the original data file that you used (ideally a CSV)"
  },
  {
    "objectID": "groundrules.html",
    "href": "groundrules.html",
    "title": "Ground Rules",
    "section": "",
    "text": "These rules are taken almost verbatim from Miriam Posner, and her original version can be found in this tweet.\nTHIS IS NOT A CONTEST. The only way to win is for everyone to win. If anyone has a question in the chat or on the discussion board, don’t hesitate to help.\nYOU ARE NOT BAD AT TECHNOLOGY. That doesn’t even make sense, because technology is not any one thing; it’s a whole bunch of different skills, and it’s really unlikely that you’re bad at all of them.\nYOUR MISTAKE IS ALMOST INVARIABLY MINOR. This is really common when people are learning new coding skills for the first time. I have seen people give up in frustration because they can’t remember where they saved their file. THIS IS FIXABLE. It does not mean you are a hopeless case!\nNO ONE IS AN EXPERT AT EVERYTHING. You just can’t be on the cutting edge of exploratory data analysis, statistical modeling, Python, data visualization, network analysis, GIS, etc., etc. Even seasoned experts are usually only great at one or two of these. Our goal here is to be good generalists!\nWE DO NOT SINK OR SWIM IN MY CLASS. There is no shame in reaching out to me or your classmates for help. Everyone swims or no one swims!"
  },
  {
    "objectID": "jupyterhub.html",
    "href": "jupyterhub.html",
    "title": "Setting Up JupyterHub",
    "section": "",
    "text": "This page will help you get set up to use Python and JupyterHub, a data science and programming interface. You will use the Jupyter Notebook file 00_getting_started.ipynb.\nhttps://jrladd.com/CIS241/resources/00_getting_started.ipynb\nOr click this link to download the file."
  },
  {
    "objectID": "jupyterhub.html#setting-up-jupyterhub",
    "href": "jupyterhub.html#setting-up-jupyterhub",
    "title": "Setting Up JupyterHub",
    "section": "Setting Up JupyterHub",
    "text": "Setting Up JupyterHub\n\nNavigate to the CIS JupyterHub.\nLog in with your W&J username (the part of your email address before the @). Whatever password you enter for the first time will become your password. KEEP TRACK OF WHAT YOU ENTERED SO THAT YOU DON’T GET LOCKED OUT!\nBookmark this page so you can always get back to JupyterHub.\nThat’s it! You can use this site from any machine, and as long as you save your work, your files will follow you everywhere."
  },
  {
    "objectID": "jupyterhub.html#managing-files",
    "href": "jupyterhub.html#managing-files",
    "title": "Setting Up JupyterHub",
    "section": "Managing Files",
    "text": "Managing Files\n\nOn the left side of the screen you’ll see a list of all the files in your JupyterHub. This won’t show anything yet because you don’t have any files yet.\nTo add a new file, copy this link to our file for today: https://jrladd.com/CIS241/resources/00_getting_started.ipynb. In JupyterHub, select File -&gt; Open from URL at the top of the screen. Paste the URL into the box that appears. The file should now appear in your list! (You could also download the file to your computer and upload it to JupyterHub with the upload button, an upward pointing arrow next to the blue + button.)\nTo create a new blank Notebook file, you can always click the blue + button and select Python 3 under Notebook.\nThe button with a folder and a + on it will let you create a new subfolder. You can then drag files into or out of the various folders. You can organize things however you want, but I recommend developing an organization strategy early that works for you. By the end of the term we’ll have a lot of files! You might create a folder for “workshops” and a folder for “class”, for example.\n\nNow you’re ready to begin! Read through the Getting Started notebook and follow the instructions. You don’t need to code anything yourself today—just follow the examples and get a feel for how Jupyter works.\nn.b. We’re still experimenting with JupyterHub. If you experience any problems with how it works (e.g. it runs really slowly, files go missing, really anything that seems odd), let me know right away. You can always run Jupyter locally on your own laptop or on any of our classroom or lab computers. See this page for instructions on working with Jupyter locally."
  },
  {
    "objectID": "slides/debugging.html",
    "href": "slides/debugging.html",
    "title": "Debugging Your Code",
    "section": "",
    "text": "Think about what you were trying to do vs. what happened instead. Create a hypothesis for what went wrong.\n\n\n\nLook for a line number where the error is occurring.\nSometimes the bug is in the line before the one that threw the error!\n\n\n\nSometimes you ran something out of order. Go back to the beginning of your code and re-run to see if that will fix it.\n\n\n\nTry your best to explain the problem out loud, preferably to a friend or teammate.\nPractice rubber duck debugging.\n\n\n\n\nIf you’re lost, refer to all the resources you have: cheatsheets, lab guides, online documentation.\nAnd when in doubt: Google the error message and see if someone else had the same problem!\n\n\n\nDon’t let a single bug frustrate you for too long. If none of the above strategies worked, ask a classmate, TA, or instructor for help with the problem."
  },
  {
    "objectID": "slides/debugging.html#step-1-define-the-problem",
    "href": "slides/debugging.html#step-1-define-the-problem",
    "title": "Debugging Your Code",
    "section": "",
    "text": "Think about what you were trying to do vs. what happened instead. Create a hypothesis for what went wrong."
  },
  {
    "objectID": "slides/debugging.html#step-2-read-the-error-message.",
    "href": "slides/debugging.html#step-2-read-the-error-message.",
    "title": "Debugging Your Code",
    "section": "",
    "text": "Look for a line number where the error is occurring.\nSometimes the bug is in the line before the one that threw the error!"
  },
  {
    "objectID": "slides/debugging.html#step-3-re-run-code-from-the-beginning.",
    "href": "slides/debugging.html#step-3-re-run-code-from-the-beginning.",
    "title": "Debugging Your Code",
    "section": "",
    "text": "Sometimes you ran something out of order. Go back to the beginning of your code and re-run to see if that will fix it."
  },
  {
    "objectID": "slides/debugging.html#step-4-talk-it-out",
    "href": "slides/debugging.html#step-4-talk-it-out",
    "title": "Debugging Your Code",
    "section": "",
    "text": "Try your best to explain the problem out loud, preferably to a friend or teammate.\nPractice rubber duck debugging."
  },
  {
    "objectID": "slides/debugging.html#step-5-check-instructions-documentation-and-google.",
    "href": "slides/debugging.html#step-5-check-instructions-documentation-and-google.",
    "title": "Debugging Your Code",
    "section": "",
    "text": "If you’re lost, refer to all the resources you have: cheatsheets, lab guides, online documentation.\nAnd when in doubt: Google the error message and see if someone else had the same problem!"
  },
  {
    "objectID": "slides/debugging.html#step-6-ask-for-help",
    "href": "slides/debugging.html#step-6-ask-for-help",
    "title": "Debugging Your Code",
    "section": "",
    "text": "Don’t let a single bug frustrate you for too long. If none of the above strategies worked, ask a classmate, TA, or instructor for help with the problem."
  },
  {
    "objectID": "slides/debugging.html#save-andor-knit-often.",
    "href": "slides/debugging.html#save-andor-knit-often.",
    "title": "Debugging Your Code",
    "section": "Save and/or Knit Often.",
    "text": "Save and/or Knit Often.\nRemember, your RMarkdown won’t knit if there are bugs. This is a great way to find them early."
  },
  {
    "objectID": "slides/debugging.html#use-good-names.",
    "href": "slides/debugging.html#use-good-names.",
    "title": "Debugging Your Code",
    "section": "Use good names.",
    "text": "Use good names.\nName your variables and dataframes with care. Rename things to make them more clear. Good names can help you find a problem quickly."
  },
  {
    "objectID": "slides/debugging.html#start-simple-and-build-up-little-by-little.",
    "href": "slides/debugging.html#start-simple-and-build-up-little-by-little.",
    "title": "Debugging Your Code",
    "section": "Start simple, and build up little by little.",
    "text": "Start simple, and build up little by little.\nDon’t try to write a whole program all in one go."
  },
  {
    "objectID": "slides/debugging.html#run-your-code-line-by-line.",
    "href": "slides/debugging.html#run-your-code-line-by-line.",
    "title": "Debugging Your Code",
    "section": "Run your code line-by-line.",
    "text": "Run your code line-by-line.\nCheck that it works as you go."
  },
  {
    "objectID": "slides/debugging.html#leave-yourself-good-annotations-and-comments",
    "href": "slides/debugging.html#leave-yourself-good-annotations-and-comments",
    "title": "Debugging Your Code",
    "section": "Leave yourself good annotations and comments!",
    "text": "Leave yourself good annotations and comments!\nUse # to leave comments: remind yourself what certain lines of code are doing."
  },
  {
    "objectID": "slides/debugging.html#resources-for-avoiding-errors",
    "href": "slides/debugging.html#resources-for-avoiding-errors",
    "title": "Debugging Your Code",
    "section": "Resources for Avoiding Errors",
    "text": "Resources for Avoiding Errors\nPractice Defensive Programming\nFollow Style Guides:\nWickham’s Guide\nGoogle’s Guide"
  },
  {
    "objectID": "slides/debugging.html#example-1",
    "href": "slides/debugging.html#example-1",
    "title": "Debugging Your Code",
    "section": "Example 1",
    "text": "Example 1\n# Get just three columns of mpg.\n\nsmall_mpg &lt;- mpg %&gt;%\n  filter(cyll, trans, cty)"
  },
  {
    "objectID": "slides/debugging.html#example-2",
    "href": "slides/debugging.html#example-2",
    "title": "Debugging Your Code",
    "section": "Example 2",
    "text": "Example 2\n# Make a summary table of highway fuel efficiency\n# in different manufacturers.\n\ngroup_by(mpg) %&gt;%\n  summarize(hwy)"
  },
  {
    "objectID": "slides/debugging.html#example-3",
    "href": "slides/debugging.html#example-3",
    "title": "Debugging Your Code",
    "section": "Example 3",
    "text": "Example 3\n# Make boxplot of city fuel efficiency\n# in different drive trains.\n\nggplot(aes(cty)) +\n  geom_boxplot(aes(fill=blue))"
  },
  {
    "objectID": "slides/mapping.html",
    "href": "slides/mapping.html",
    "title": "Mapping and Spatial Data",
    "section": "",
    "text": "Degrees, Minutes, Seconds format:\n110°W 21’ 13”\nDecimal Degrees format:\n110.353611\n(+/- for N/S or W/E)\n\n\n\nYou can always use an online conversion tool.\n\n\n\nYou need a “bounding box” to define the edges of your map.\n\nFind bbox coordinates online at bboxfinder.com.\n\n\n\nPlotting points in space is only the first step."
  },
  {
    "objectID": "slides/mapping.html#geographic-data-includes-geocoordinates.",
    "href": "slides/mapping.html#geographic-data-includes-geocoordinates.",
    "title": "Mapping and Spatial Data",
    "section": "",
    "text": "Degrees, Minutes, Seconds format:\n110°W 21’ 13”\nDecimal Degrees format:\n110.353611\n(+/- for N/S or W/E)"
  },
  {
    "objectID": "slides/mapping.html#most-mapping-software-uses-decimal-degrees",
    "href": "slides/mapping.html#most-mapping-software-uses-decimal-degrees",
    "title": "Mapping and Spatial Data",
    "section": "",
    "text": "You can always use an online conversion tool."
  },
  {
    "objectID": "slides/mapping.html#longitude-and-latitude-tell-us-the-locations-of-the-data-and-its-extent.",
    "href": "slides/mapping.html#longitude-and-latitude-tell-us-the-locations-of-the-data-and-its-extent.",
    "title": "Mapping and Spatial Data",
    "section": "",
    "text": "You need a “bounding box” to define the edges of your map.\n\nFind bbox coordinates online at bboxfinder.com."
  },
  {
    "objectID": "slides/mapping.html#maps-are-awesome.-spatial-analysis-is-hard.",
    "href": "slides/mapping.html#maps-are-awesome.-spatial-analysis-is-hard.",
    "title": "Mapping and Spatial Data",
    "section": "",
    "text": "Plotting points in space is only the first step."
  },
  {
    "objectID": "slides/mapping.html#first-install-some-new-libraries.",
    "href": "slides/mapping.html#first-install-some-new-libraries.",
    "title": "Mapping and Spatial Data",
    "section": "First, install some new libraries.",
    "text": "First, install some new libraries.\n# In the console, type:\ninstall.packages(\"devtools\")\nlibrary(devtools)\ndevtools::install_github(\"dkahle/ggmap\")\ninstall.packages(\"rworldmap\")\ninstall.packages(\"gapminder\")"
  },
  {
    "objectID": "slides/mapping.html#then-import-those-libraries-in-a-new-rscript.",
    "href": "slides/mapping.html#then-import-those-libraries-in-a-new-rscript.",
    "title": "Mapping and Spatial Data",
    "section": "Then import those libraries in a new RScript.",
    "text": "Then import those libraries in a new RScript.\n# In an R Script or RMarkdown file, type:\nlibrary(ggmap)\nlibrary(dplyr)\nlibrary(sp)\nlibrary(rworldmap)\nlibrary(gapminder)"
  },
  {
    "objectID": "slides/mapping.html#ggmap-works-like-ggplot-and-we-can-apply-the-same-skills-to-it.",
    "href": "slides/mapping.html#ggmap-works-like-ggplot-and-we-can-apply-the-same-skills-to-it.",
    "title": "Mapping and Spatial Data",
    "section": "GGmap works like ggplot, and we can apply the same skills to it.",
    "text": "GGmap works like ggplot, and we can apply the same skills to it.\nLet’s make this map together:"
  },
  {
    "objectID": "slides/mapping.html#first-we-make-a-bounding-box.",
    "href": "slides/mapping.html#first-we-make-a-bounding-box.",
    "title": "Mapping and Spatial Data",
    "section": "First we make a bounding box.",
    "text": "First we make a bounding box.\nFor the US, we can enter the bounding coordinates manually:\nusbbox &lt;- c(left = -125, bottom = 25.75, right = -67, top = 49)"
  },
  {
    "objectID": "slides/mapping.html#then-we-make-a-map-object-for-ggmap-to-process.",
    "href": "slides/mapping.html#then-we-make-a-map-object-for-ggmap-to-process.",
    "title": "Mapping and Spatial Data",
    "section": "Then we make a “map object” for ggmap to process.",
    "text": "Then we make a “map object” for ggmap to process.\nWe do this using ggmap’s special get_stamenmap() function.\nusmap &lt;- get_stamenmap(usbbox, zoom = 5)\nStamen is a map/geocoding service."
  },
  {
    "objectID": "slides/mapping.html#then-just-run-ggmap",
    "href": "slides/mapping.html#then-just-run-ggmap",
    "title": "Mapping and Spatial Data",
    "section": "Then, just run ggmap!",
    "text": "Then, just run ggmap!\nggmap(usmap)"
  },
  {
    "objectID": "slides/mapping.html#now-you-can-play-around-and-adjust-the-features.",
    "href": "slides/mapping.html#now-you-can-play-around-and-adjust-the-features.",
    "title": "Mapping and Spatial Data",
    "section": "Now you can play around and adjust the features.",
    "text": "Now you can play around and adjust the features.\nWhat happens if you lower the zoom value? What happens if you add a maptype to the get_stamenmap() function?\nPossible maptypes: “terrain”, “terrain-background”, “terrain-labels”, “terrain-lines”, “toner”, “toner-2010”, “toner-2011”, “toner-background”, “toner-hybrid”, “toner-labels”, “toner-lines”, “toner-lite”, “watercolor”"
  },
  {
    "objectID": "slides/mapping.html#lets-make-a-map-based-on-crime-data-in-houston-tx.",
    "href": "slides/mapping.html#lets-make-a-map-based-on-crime-data-in-houston-tx.",
    "title": "Mapping and Spatial Data",
    "section": "Let’s make a map based on crime data in Houston, TX.",
    "text": "Let’s make a map based on crime data in Houston, TX.\nggmap comes with a crime dataset we can use.\n# Let's filter the data to only violent crimes\nviolent_crimes &lt;- filter(crime, offense != \"auto theft\", offense != \"theft\", offense != \"burglary\")\n\n# rank violent crimes\nviolent_crimes$offense &lt;- factor(violent_crimes$offense,\n                                 levels = c(\"robbery\", \"aggravated \nassault\", \"rape\", \"murder\"))\n\n# restrict to downtown\nviolent_crimes &lt;- filter(violent_crimes,\n                         -95.39681 &lt;= lon & lon &lt;= -95.34188,\n                         29.73631 &lt;= lat & lat &lt;=  29.78400)"
  },
  {
    "objectID": "slides/mapping.html#now-we-can-prepare-our-houston-bbox-and-map.",
    "href": "slides/mapping.html#now-we-can-prepare-our-houston-bbox-and-map.",
    "title": "Mapping and Spatial Data",
    "section": "Now we can prepare our Houston bbox and map.",
    "text": "Now we can prepare our Houston bbox and map.\n# Use SpatialPoints from sp library to get\n# bbox from our data instead of manually.\nbbox &lt;- bbox(SpatialPoints(violent_crimes[,c(\"lon\", \"lat\")]))\n\n# Get a map based on this bbox\nmap &lt;- get_stamenmap(bbox, maptype=\"toner-lite\", zoom=13)"
  },
  {
    "objectID": "slides/mapping.html#write-a-ggmap-function-just-like-ggplot.",
    "href": "slides/mapping.html#write-a-ggmap-function-just-like-ggplot.",
    "title": "Mapping and Spatial Data",
    "section": "Write a ggmap function just like ggplot.",
    "text": "Write a ggmap function just like ggplot.\nggmap(map, darken=0.7) +\n  geom_point(data=violent_crimes, aes(lon, lat), col=\"red\")\nWow! Try it with and without the darken parameter. What changes?"
  },
  {
    "objectID": "slides/mapping.html#and-look-at-the-final-product",
    "href": "slides/mapping.html#and-look-at-the-final-product",
    "title": "Mapping and Spatial Data",
    "section": "And look at the final product!",
    "text": "And look at the final product!"
  },
  {
    "objectID": "slides/mapping.html#we-can-also-facet-this-graph-just-like-ggplot.",
    "href": "slides/mapping.html#we-can-also-facet-this-graph-just-like-ggplot.",
    "title": "Mapping and Spatial Data",
    "section": "We can also facet this graph, just like ggplot.",
    "text": "We can also facet this graph, just like ggplot.\nggmap(map, darken=0.6) +\n  geom_point(data= violent_crimes, aes(lon, lat, color = offense)) +\n  facet_wrap(~month)\n\n\n\n\nNeeds some cleanup, but not too bad!"
  },
  {
    "objectID": "slides/mapping.html#we-can-take-the-same-data-and-make-a-heat-map-instead.",
    "href": "slides/mapping.html#we-can-take-the-same-data-and-make-a-heat-map-instead.",
    "title": "Mapping and Spatial Data",
    "section": "We can take the same data and make a “heat map” instead.",
    "text": "We can take the same data and make a “heat map” instead.\n# Filter to only robberies\nrobberies &lt;- violent_crimes %&gt;% filter(offense == \"robbery\")\n\n# Use density geometries\nggmap(map, extent=\"device\") +\n  geom_density2d(data=robberies, aes(x=lon, y=lat), size=0.3) +\n  stat_density2d(data=robberies, aes(x=lon, y=lat, fill=..level.., alpha=..level..), size=0.01, bins=16, geom=\"polygon\") +\n  scale_fill_gradient(low = \"blue\", high = \"red\") +\n  scale_alpha(range = c(0, 0.3), guide = \"none\")\n\n\n\n\nCool, right? And maybe more useful than a simple dot map."
  },
  {
    "objectID": "slides/mapping.html#challenge-1",
    "href": "slides/mapping.html#challenge-1",
    "title": "Mapping and Spatial Data",
    "section": "Challenge 1",
    "text": "Challenge 1\nRemember how the Garlic Mustard dataset had latitude and longitude variables? One thing we might need to know, in order to validate our study, is if there is geographic bias in where garlic mustard plots were.\n\nFind the bounding box for your data points\nPlot the garlic mustard points on our map of the US\nColor the points by a categorical variable\nColor and/or size the points by a numeric variable\nSee if you can make a heat map of where the plots are concentrated."
  },
  {
    "objectID": "slides/mapping.html#challenge-2",
    "href": "slides/mapping.html#challenge-2",
    "title": "Mapping and Spatial Data",
    "section": "Challenge 2",
    "text": "Challenge 2\nNow do the same thing for Europe! How would you get the right bounding box?"
  },
  {
    "objectID": "slides/mapping.html#challenge-3",
    "href": "slides/mapping.html#challenge-3",
    "title": "Mapping and Spatial Data",
    "section": "Challenge 3",
    "text": "Challenge 3\nMake a map of Denison University, and label a building or location on campus that you enjoy, with text that relates to why it’s special to you - or why you’re thankful for it.\n# Hint: the \"annotate\" layer of ggmap looks like this:\nannotate('text', x=-82.523211, y=40.071658, label='I teach here &lt;3', colour=I('white'), size=4)"
  },
  {
    "objectID": "slides/mapping.html#solution-1",
    "href": "slides/mapping.html#solution-1",
    "title": "Mapping and Spatial Data",
    "section": "Solution 1",
    "text": "Solution 1"
  },
  {
    "objectID": "slides/mapping.html#alternative-solution-1",
    "href": "slides/mapping.html#alternative-solution-1",
    "title": "Mapping and Spatial Data",
    "section": "Alternative Solution 1",
    "text": "Alternative Solution 1"
  },
  {
    "objectID": "slides/mapping.html#solution-2",
    "href": "slides/mapping.html#solution-2",
    "title": "Mapping and Spatial Data",
    "section": "Solution 2",
    "text": "Solution 2"
  },
  {
    "objectID": "slides/mapping.html#solution-3",
    "href": "slides/mapping.html#solution-3",
    "title": "Mapping and Spatial Data",
    "section": "Solution 3",
    "text": "Solution 3"
  },
  {
    "objectID": "slides/mapping.html#you-see-these-everywhere",
    "href": "slides/mapping.html#you-see-these-everywhere",
    "title": "Mapping and Spatial Data",
    "section": "You see these everywhere!",
    "text": "You see these everywhere!\n\n\n\nThe in-progress NYTimes electoral map from 2008."
  },
  {
    "objectID": "slides/mapping.html#you-dont-even-need-ggmap-for-this.-regular-ggplot-will-do.-lets-make-one-together.",
    "href": "slides/mapping.html#you-dont-even-need-ggmap-for-this.-regular-ggplot-will-do.-lets-make-one-together.",
    "title": "Mapping and Spatial Data",
    "section": "You don’t even need ggmap for this. Regular ggplot will do. Let’s make one together.",
    "text": "You don’t even need ggmap for this. Regular ggplot will do. Let’s make one together."
  },
  {
    "objectID": "slides/mapping.html#get-some-global-gdp-data-from-gapminder.",
    "href": "slides/mapping.html#get-some-global-gdp-data-from-gapminder.",
    "title": "Mapping and Spatial Data",
    "section": "Get some global GDP data from gapminder.",
    "text": "Get some global GDP data from gapminder.\n# Get gapminder world economy data for 2007\ngap2007=gapminder %&gt;%\n  filter(year==2007) %&gt;%\n  rename(region=country)"
  },
  {
    "objectID": "slides/mapping.html#chloropleth-maps-are-made-of-polygons.-lets-use-rworldmap-to-get-our-polygons.",
    "href": "slides/mapping.html#chloropleth-maps-are-made-of-polygons.-lets-use-rworldmap-to-get-our-polygons.",
    "title": "Mapping and Spatial Data",
    "section": "Chloropleth maps are made of polygons. Let’s use rworldmap to get our polygons.",
    "text": "Chloropleth maps are made of polygons. Let’s use rworldmap to get our polygons.\n# Get world polygons\nworld &lt;- map_data(map=\"world\")\n\n# Now we can \"join\" this to our gapminder data:\nworld2 &lt;- left_join(world, gap2007, by=\"region\")"
  },
  {
    "objectID": "slides/mapping.html#finally-we-can-write-our-ggplot-code-using-geom_polygon.",
    "href": "slides/mapping.html#finally-we-can-write-our-ggplot-code-using-geom_polygon.",
    "title": "Mapping and Spatial Data",
    "section": "Finally we can write our ggplot code using geom_polygon().",
    "text": "Finally we can write our ggplot code using geom_polygon().\n# Chloropleth world GDP map\nggplot(world2, aes(long, lat, group = group))+\n  geom_polygon(aes(fill = gdpPercap), col=\"white\")+\n  scale_fill_viridis_c(option = \"C\") +\n  theme_void()"
  },
  {
    "objectID": "slides/mapping.html#and-voila",
    "href": "slides/mapping.html#and-voila",
    "title": "Mapping and Spatial Data",
    "section": "And voila!",
    "text": "And voila!"
  },
  {
    "objectID": "slides/mapping.html#you-try-it",
    "href": "slides/mapping.html#you-try-it",
    "title": "Mapping and Spatial Data",
    "section": "You try it!",
    "text": "You try it!\nChallenge: Make a similar map for the urban population of US states.\nHere’s some code to get you started:\n# Get US states polygons\nstates &lt;- map_data(map=\"state\")\n# Lowercase crime data\nUSArrests$region = tolower(rownames(USArrests))\nWhat do you need to do next? Think about joining data before you try ggplot!"
  },
  {
    "objectID": "slides/mapping.html#heres-what-youre-aiming-for",
    "href": "slides/mapping.html#heres-what-youre-aiming-for",
    "title": "Mapping and Spatial Data",
    "section": "Here’s what you’re aiming for:",
    "text": "Here’s what you’re aiming for:"
  },
  {
    "objectID": "slides/naivebayes.html#not-all-classifiers-are-based-on-a-linear-model",
    "href": "slides/naivebayes.html#not-all-classifiers-are-based-on-a-linear-model",
    "title": "Naive Bayes Classifier",
    "section": "Not all classifiers are based on a linear model!",
    "text": "Not all classifiers are based on a linear model!"
  },
  {
    "objectID": "slides/naivebayes.html#naive-bayes-predicts-a-target-by-finding-the-probability-of-predictors-based-on-a-specific-target.",
    "href": "slides/naivebayes.html#naive-bayes-predicts-a-target-by-finding-the-probability-of-predictors-based-on-a-specific-target.",
    "title": "Naive Bayes Classifier",
    "section": "Naive Bayes predicts a target by finding the probability of predictors based on a specific target.",
    "text": "Naive Bayes predicts a target by finding the probability of predictors based on a specific target.\nLike in hypothesis testing, this is the opposite of what we’d expect!"
  },
  {
    "objectID": "slides/naivebayes.html#exact-bayesian-classification",
    "href": "slides/naivebayes.html#exact-bayesian-classification",
    "title": "Naive Bayes Classifier",
    "section": "Exact Bayesian Classification",
    "text": "Exact Bayesian Classification\nFind all records that are the same as the one you care about. What’s the proportion of possible targets? The highest proportion is your prediction!\nThis is impractical, because very few records are identical."
  },
  {
    "objectID": "slides/naivebayes.html#naive-bayes-classification",
    "href": "slides/naivebayes.html#naive-bayes-classification",
    "title": "Naive Bayes Classifier",
    "section": "Naive Bayes Classification",
    "text": "Naive Bayes Classification\nFor each possible target, find the individual conditional probabilities of every predictor. Multiply these probabilities by each other and by the number of records in the possible target class. Divide this by the sum of these values for all the classes. That gives you the probability!"
  },
  {
    "objectID": "slides/naivebayes.html#this-is-naive-because-it-assumes-every-predictor-is-independent.",
    "href": "slides/naivebayes.html#this-is-naive-because-it-assumes-every-predictor-is-independent.",
    "title": "Naive Bayes Classifier",
    "section": "This is naive because it assumes every predictor is independent.",
    "text": "This is naive because it assumes every predictor is independent.\nThis isn’t always true, but naive Bayes classifiers can still be useful."
  },
  {
    "objectID": "slides/naivebayes.html#this-can-only-be-used-with-categorical-predictor-variables",
    "href": "slides/naivebayes.html#this-can-only-be-used-with-categorical-predictor-variables",
    "title": "Naive Bayes Classifier",
    "section": "This can only be used with categorical predictor variables!!",
    "text": "This can only be used with categorical predictor variables!!\nNumerical variables would need to be “binned” into categories first."
  },
  {
    "objectID": "slides/naivebayes.html#we-need-the-multinomialnb-class.",
    "href": "slides/naivebayes.html#we-need-the-multinomialnb-class.",
    "title": "Naive Bayes Classifier",
    "section": "We need the MultinomialNB class.",
    "text": "We need the MultinomialNB class.\nfrom sklearn.naive_bayes import MultinomialNB"
  },
  {
    "objectID": "slides/naivebayes.html#lets-look-at-the-titanic-dataset.",
    "href": "slides/naivebayes.html#lets-look-at-the-titanic-dataset.",
    "title": "Naive Bayes Classifier",
    "section": "Let’s look at the Titanic dataset.",
    "text": "Let’s look at the Titanic dataset.\nCan we predict who survived based on some categorical data?\nLoad the data and create predictors and target variables."
  },
  {
    "objectID": "slides/naivebayes.html#prepare-and-split-the-data.",
    "href": "slides/naivebayes.html#prepare-and-split-the-data.",
    "title": "Naive Bayes Classifier",
    "section": "Prepare and split the data.",
    "text": "Prepare and split the data.\nThis time we use one-hot encoding. We don’t need to drop_first.\nX = pd.get_dummies(titanic[predictors]) # One-hot encoding\ny = titanic[target] # Creating a y to keep our code cleaner\n# No variable standardization needed. Why?\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, \n    y, \n    test_size=0.3, \n    random_state=0)"
  },
  {
    "objectID": "slides/naivebayes.html#create-and-fit-the-model",
    "href": "slides/naivebayes.html#create-and-fit-the-model",
    "title": "Naive Bayes Classifier",
    "section": "Create and fit the model",
    "text": "Create and fit the model\nnaive_model = MultinomialNB(alpha=0.01, fit_prior=True)\nnaive_model.fit(X_train,y_train)\nAlpha sets smoothing to prevent problems with 0s. The default is 1, but better to set it smaller. fit_prior makes sure to use prior probabilities (True is the default)."
  },
  {
    "objectID": "slides/naivebayes.html#get-probabilities-and-predictions-as-usual.",
    "href": "slides/naivebayes.html#get-probabilities-and-predictions-as-usual.",
    "title": "Naive Bayes Classifier",
    "section": "Get probabilities and predictions as usual.",
    "text": "Get probabilities and predictions as usual.\nprobabilities = naive_model.predict_proba(X_test)\nprobabilities = pd.DataFrame(probabilities)\n\npredictions = naive_model.predict(X_test)"
  },
  {
    "objectID": "slides/naivebayes.html#we-use-exactly-the-same-methods-as-every-other-classifier",
    "href": "slides/naivebayes.html#we-use-exactly-the-same-methods-as-every-other-classifier",
    "title": "Naive Bayes Classifier",
    "section": "We use exactly the same methods as every other classifier!",
    "text": "We use exactly the same methods as every other classifier!\nImport all the same metric functions as last time.\n\nConfusion Matrix\nClassification Report\nCross-validation\nROC Curve & AUC Score (binary classifier only)"
  },
  {
    "objectID": "slides/naivebayes.html#thanks-thomas-bayes",
    "href": "slides/naivebayes.html#thanks-thomas-bayes",
    "title": "Naive Bayes Classifier",
    "section": "Thanks, Thomas Bayes!",
    "text": "Thanks, Thomas Bayes!"
  },
  {
    "objectID": "slides/whatisdata.html#data-is-something-that-people-make.",
    "href": "slides/whatisdata.html#data-is-something-that-people-make.",
    "title": "What Is Data?",
    "section": "Data Is Something That People Make.",
    "text": "Data Is Something That People Make."
  },
  {
    "objectID": "slides/whatisdata.html#data-can-be-rectangular-tabular.",
    "href": "slides/whatisdata.html#data-can-be-rectangular-tabular.",
    "title": "What Is Data?",
    "section": "Data Can Be Rectangular (Tabular).",
    "text": "Data Can Be Rectangular (Tabular)."
  },
  {
    "objectID": "slides/whatisdata.html#data-can-be-structured-relational.",
    "href": "slides/whatisdata.html#data-can-be-structured-relational.",
    "title": "What Is Data?",
    "section": "Data Can be Structured (Relational).",
    "text": "Data Can be Structured (Relational)."
  },
  {
    "objectID": "slides/whatisdata.html#data-has-rows-observations-and-columns-features.",
    "href": "slides/whatisdata.html#data-has-rows-observations-and-columns-features.",
    "title": "What Is Data?",
    "section": "Data has Rows (Observations) and Columns (Features).",
    "text": "Data has Rows (Observations) and Columns (Features)."
  },
  {
    "objectID": "slides/whatisdata.html#one-row-for-each-observation.",
    "href": "slides/whatisdata.html#one-row-for-each-observation.",
    "title": "What Is Data?",
    "section": "One Row for Each Observation.",
    "text": "One Row for Each Observation."
  },
  {
    "objectID": "slides/whatisdata.html#one-column-for-each-type-of-information.",
    "href": "slides/whatisdata.html#one-column-for-each-type-of-information.",
    "title": "What Is Data?",
    "section": "One Column for Each Type of Information.",
    "text": "One Column for Each Type of Information."
  },
  {
    "objectID": "slides/whatisdata.html#one-value-in-every-cell.",
    "href": "slides/whatisdata.html#one-value-in-every-cell.",
    "title": "What Is Data?",
    "section": "One Value in Every Cell.",
    "text": "One Value in Every Cell."
  },
  {
    "objectID": "slides/whatisdata.html#avoid-visual-data-i.e.-colors-in-a-spreadsheet.",
    "href": "slides/whatisdata.html#avoid-visual-data-i.e.-colors-in-a-spreadsheet.",
    "title": "What Is Data?",
    "section": "Avoid Visual “Data” (i.e. colors in a spreadsheet).",
    "text": "Avoid Visual “Data” (i.e. colors in a spreadsheet)."
  },
  {
    "objectID": "slides/whatisdata.html#use-good-null-values.",
    "href": "slides/whatisdata.html#use-good-null-values.",
    "title": "What Is Data?",
    "section": "Use Good Null Values.",
    "text": "Use Good Null Values."
  },
  {
    "objectID": "slides/whatisdata.html#save-data-in-plain-text-files-csv-or-tsv.",
    "href": "slides/whatisdata.html#save-data-in-plain-text-files-csv-or-tsv.",
    "title": "What Is Data?",
    "section": "Save Data in Plain Text Files (CSV or TSV).",
    "text": "Save Data in Plain Text Files (CSV or TSV)."
  },
  {
    "objectID": "slides/whatisdata.html#data-can-be-quantitative-numerical.",
    "href": "slides/whatisdata.html#data-can-be-quantitative-numerical.",
    "title": "What Is Data?",
    "section": "Data Can Be Quantitative (Numerical).",
    "text": "Data Can Be Quantitative (Numerical).\n\nDiscrete (integers or whole numbers)\nContinuous (any value, including decimals)"
  },
  {
    "objectID": "slides/whatisdata.html#data-can-be-qualitative-categorical.",
    "href": "slides/whatisdata.html#data-can-be-qualitative-categorical.",
    "title": "What Is Data?",
    "section": "Data Can Be Qualitative (Categorical).",
    "text": "Data Can Be Qualitative (Categorical).\n\nOrdinal (categories have an order or hierarchy)\nNominal (categories don’t have an order)"
  },
  {
    "objectID": "slides/whatisdata.html#types-of-metadata",
    "href": "slides/whatisdata.html#types-of-metadata",
    "title": "What Is Data?",
    "section": "Types of Metadata",
    "text": "Types of Metadata\n\nDescriptive metadata can help you find and understand a dataset or resource. (e.g. titles and authors of books)\nAdministrative metadata can help you manage a resource and tell you about how it was created. (e.g. publishers of books, or ebook file formats)\nStructural metadata can help you understand the different parts of the dataset and their relationship. (e.g. column labels, or tables of contents in books)"
  },
  {
    "objectID": "slides/whatisdata.html#metadata-has-standards-for-interoperability.",
    "href": "slides/whatisdata.html#metadata-has-standards-for-interoperability.",
    "title": "What Is Data?",
    "section": "Metadata has standards for interoperability.",
    "text": "Metadata has standards for interoperability.\nDublin Core – 13 features common to digital data\nDDI: Data Documentation Initiative – social, behavioral, and economic sciences\nMARC: MAchine Readable Cataloging – libraries, books & media"
  }
]